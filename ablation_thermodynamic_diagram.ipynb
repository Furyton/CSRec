{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b410e6ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from os import path\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from dataloaders import dataloader_factory\n",
    "from scheduler.utils import *\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b142c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "device = 'cuda'\n",
    "figure_type = 'ed'\n",
    "model_code = 'gru4rec'\n",
    "\n",
    "type_list = [\"base_2022\", \"base_2021\", \"partial_2000\", \"partial_2001\", \"dvae\", \"ed\", \"ep\"]\n",
    "\n",
    "suffix = [\"base_2022\", \"base_2021\", \"base_partial_2022\", \"base_partial_2022\", \"dvae\", \"ed\", \"ep\"]\n",
    "\n",
    "model_base_path = [\"___el_\" + s for s in suffix]\n",
    "primary_keywords = [\"gru4rec\", \"gru4rec\", \"gru4rec-rate-0.8-seed-2000\", \"gru4rec-rate-0.8-seed-2001\", \"gru4rec\", \"gru4rec\", \"gru4rec\"]\n",
    "secondary_keywords = [\"gru4rec\", \"gru4rec\", \"gru4rec\", \"gru4rec\", \"teacher\", \"student\", \"student\"]\n",
    "\n",
    "def dir_finder(path: Path, keyword):\n",
    "    for child in path.iterdir():\n",
    "        if child.is_dir() and keyword in child.name:\n",
    "            yield child\n",
    "\n",
    "model_path_dict = {}\n",
    "config_path_dict = {}\n",
    "\n",
    "rt = Path(\".\")\n",
    "\n",
    "for type_, base_path, primary_key, secondary_key in zip(type_list, model_base_path, primary_keywords, secondary_keywords):\n",
    "    base = rt.joinpath(base_path)\n",
    "    primary_path = next(dir_finder(base, primary_key))\n",
    "    secondary_path = next(dir_finder(primary_path, secondary_key))\n",
    "    secondary_p = secondary_path.joinpath('checkpoint', 'best_acc_model.pth') # model path\n",
    "    if not secondary_p.exists():\n",
    "        raise FileNotFoundError(secondary_p)\n",
    "    model_path_dict[type_] = secondary_p\n",
    "    \n",
    "    config_path = primary_path.joinpath('config.json')\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(config_path)\n",
    "    \n",
    "    config_path_dict[type_] = config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56aac7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(tp):\n",
    "    with open(path.normpath(config_path_dict[tp ]), 'r') as f:\n",
    "        args = argparse.Namespace()\n",
    "        args.__dict__.update(json.load(f))\n",
    "        if args.kwargs is not None:\n",
    "            args.__dict__.update(args.kwargs)\n",
    "\n",
    "    args.do_sampling = False\n",
    "    \n",
    "    return args\n",
    "\n",
    "base_args = get_args('base_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99da1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, dataset = dataloader_factory(base_args)\n",
    "\n",
    "item_train, item_valid, item_test, usernum, itemnum, rating_train, rating_valid, rating_test = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130f6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_with_weight(model_code, model_path, args):\n",
    "    model = generate_model(args, model_code, dataset, device)\n",
    "    load_state_from_given_path(model, model_path, device, must_exist=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6335c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teacher_model(tp='base', use_T=True):\n",
    "    from models.Ensembler import Ensembler\n",
    "\n",
    "    if tp in [\"base\", \"dvae\"]:\n",
    "        model = get_model_with_weight(model_code, model_path_dict['base_2022'] if tp == 'base' else model_path_dict['dvae'], base_args)\n",
    "        if use_T:\n",
    "            model.set_temperature(3.0)\n",
    "    else:\n",
    "        if tp == 'ed':\n",
    "            model1 = get_model_with_weight(model_code, model_path_dict['base_2021'], base_args)\n",
    "            model2 = get_model_with_weight(model_code, model_path_dict['base_2022'], base_args)\n",
    "\n",
    "            ed_args = get_args('ed')\n",
    "\n",
    "            T = ed_args.T\n",
    "        elif tp == 'ep':\n",
    "            model1 = get_model_with_weight(model_code, model_path_dict['partial_2000'], base_args)\n",
    "            model2 = get_model_with_weight(model_code, model_path_dict['partial_2001'], base_args)\n",
    "\n",
    "            ep_args = get_args('ep')\n",
    "\n",
    "            T = ep_args.T\n",
    "        \n",
    "        if use_T:\n",
    "            model = Ensembler(device, [model1, model2], temp=T)\n",
    "        else:\n",
    "            model = Ensembler(device, [model1, model2])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61bf1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(model, uk=100, ik=100, sm=True):\n",
    "    model.eval()\n",
    "\n",
    "    score_batch_list = []\n",
    "    user_batch_list = []\n",
    "\n",
    "    score_all = None\n",
    "    users = None\n",
    "\n",
    "    iterator = tqdm(test_loader)\n",
    "#     itertor = test_loader\n",
    "\n",
    "    cnt = 1\n",
    "\n",
    "    MOD = len(iterator) // 20\n",
    "\n",
    "    for batch in iterator:\n",
    "        if device == 'cuda':\n",
    "            batch = [x.to('cuda') for x in batch]\n",
    "        with torch.no_grad():\n",
    "            if score_all is None:\n",
    "                score_all = model.full_sort_predict(batch).cpu()\n",
    "                users = batch[-1].cpu()\n",
    "            else:\n",
    "                _score = model.full_sort_predict(batch)\n",
    "                _user = batch[-1]\n",
    "                score_all = torch.cat([score_all, _score.cpu()])\n",
    "                users = torch.cat([users, _user.cpu()])\n",
    "\n",
    "            if cnt % MOD == 0:\n",
    "                score_batch_list.append(score_all)\n",
    "                user_batch_list.append(users)\n",
    "\n",
    "                score_all = None\n",
    "                users = None\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "    score_all = torch.cat(score_batch_list)\n",
    "    users = torch.cat(user_batch_list)\n",
    "\n",
    "    selected_score = score_all[:uk].cpu()\n",
    "    selected_topk = selected_score.topk(ik, dim=1)\n",
    "    if sm:\n",
    "        softmaxed_topk = torch.softmax(selected_topk.values, dim=1)\n",
    "        return softmaxed_topk, score_all\n",
    "    else:\n",
    "        return selected_topk.values, score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4668e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(itemnum * 0.1)\n",
    "# uk = int(usernum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719bb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = get_teacher_model('base')\n",
    "ed = get_teacher_model('ed')\n",
    "ep = get_teacher_model('ep')\n",
    "dvae = get_teacher_model('dvae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d38f0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [06:30<00:00,  1.02it/s]\n",
      "100%|██████████| 400/400 [04:10<00:00,  1.60it/s]\n",
      " 74%|███████▍  | 295/400 [03:00<01:15,  1.39it/s]"
     ]
    }
   ],
   "source": [
    "data1, raw_data1 = get_data(bs, uk=usernum, ik=k)\n",
    "data2, raw_data2 = get_data(ed, uk=usernum, ik=k, sm=False)\n",
    "data3, raw_data3 = get_data(ep, uk=usernum, ik=k, sm=False)\n",
    "data4, raw_data4 = get_data(dvae, uk=usernum, ik=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd80d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 3, gridspec_kw={'width_ratios': [1,1,0.08]})\n",
    "\n",
    "# axs[0, 0].get_shared_y_axes().join(axs[0, 1])\n",
    "# axs[1, 0].get_shared_y_axes().join(axs[1, 1])\n",
    "\n",
    "# axs[0, 0].title.set_text('base')\n",
    "# axs[0, 1].title.set_text('ed')\n",
    "# axs[1, 0].title.set_text('ep')\n",
    "# axs[1, 1].title.set_text('dvae')\n",
    "\n",
    "# s1 = sns.heatmap(data1[:, :50], ax=axs[0, 0], xticklabels=False, cbar_ax=axs[0, 2])\n",
    "# s1.set_xlabel('')\n",
    "# s1.set_ylabel('')\n",
    "# s2 = sns.heatmap(data2[:, :50], ax=axs[0, 1], cbar_ax=axs[0, 2], xticklabels=False)\n",
    "# s2.set_xlabel('')\n",
    "# s2.set_ylabel('')\n",
    "# s2.set_yticks([])\n",
    "\n",
    "# s3 = sns.heatmap(data3[:, :50], ax=axs[1, 0], cbar_ax=axs[0, 2])\n",
    "# s3.set_xlabel('')\n",
    "# s3.set_ylabel('')\n",
    "# s4 = sns.heatmap(data4[:, :50], ax=axs[1, 1], cbar_ax=axs[0, 2])\n",
    "# s4.set_xlabel('')\n",
    "# s4.set_ylabel('')\n",
    "# s4.set_yticks([])\n",
    "\n",
    "# for ax in [s1, s2, s3, s4]:\n",
    "#     tl = ax.get_xticklabels()\n",
    "#     ax.set_xticklabels(tl, rotation=90)\n",
    "#     tly = ax.get_yticklabels()\n",
    "#     ax.set_yticklabels(tly, rotation=0)\n",
    "\n",
    "# axs[-1,-1].axis('off')\n",
    "\n",
    "# plt.savefig('./ablation/heatmap_of_four_no_log.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6192ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save([data2, data3], 'data_2_3.pt')\n",
    "# torch.save([data1, data2, data3, data4], 'full_user_data_with_T.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e781534ff0a4a9cdbb0600245590fb60d97caba7a50501441961d6e7d9538dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
