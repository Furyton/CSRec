INFO    [02-25 13:31:12] setup_train in utils:
{
    "experiment_dir": "___lfms_soft_2022",
    "experiment_description": "pop",
    "describe": "{config[model_code]}-T-{config[T]}-al-{config[alpha]}",
    "dataset_name": "lastfm_small.csv",
    "sched": "distill",
    "model_code": "sasrec",
    "mentor_code": "pop",
    "training_routine": "student",
    "softmaxed_mentor": false,
    "alpha": 0.5,
    "T": 9.0,
    "num_epochs": 50,
    "mode": "train",
    "max_len": 20,
    "test_state_path": null,
    "model_state_path": null,
    "mentor_state_path": null,
    "rand_seed": 2022,
    "load_processed_dataset": true,
    "save_processed_dataset": false,
    "dataset_cache_filename": null,
    "weight_decay": 0,
    "decay_step": 15,
    "gamma": 0.99,
    "lr": 0.001,
    "min_length": 5,
    "min_item_inter": 5,
    "good_only": false,
    "use_rating": true,
    "test_negative_sampler_code": "random",
    "test_negative_sample_size": 0,
    "dataloader_type": "next",
    "train_batch_size": 64,
    "val_batch_size": 64,
    "test_batch_size": 64,
    "prop_sliding_window": -1.0,
    "worker_number": 2,
    "metric_ks": [
        5,
        10
    ],
    "device": "cuda",
    "num_gpu": 1,
    "optimizer": "Adam",
    "best_metric": "NDCG@10",
    "show_process_bar": false,
    "enable_sample": false,
    "samples_ratio": 0.1,
    "config_file": "config2.lastfm_small/sasrec/config_distill.json",
    "task_id": 11,
    "split": "leave_one_out",
    "do_remap": true,
    "train_negative_sampler_code": "random",
    "train_negative_sample_size": 100,
    "device_idx": "0",
    "momentum": null,
    "log_period_as_iter": 12800,
    "dvae_alpha": 0.5,
    "weight_list": [
        0.5,
        0.5
    ],
    "validation_rate": 0.2,
    "num_items": null,
    "start_index": 1,
    "kwargs": null
}
DEBUG   [02-25 13:31:12] __init__ in DistillSched:
DistillScheduler attribs: teacher tag=teacher_pop, student tag=student_sasrec
INFO    [02-25 13:31:12] dataloader_factory in __init__:
loading processed dataset cache in /data/wushiguang-slurm/code/gitee-repos/soft-rec/Data/Cache/lastfm_small-5-5.pkl
INFO    [02-25 13:31:12] check_dataset_cache in utils:
check if the cache is generated under this configuration
INFO    [02-25 13:31:12] check_dataset_cache in utils:
correct.
INFO    [02-25 13:31:12] __init__ in NextItemDataloader:
there are 3646 items in this dataset, 3173 users, padding_first? False
DEBUG   [02-25 13:31:13] generate_model in utils:
model_code_list=['pop']
INFO    [02-25 13:31:13] load_model_config in utils:
loading model pop's config file at asset/config/model/pop.json
INFO    [02-25 13:31:13] load_model_config in utils:
{}
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/teacher_pop_logs does not exist! Create one.
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/teacher_pop_logs/tb_vis does not exist! Create one.
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/teacher_pop_logs/checkpoint does not exist! Create one.
WARNING [02-25 13:31:18] get_path in utils:
Path is None
WARNING [02-25 13:31:18] load_state_from_given_path in utils:
Not given any path.
DEBUG   [02-25 13:31:18] __init__ in DistillSched:
teacher model: 
POPModel(
  (fake_parameter): Linear(in_features=1, out_features=1, bias=False)
)
INFO    [02-25 13:31:18] assert_model_device in utils:
model teacher_pop has 3.814697265625e-06 MB params.
INFO    [02-25 13:31:18] __init__ in BasicTrainer:
48256 iter per epoch
DEBUG   [02-25 13:31:18] generate_model in utils:
model_code_list=['sasrec']
INFO    [02-25 13:31:18] load_model_config in utils:
loading model sasrec's config file at asset/config/model/sasrec.json
INFO    [02-25 13:31:18] load_model_config in utils:
{
    "n_layers": 2,
    "n_heads": 2,
    "hidden_size": 64,
    "inner_size": 128,
    "hidden_dropout_prob": 0.35,
    "attn_dropout_prob": 0.35,
    "hidden_act": "relu",
    "layer_norm_eps": 1e-12,
    "initializer_range": 0.02,
    "loss_type": "CE"
}
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/student_sasrec_logs does not exist! Create one.
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/student_sasrec_logs/tb_vis does not exist! Create one.
WARNING [02-25 13:31:18] get_exist_path in utils:
dir ___lfms_soft_2022/pop_sasrec-T-9.0-al-0.5_02-25_13:31_t11/student_sasrec_logs/checkpoint does not exist! Create one.
WARNING [02-25 13:31:18] get_path in utils:
Path is None
WARNING [02-25 13:31:18] load_state_from_given_path in utils:
Not given any path.
DEBUG   [02-25 13:31:18] __init__ in DistillSched:
student model: 
SASRecModel(
  (item_embedding): Embedding(3647, 64, padding_idx=0)
  (position_embedding): Embedding(20, 64)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0): TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.35, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.35, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=128, bias=True)
          (dense_2): Linear(in_features=128, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.35, inplace=False)
        )
      )
      (1): TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (attn_dropout): Dropout(p=0.35, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.35, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=128, bias=True)
          (dense_2): Linear(in_features=128, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.35, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.35, inplace=False)
  (loss_fct): CrossEntropyLoss()
)
INFO    [02-25 13:31:18] assert_model_device in utils:
model student_sasrec has 1.151123046875 MB params.
INFO    [02-25 13:31:18] assert_model_device in utils:
model teacher_pop has 3.814697265625e-06 MB params.
INFO    [02-25 13:31:18] __init__ in DistillTrainer:
48256 iter per epoch
INFO    [02-25 13:31:18] _set_current_routine in Routine:
first routine: student
INFO    [02-25 13:31:18] run_routine in Routine:
Start routine student
INFO    [02-25 13:31:18] run_routine in Routine:
Start training
INFO    [02-25 13:31:18] train in DistillTrainer:
Test mentor model: teacher_pop
INFO    [02-25 13:31:21] test_mentor in DistillTrainer:
{'Recall@10': 0.030853040553629398, 'NDCG@10': 0.01389513817615807, 'MRR@10': 0.008818043749779464, 'Recall@5': 0.0165625, 'NDCG@5': 0.009325398094952107, 'MRR@5': 0.006963541805744171, 'Recall*@10': 0.030853040553629398, 'NDCG*@10': 0.01389513817615807, 'MRR*@10': 0.008818043749779464, 'Recall*@5': 0.0165625, 'NDCG*@5': 0.009325398094952107, 'MRR*@5': 0.006963541805744171}
INFO    [02-25 13:31:21] train in DistillTrainer:
result:
{'Recall@10': 0.030853040553629398, 'NDCG@10': 0.01389513817615807, 'MRR@10': 0.008818043749779464, 'Recall@5': 0.0165625, 'NDCG@5': 0.009325398094952107, 'MRR@5': 0.006963541805744171, 'Recall*@10': 0.030853040553629398, 'NDCG*@10': 0.01389513817615807, 'MRR*@10': 0.008818043749779464, 'Recall*@5': 0.0165625, 'NDCG*@5': 0.009325398094952107, 'MRR*@5': 0.006963541805744171}
INFO    [02-25 13:31:24] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [02-25 13:31:24] validate in BasicTrainer:
{'Recall@10': 0.00125, 'NDCG@10': 0.0004349556937813759, 'MRR@10': 0.00019828869495540856, 'Recall@5': 0.0003125, 'NDCG@5': 0.0001208915002644062, 'MRR@5': 6.250000093132258e-05, 'Recall*@10': 0.00125, 'NDCG*@10': 0.0004349556937813759, 'MRR*@10': 0.00019828869495540856, 'Recall*@5': 0.0003125, 'NDCG*@5': 0.0001208915002644062, 'MRR*@5': 6.250000093132258e-05}
INFO    [02-25 13:31:24] train in BasicTrainer:
epoch: 0
DEBUG   [02-25 13:31:25] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 177450
DEBUG   [02-25 13:31:25] calculate_loss in loss:
pred max in softmax: 0.0007701808353886008, argmax 38282
INFO    [02-25 13:31:42] _train_one_epoch in BasicTrainer:
loss = 5.425007796097813
INFO    [02-25 13:31:45] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [02-25 13:31:45] validate in BasicTrainer:
{'Recall@10': 0.061934121698141095, 'NDCG@10': 0.03298019908368587, 'MRR@10': 0.02427807301748544, 'Recall@5': 0.037331081107258794, 'NDCG@5': 0.0250843646004796, 'MRR@5': 0.021054054428823292, 'Recall*@10': 0.061934121698141095, 'NDCG*@10': 0.03298019908368587, 'MRR*@10': 0.02427807301748544, 'Recall*@5': 0.037331081107258794, 'NDCG*@5': 0.0250843646004796, 'MRR*@5': 0.021054054428823292}
INFO    [02-25 13:31:45] train in BasicTrainer:
duration: 21.34281039237976s
INFO    [02-25 13:31:45] train in BasicTrainer:
epoch: 1
DEBUG   [02-25 13:31:52] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 111804
DEBUG   [02-25 13:31:52] calculate_loss in loss:
pred max in softmax: 0.0667356476187706, argmax 110280
DEBUG   [02-25 13:31:52] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 99067
DEBUG   [02-25 13:31:52] calculate_loss in loss:
pred max in softmax: 0.044892776757478714, argmax 175926
INFO    [02-25 13:32:04] _train_one_epoch in BasicTrainer:
loss = 4.911649265086935
INFO    [02-25 13:32:07] log in loggers:
Update Best NDCG@10 Model at 1
INFO    [02-25 13:32:07] validate in BasicTrainer:
{'Recall@10': 0.1382432433962822, 'NDCG@10': 0.07255212903022766, 'MRR@10': 0.052814538646489384, 'Recall@5': 0.08684966221451759, 'NDCG@5': 0.056271227486431596, 'MRR@5': 0.046293356530368326, 'Recall*@10': 0.1382432433962822, 'NDCG*@10': 0.07255212903022766, 'MRR*@10': 0.052814538646489384, 'Recall*@5': 0.08684966221451759, 'NDCG*@5': 0.056271227486431596, 'MRR*@5': 0.046293356530368326}
INFO    [02-25 13:32:07] train in BasicTrainer:
duration: 21.25495147705078s
INFO    [02-25 13:32:07] train in BasicTrainer:
epoch: 2
DEBUG   [02-25 13:32:19] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 193889
DEBUG   [02-25 13:32:19] calculate_loss in loss:
pred max in softmax: 0.1179310604929924, argmax 127513
DEBUG   [02-25 13:32:19] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 37068
DEBUG   [02-25 13:32:19] calculate_loss in loss:
pred max in softmax: 0.09352733939886093, argmax 34455
INFO    [02-25 13:32:25] _train_one_epoch in BasicTrainer:
loss = 4.597065579669861
INFO    [02-25 13:32:28] log in loggers:
Update Best NDCG@10 Model at 2
INFO    [02-25 13:32:28] validate in BasicTrainer:
{'Recall@10': 0.1643496622145176, 'NDCG@10': 0.09311106398701668, 'MRR@10': 0.07149275794625282, 'Recall@5': 0.1113091216981411, 'NDCG@5': 0.07608420863747596, 'MRR@5': 0.0645396976172924, 'Recall*@10': 0.1643496622145176, 'NDCG*@10': 0.09311106398701668, 'MRR*@10': 0.07149275794625282, 'Recall*@5': 0.1113091216981411, 'NDCG*@5': 0.07608420863747596, 'MRR*@5': 0.0645396976172924}
INFO    [02-25 13:32:28] train in BasicTrainer:
duration: 21.200974225997925s
INFO    [02-25 13:32:28] train in BasicTrainer:
epoch: 3
DEBUG   [02-25 13:32:46] calculate_loss in loss:
soft_target max: 0.5002565979957581, argmax 12484
DEBUG   [02-25 13:32:46] calculate_loss in loss:
pred max in softmax: 0.15809476375579834, argmax 229579
DEBUG   [02-25 13:32:46] calculate_loss in loss:
soft_target max: 0.5002753734588623, argmax 133318
DEBUG   [02-25 13:32:46] calculate_loss in loss:
pred max in softmax: 0.15253610908985138, argmax 163386
INFO    [02-25 13:32:46] _train_one_epoch in BasicTrainer:
loss = 4.412883411668024
INFO    [02-25 13:32:49] log in loggers:
Update Best NDCG@10 Model at 3
INFO    [02-25 13:32:49] validate in BasicTrainer:
{'Recall@10': 0.1786402028799057, 'NDCG@10': 0.10185676246881485, 'MRR@10': 0.07839469470083714, 'Recall@5': 0.1245777028799057, 'NDCG@5': 0.08439851142466068, 'MRR@5': 0.07120397176593542, 'Recall*@10': 0.1786402028799057, 'NDCG*@10': 0.10185676246881485, 'MRR*@10': 0.07839469470083714, 'Recall*@5': 0.1245777028799057, 'NDCG*@5': 0.08439851142466068, 'MRR*@5': 0.07120397176593542}
INFO    [02-25 13:32:49] train in BasicTrainer:
duration: 21.110548973083496s
INFO    [02-25 13:32:49] train in BasicTrainer:
epoch: 4
INFO    [02-25 13:33:07] _train_one_epoch in BasicTrainer:
loss = 4.303982034286074
INFO    [02-25 13:33:10] log in loggers:
Update Best NDCG@10 Model at 4
INFO    [02-25 13:33:10] validate in BasicTrainer:
{'Recall@10': 0.1819932433962822, 'NDCG@10': 0.1065238270163536, 'MRR@10': 0.0833506652712822, 'Recall@5': 0.12989020287990571, 'NDCG@5': 0.08972421526908875, 'MRR@5': 0.0764469338953495, 'Recall*@10': 0.1819932433962822, 'NDCG*@10': 0.1065238270163536, 'MRR*@10': 0.0833506652712822, 'Recall*@5': 0.12989020287990571, 'NDCG*@5': 0.08972421526908875, 'MRR*@5': 0.0764469338953495}
INFO    [02-25 13:33:10] train in BasicTrainer:
duration: 21.201669216156006s
INFO    [02-25 13:33:10] train in BasicTrainer:
epoch: 5
DEBUG   [02-25 13:33:16] calculate_loss in loss:
soft_target max: 0.5002579689025879, argmax 162931
DEBUG   [02-25 13:33:16] calculate_loss in loss:
pred max in softmax: 0.1342456042766571, argmax 206956
DEBUG   [02-25 13:33:16] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 170156
DEBUG   [02-25 13:33:16] calculate_loss in loss:
pred max in softmax: 0.3078429102897644, argmax 202671
INFO    [02-25 13:33:29] _train_one_epoch in BasicTrainer:
loss = 4.228736653252053
INFO    [02-25 13:33:31] log in loggers:
Update Best NDCG@10 Model at 5
INFO    [02-25 13:33:31] validate in BasicTrainer:
{'Recall@10': 0.19153716221451758, 'NDCG@10': 0.11051224149763585, 'MRR@10': 0.08584468580782413, 'Recall@5': 0.13028716221451758, 'NDCG@5': 0.09058226354420185, 'MRR@5': 0.0775474389642477, 'Recall*@10': 0.19153716221451758, 'NDCG*@10': 0.11051224149763585, 'MRR*@10': 0.08584468580782413, 'Recall*@5': 0.13028716221451758, 'NDCG*@5': 0.09058226354420185, 'MRR*@5': 0.0775474389642477}
INFO    [02-25 13:33:31] train in BasicTrainer:
duration: 21.167675256729126s
INFO    [02-25 13:33:31] train in BasicTrainer:
epoch: 6
DEBUG   [02-25 13:33:43] calculate_loss in loss:
soft_target max: 0.5003243088722229, argmax 53979
DEBUG   [02-25 13:33:43] calculate_loss in loss:
pred max in softmax: 0.2060145139694214, argmax 173092
DEBUG   [02-25 13:33:43] calculate_loss in loss:
soft_target max: 0.5003190040588379, argmax 61817
DEBUG   [02-25 13:33:43] calculate_loss in loss:
pred max in softmax: 0.18498678505420685, argmax 70770
INFO    [02-25 13:33:50] _train_one_epoch in BasicTrainer:
loss = 4.175747603257076
INFO    [02-25 13:33:52] log in loggers:
Update Best NDCG@10 Model at 6
INFO    [02-25 13:33:52] validate in BasicTrainer:
{'Recall@10': 0.1990118244290352, 'NDCG@10': 0.1162165255099535, 'MRR@10': 0.09101904101669789, 'Recall@5': 0.13934966221451758, 'NDCG@5': 0.09703801535069942, 'MRR@5': 0.083167935423553, 'Recall*@10': 0.1990118244290352, 'NDCG*@10': 0.1162165255099535, 'MRR*@10': 0.09101904101669789, 'Recall*@5': 0.13934966221451758, 'NDCG*@5': 0.09703801535069942, 'MRR*@5': 0.083167935423553}
INFO    [02-25 13:33:52] train in BasicTrainer:
duration: 21.01036262512207s
INFO    [02-25 13:33:52] train in BasicTrainer:
epoch: 7
DEBUG   [02-25 13:34:10] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 175654
DEBUG   [02-25 13:34:10] calculate_loss in loss:
pred max in softmax: 0.19449259340763092, argmax 171897
DEBUG   [02-25 13:34:10] calculate_loss in loss:
soft_target max: 0.5003260374069214, argmax 13311
DEBUG   [02-25 13:34:10] calculate_loss in loss:
pred max in softmax: 0.259330689907074, argmax 86336
INFO    [02-25 13:34:11] _train_one_epoch in BasicTrainer:
loss = 4.131464482302375
INFO    [02-25 13:34:13] log in loggers:
Update Best NDCG@10 Model at 7
INFO    [02-25 13:34:13] validate in BasicTrainer:
{'Recall@10': 0.20105574339628218, 'NDCG@10': 0.11738819219172, 'MRR@10': 0.09169229753315448, 'Recall@5': 0.1455996622145176, 'NDCG@5': 0.09953676119446754, 'MRR@5': 0.08437091957777738, 'Recall*@10': 0.20105574339628218, 'NDCG*@10': 0.11738819219172, 'MRR*@10': 0.09169229753315448, 'Recall*@5': 0.1455996622145176, 'NDCG*@5': 0.09953676119446754, 'MRR*@5': 0.08437091957777738}
INFO    [02-25 13:34:13] train in BasicTrainer:
duration: 21.131750106811523s
INFO    [02-25 13:34:13] train in BasicTrainer:
epoch: 8
INFO    [02-25 13:34:32] _train_one_epoch in BasicTrainer:
loss = 4.103509991491505
INFO    [02-25 13:34:35] log in loggers:
Update Best NDCG@10 Model at 8
INFO    [02-25 13:34:35] validate in BasicTrainer:
{'Recall@10': 0.20105574339628218, 'NDCG@10': 0.11857296898961067, 'MRR@10': 0.09334817484021186, 'Recall@5': 0.1417060811072588, 'NDCG@5': 0.0994444603472948, 'MRR@5': 0.08549155432730914, 'Recall*@10': 0.20105574339628218, 'NDCG*@10': 0.11857296898961067, 'MRR*@10': 0.09334817484021186, 'Recall*@5': 0.1417060811072588, 'NDCG*@5': 0.0994444603472948, 'MRR*@5': 0.08549155432730914}
INFO    [02-25 13:34:35] train in BasicTrainer:
duration: 21.169889450073242s
INFO    [02-25 13:34:35] train in BasicTrainer:
epoch: 9
DEBUG   [02-25 13:34:40] calculate_loss in loss:
soft_target max: 0.5003243088722229, argmax 68567
DEBUG   [02-25 13:34:40] calculate_loss in loss:
pred max in softmax: 0.31644412875175476, argmax 74638
DEBUG   [02-25 13:34:40] calculate_loss in loss:
soft_target max: 0.5003243088722229, argmax 210800
DEBUG   [02-25 13:34:40] calculate_loss in loss:
pred max in softmax: 0.3244018852710724, argmax 6827
INFO    [02-25 13:34:53] _train_one_epoch in BasicTrainer:
loss = 4.0772434811377085
INFO    [02-25 13:34:56] log in loggers:
Update Best NDCG@10 Model at 9
INFO    [02-25 13:34:56] validate in BasicTrainer:
{'Recall@10': 0.20565878391265868, 'NDCG@10': 0.11899688385426999, 'MRR@10': 0.09257340349256993, 'Recall@5': 0.1437837839126587, 'NDCG@5': 0.09898165114223957, 'MRR@5': 0.0843113749474287, 'Recall*@10': 0.20565878391265868, 'NDCG*@10': 0.11899688385426999, 'MRR*@10': 0.09257340349256993, 'Recall*@5': 0.1437837839126587, 'NDCG*@5': 0.09898165114223957, 'MRR*@5': 0.0843113749474287}
INFO    [02-25 13:34:56] train in BasicTrainer:
duration: 21.51257634162903s
INFO    [02-25 13:34:56] train in BasicTrainer:
epoch: 10
DEBUG   [02-25 13:35:08] calculate_loss in loss:
soft_target max: 0.5002814531326294, argmax 32707
DEBUG   [02-25 13:35:08] calculate_loss in loss:
pred max in softmax: 0.1495290845632553, argmax 2635
DEBUG   [02-25 13:35:08] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 88126
DEBUG   [02-25 13:35:08] calculate_loss in loss:
pred max in softmax: 0.3263727128505707, argmax 232071
INFO    [02-25 13:35:15] _train_one_epoch in BasicTrainer:
loss = 4.050133102768612
INFO    [02-25 13:35:17] log in loggers:
Update Best NDCG@10 Model at 10
INFO    [02-25 13:35:17] validate in BasicTrainer:
{'Recall@10': 0.21472128391265868, 'NDCG@10': 0.12377972304821014, 'MRR@10': 0.09603980027139186, 'Recall@5': 0.1485557433962822, 'NDCG@5': 0.10237437590956688, 'MRR@5': 0.08720129556953907, 'Recall*@10': 0.21472128391265868, 'NDCG*@10': 0.12377972304821014, 'MRR*@10': 0.09603980027139186, 'Recall*@5': 0.1485557433962822, 'NDCG*@5': 0.10237437590956688, 'MRR*@5': 0.08720129556953907}
INFO    [02-25 13:35:17] train in BasicTrainer:
duration: 21.309200048446655s
INFO    [02-25 13:35:17] train in BasicTrainer:
epoch: 11
DEBUG   [02-25 13:35:35] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 82628
DEBUG   [02-25 13:35:35] calculate_loss in loss:
pred max in softmax: 0.24318894743919373, argmax 161394
DEBUG   [02-25 13:35:35] calculate_loss in loss:
soft_target max: 0.5003798007965088, argmax 99695
DEBUG   [02-25 13:35:35] calculate_loss in loss:
pred max in softmax: 0.17699643969535828, argmax 176761
INFO    [02-25 13:35:36] _train_one_epoch in BasicTrainer:
loss = 4.03047721771726
INFO    [02-25 13:35:39] validate in BasicTrainer:
{'Recall@10': 0.21668074339628218, 'NDCG@10': 0.12297815203666687, 'MRR@10': 0.09429799921810628, 'Recall@5': 0.1540371622145176, 'NDCG@5': 0.10293374821543694, 'MRR@5': 0.08614822804927826, 'Recall*@10': 0.21668074339628218, 'NDCG*@10': 0.12297815203666687, 'MRR*@10': 0.09429799921810628, 'Recall*@5': 0.1540371622145176, 'NDCG*@5': 0.10293374821543694, 'MRR*@5': 0.08614822804927826}
INFO    [02-25 13:35:39] train in BasicTrainer:
duration: 21.169358253479004s
INFO    [02-25 13:35:39] train in BasicTrainer:
epoch: 12
INFO    [02-25 13:35:57] _train_one_epoch in BasicTrainer:
loss = 4.018993772309402
INFO    [02-25 13:36:00] validate in BasicTrainer:
{'Recall@10': 0.2119932433962822, 'NDCG@10': 0.12186734423041344, 'MRR@10': 0.09438653707504273, 'Recall@5': 0.1469932433962822, 'NDCG@5': 0.10101876616477966, 'MRR@5': 0.08588232114911079, 'Recall*@10': 0.2119932433962822, 'NDCG*@10': 0.12186734423041344, 'MRR*@10': 0.09438653707504273, 'Recall*@5': 0.1469932433962822, 'NDCG*@5': 0.10101876616477966, 'MRR*@5': 0.08588232114911079}
INFO    [02-25 13:36:00] train in BasicTrainer:
duration: 21.112362384796143s
INFO    [02-25 13:36:00] train in BasicTrainer:
epoch: 13
DEBUG   [02-25 13:36:05] calculate_loss in loss:
soft_target max: 0.5003243088722229, argmax 83155
DEBUG   [02-25 13:36:05] calculate_loss in loss:
pred max in softmax: 0.2834009826183319, argmax 195999
DEBUG   [02-25 13:36:05] calculate_loss in loss:
soft_target max: 0.5002579689025879, argmax 177519
DEBUG   [02-25 13:36:05] calculate_loss in loss:
pred max in softmax: 0.3257587254047394, argmax 49785
INFO    [02-25 13:36:18] _train_one_epoch in BasicTrainer:
loss = 3.9983147417518756
INFO    [02-25 13:36:21] validate in BasicTrainer:
{'Recall@10': 0.2085557433962822, 'NDCG@10': 0.12020897530019284, 'MRR@10': 0.09310084283351898, 'Recall@5': 0.14841216221451758, 'NDCG@5': 0.10069855622947216, 'MRR@5': 0.08500816598534584, 'Recall*@10': 0.2085557433962822, 'NDCG*@10': 0.12020897530019284, 'MRR*@10': 0.09310084283351898, 'Recall*@5': 0.14841216221451758, 'NDCG*@5': 0.10069855622947216, 'MRR*@5': 0.08500816598534584}
INFO    [02-25 13:36:21] train in BasicTrainer:
duration: 20.983335733413696s
INFO    [02-25 13:36:21] train in BasicTrainer:
epoch: 14
DEBUG   [02-25 13:36:32] calculate_loss in loss:
soft_target max: 0.5001891255378723, argmax 196906
DEBUG   [02-25 13:36:32] calculate_loss in loss:
pred max in softmax: 0.24895623326301575, argmax 36230
DEBUG   [02-25 13:36:32] calculate_loss in loss:
soft_target max: 0.5003260374069214, argmax 115427
DEBUG   [02-25 13:36:32] calculate_loss in loss:
pred max in softmax: 0.4885750710964203, argmax 174995
INFO    [02-25 13:36:39] _train_one_epoch in BasicTrainer:
loss = 3.983480223610167
INFO    [02-25 13:36:42] validate in BasicTrainer:
{'Recall@10': 0.21222128391265868, 'NDCG@10': 0.12367513529956341, 'MRR@10': 0.09654392033815384, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10487662553787232, 'MRR@5': 0.08882756412029266, 'Recall*@10': 0.21222128391265868, 'NDCG*@10': 0.12367513529956341, 'MRR*@10': 0.09654392033815384, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10487662553787232, 'MRR*@5': 0.08882756412029266}
INFO    [02-25 13:36:42] train in BasicTrainer:
duration: 21.128283500671387s
INFO    [02-25 13:36:42] train in BasicTrainer:
epoch: 15
DEBUG   [02-25 13:36:59] calculate_loss in loss:
soft_target max: 0.5003798007965088, argmax 66872
DEBUG   [02-25 13:36:59] calculate_loss in loss:
pred max in softmax: 0.2531318664550781, argmax 181760
DEBUG   [02-25 13:36:59] calculate_loss in loss:
soft_target max: 0.5002622008323669, argmax 194047
DEBUG   [02-25 13:36:59] calculate_loss in loss:
pred max in softmax: 0.26375821232795715, argmax 127801
INFO    [02-25 13:37:00] _train_one_epoch in BasicTrainer:
loss = 3.971048509410585
INFO    [02-25 13:37:03] validate in BasicTrainer:
{'Recall@10': 0.2112837839126587, 'NDCG@10': 0.12155339747667313, 'MRR@10': 0.09411962196230889, 'Recall@5': 0.14636824339628218, 'NDCG@5': 0.10047976054251194, 'MRR@5': 0.08537218637764454, 'Recall*@10': 0.2112837839126587, 'NDCG*@10': 0.12155339747667313, 'MRR*@10': 0.09411962196230889, 'Recall*@5': 0.14636824339628218, 'NDCG*@5': 0.10047976054251194, 'MRR*@5': 0.08537218637764454}
INFO    [02-25 13:37:03] train in BasicTrainer:
duration: 21.086400985717773s
INFO    [02-25 13:37:03] train in BasicTrainer:
epoch: 16
INFO    [02-25 13:37:21] _train_one_epoch in BasicTrainer:
loss = 3.953294717980949
INFO    [02-25 13:37:24] validate in BasicTrainer:
{'Recall@10': 0.2128462839126587, 'NDCG@10': 0.1212503106892109, 'MRR@10': 0.09311150163412094, 'Recall@5': 0.15543074339628218, 'NDCG@5': 0.1027733512967825, 'MRR@5': 0.08553730495274067, 'Recall*@10': 0.2128462839126587, 'NDCG*@10': 0.1212503106892109, 'MRR*@10': 0.09311150163412094, 'Recall*@5': 0.15543074339628218, 'NDCG*@5': 0.1027733512967825, 'MRR*@5': 0.08553730495274067}
INFO    [02-25 13:37:24] train in BasicTrainer:
duration: 21.04796576499939s
INFO    [02-25 13:37:24] train in BasicTrainer:
epoch: 17
DEBUG   [02-25 13:37:29] calculate_loss in loss:
soft_target max: 0.5002579689025879, argmax 115520
DEBUG   [02-25 13:37:29] calculate_loss in loss:
pred max in softmax: 0.3336253762245178, argmax 222774
DEBUG   [02-25 13:37:29] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 84479
DEBUG   [02-25 13:37:29] calculate_loss in loss:
pred max in softmax: 0.4079015254974365, argmax 154466
INFO    [02-25 13:37:42] _train_one_epoch in BasicTrainer:
loss = 3.9473401118336686
INFO    [02-25 13:37:45] validate in BasicTrainer:
{'Recall@10': 0.2098057433962822, 'NDCG@10': 0.12370041556656361, 'MRR@10': 0.09731276884675026, 'Recall@5': 0.1507432433962822, 'NDCG@5': 0.10465747721493245, 'MRR@5': 0.08948662906885146, 'Recall*@10': 0.2098057433962822, 'NDCG*@10': 0.12370041556656361, 'MRR*@10': 0.09731276884675026, 'Recall*@5': 0.1507432433962822, 'NDCG*@5': 0.10465747721493245, 'MRR*@5': 0.08948662906885146}
INFO    [02-25 13:37:45] train in BasicTrainer:
duration: 21.04261302947998s
INFO    [02-25 13:37:45] train in BasicTrainer:
epoch: 18
DEBUG   [02-25 13:37:56] calculate_loss in loss:
soft_target max: 0.5003260374069214, argmax 140956
DEBUG   [02-25 13:37:56] calculate_loss in loss:
pred max in softmax: 0.3277897238731384, argmax 124037
DEBUG   [02-25 13:37:56] calculate_loss in loss:
soft_target max: 0.500251054763794, argmax 11559
DEBUG   [02-25 13:37:56] calculate_loss in loss:
pred max in softmax: 0.34230750799179077, argmax 135803
INFO    [02-25 13:38:03] _train_one_epoch in BasicTrainer:
loss = 3.93833458265512
INFO    [02-25 13:38:06] log in loggers:
Update Best NDCG@10 Model at 18
INFO    [02-25 13:38:06] validate in BasicTrainer:
{'Recall@10': 0.2116807433962822, 'NDCG@10': 0.12423850104212761, 'MRR@10': 0.09738409817218781, 'Recall@5': 0.1563682433962822, 'NDCG@5': 0.10647229067981243, 'MRR@5': 0.0901212015002966, 'Recall*@10': 0.2116807433962822, 'NDCG*@10': 0.12423850104212761, 'MRR*@10': 0.09738409817218781, 'Recall*@5': 0.1563682433962822, 'NDCG*@5': 0.10647229067981243, 'MRR*@5': 0.0901212015002966}
INFO    [02-25 13:38:06] train in BasicTrainer:
duration: 21.362274408340454s
INFO    [02-25 13:38:06] train in BasicTrainer:
epoch: 19
DEBUG   [02-25 13:38:23] calculate_loss in loss:
soft_target max: 0.5003260374069214, argmax 221190
DEBUG   [02-25 13:38:23] calculate_loss in loss:
pred max in softmax: 0.31426411867141724, argmax 172635
DEBUG   [02-25 13:38:23] calculate_loss in loss:
soft_target max: 0.5002814531326294, argmax 61883
DEBUG   [02-25 13:38:23] calculate_loss in loss:
pred max in softmax: 0.29534775018692017, argmax 1922
INFO    [02-25 13:38:25] _train_one_epoch in BasicTrainer:
loss = 3.9241061605888587
INFO    [02-25 13:38:28] log in loggers:
Update Best NDCG@10 Model at 19
INFO    [02-25 13:38:28] validate in BasicTrainer:
{'Recall@10': 0.2151182433962822, 'NDCG@10': 0.1259275996685028, 'MRR@10': 0.0986222730576992, 'Recall@5': 0.1529307433962822, 'NDCG@5': 0.10587100051343441, 'MRR@5': 0.09037500232458115, 'Recall*@10': 0.2151182433962822, 'NDCG*@10': 0.1259275996685028, 'MRR*@10': 0.0986222730576992, 'Recall*@5': 0.1529307433962822, 'NDCG*@5': 0.10587100051343441, 'MRR*@5': 0.09037500232458115}
INFO    [02-25 13:38:28] train in BasicTrainer:
duration: 21.26643681526184s
INFO    [02-25 13:38:28] train in BasicTrainer:
epoch: 20
INFO    [02-25 13:38:46] _train_one_epoch in BasicTrainer:
loss = 3.917934521756058
INFO    [02-25 13:38:49] validate in BasicTrainer:
{'Recall@10': 0.21401182442903519, 'NDCG@10': 0.12526494406163693, 'MRR@10': 0.09809286683797837, 'Recall@5': 0.1557432433962822, 'NDCG@5': 0.10656617753207684, 'MRR@5': 0.09045608252286912, 'Recall*@10': 0.21401182442903519, 'NDCG*@10': 0.12526494406163693, 'MRR*@10': 0.09809286683797837, 'Recall*@5': 0.1557432433962822, 'NDCG*@5': 0.10656617753207684, 'MRR*@5': 0.09045608252286912}
INFO    [02-25 13:38:49] train in BasicTrainer:
duration: 21.233494520187378s
INFO    [02-25 13:38:49] train in BasicTrainer:
epoch: 21
DEBUG   [02-25 13:38:53] calculate_loss in loss:
soft_target max: 0.5003798007965088, argmax 158047
DEBUG   [02-25 13:38:53] calculate_loss in loss:
pred max in softmax: 0.5054266452789307, argmax 34534
DEBUG   [02-25 13:38:53] calculate_loss in loss:
soft_target max: 0.5003798007965088, argmax 172635
DEBUG   [02-25 13:38:53] calculate_loss in loss:
pred max in softmax: 0.32013702392578125, argmax 151114
INFO    [02-25 13:39:07] _train_one_epoch in BasicTrainer:
loss = 3.907294434324816
INFO    [02-25 13:39:10] validate in BasicTrainer:
{'Recall@10': 0.2153462839126587, 'NDCG@10': 0.12482371479272843, 'MRR@10': 0.09712725058197975, 'Recall@5': 0.1529307433962822, 'NDCG@5': 0.10470910087227821, 'MRR@5': 0.08886796355247498, 'Recall*@10': 0.2153462839126587, 'NDCG*@10': 0.12482371479272843, 'MRR*@10': 0.09712725058197975, 'Recall*@5': 0.1529307433962822, 'NDCG*@5': 0.10470910087227821, 'MRR*@5': 0.08886796355247498}
INFO    [02-25 13:39:10] train in BasicTrainer:
duration: 21.075629472732544s
INFO    [02-25 13:39:10] train in BasicTrainer:
epoch: 22
DEBUG   [02-25 13:39:20] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 75334
DEBUG   [02-25 13:39:20] calculate_loss in loss:
pred max in softmax: 0.2742665708065033, argmax 135298
DEBUG   [02-25 13:39:20] calculate_loss in loss:
soft_target max: 0.5003368854522705, argmax 172007
DEBUG   [02-25 13:39:20] calculate_loss in loss:
pred max in softmax: 0.26870664954185486, argmax 30771
INFO    [02-25 13:39:28] _train_one_epoch in BasicTrainer:
loss = 3.9047953560750743
INFO    [02-25 13:39:31] validate in BasicTrainer:
{'Recall@10': 0.2163682433962822, 'NDCG@10': 0.12520954579114915, 'MRR@10': 0.09725347101688385, 'Recall@5': 0.1532432433962822, 'NDCG@5': 0.10475908987224102, 'MRR@5': 0.08879476547241211, 'Recall*@10': 0.2163682433962822, 'NDCG*@10': 0.12520954579114915, 'MRR*@10': 0.09725347101688385, 'Recall*@5': 0.1532432433962822, 'NDCG*@5': 0.10475908987224102, 'MRR*@5': 0.08879476547241211}
INFO    [02-25 13:39:31] train in BasicTrainer:
duration: 21.436685800552368s
INFO    [02-25 13:39:31] train in BasicTrainer:
epoch: 23
DEBUG   [02-25 13:39:48] calculate_loss in loss:
soft_target max: 0.5003190040588379, argmax 69111
DEBUG   [02-25 13:39:48] calculate_loss in loss:
pred max in softmax: 0.3181556463241577, argmax 94449
DEBUG   [02-25 13:39:48] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 82628
DEBUG   [02-25 13:39:48] calculate_loss in loss:
pred max in softmax: 0.3214088976383209, argmax 113906
INFO    [02-25 13:39:50] _train_one_epoch in BasicTrainer:
loss = 3.8933897812107197
INFO    [02-25 13:39:53] validate in BasicTrainer:
{'Recall@10': 0.21261824339628219, 'NDCG@10': 0.12362138710916043, 'MRR@10': 0.09641354240477085, 'Recall@5': 0.1504307433962822, 'NDCG@5': 0.10351059652864933, 'MRR@5': 0.08811331905424595, 'Recall*@10': 0.21261824339628219, 'NDCG*@10': 0.12362138710916043, 'MRR*@10': 0.09641354240477085, 'Recall*@5': 0.1504307433962822, 'NDCG*@5': 0.10351059652864933, 'MRR*@5': 0.08811331905424595}
INFO    [02-25 13:39:53] train in BasicTrainer:
duration: 21.60909628868103s
INFO    [02-25 13:39:53] train in BasicTrainer:
epoch: 24
INFO    [02-25 13:40:12] _train_one_epoch in BasicTrainer:
loss = 3.8872809160293254
INFO    [02-25 13:40:15] log in loggers:
Update Best NDCG@10 Model at 24
INFO    [02-25 13:40:15] validate in BasicTrainer:
{'Recall@10': 0.2197212839126587, 'NDCG@10': 0.12705757051706315, 'MRR@10': 0.09880491062998771, 'Recall@5': 0.1545777028799057, 'NDCG@5': 0.1061444578319788, 'MRR@5': 0.09026224806904792, 'Recall*@10': 0.2197212839126587, 'NDCG*@10': 0.12705757051706315, 'MRR*@10': 0.09880491062998771, 'Recall*@5': 0.1545777028799057, 'NDCG*@5': 0.1061444578319788, 'MRR*@5': 0.09026224806904792}
INFO    [02-25 13:40:15] train in BasicTrainer:
duration: 22.037676095962524s
INFO    [02-25 13:40:15] train in BasicTrainer:
epoch: 25
DEBUG   [02-25 13:40:19] calculate_loss in loss:
soft_target max: 0.500251054763794, argmax 45404
DEBUG   [02-25 13:40:19] calculate_loss in loss:
pred max in softmax: 0.5096564888954163, argmax 186487
DEBUG   [02-25 13:40:19] calculate_loss in loss:
soft_target max: 0.5003576874732971, argmax 86275
DEBUG   [02-25 13:40:19] calculate_loss in loss:
pred max in softmax: 0.22685326635837555, argmax 42975
INFO    [02-25 13:40:34] _train_one_epoch in BasicTrainer:
loss = 3.8823633209779977
INFO    [02-25 13:40:37] validate in BasicTrainer:
{'Recall@10': 0.2209712839126587, 'NDCG@10': 0.12519877329468726, 'MRR@10': 0.09591978877782821, 'Recall@5': 0.1551182433962822, 'NDCG@5': 0.10401660814881325, 'MRR@5': 0.08724507495760918, 'Recall*@10': 0.2209712839126587, 'NDCG*@10': 0.12519877329468726, 'MRR*@10': 0.09591978877782821, 'Recall*@5': 0.1551182433962822, 'NDCG*@5': 0.10401660814881325, 'MRR*@5': 0.08724507495760918}
INFO    [02-25 13:40:37] train in BasicTrainer:
duration: 21.702149152755737s
INFO    [02-25 13:40:37] train in BasicTrainer:
epoch: 26
DEBUG   [02-25 13:40:47] calculate_loss in loss:
soft_target max: 0.5003798007965088, argmax 26755
DEBUG   [02-25 13:40:47] calculate_loss in loss:
pred max in softmax: 0.3417048156261444, argmax 53436
INFO    [02-25 13:40:56] _train_one_epoch in BasicTrainer:
loss = 3.88038445847104
INFO    [02-25 13:40:58] validate in BasicTrainer:
{'Recall@10': 0.2163682433962822, 'NDCG@10': 0.12694595515727997, 'MRR@10': 0.09959776617586613, 'Recall@5': 0.1551182433962822, 'NDCG@5': 0.10711335755884648, 'MRR@5': 0.09139414571225643, 'Recall*@10': 0.2163682433962822, 'NDCG*@10': 0.12694595515727997, 'MRR*@10': 0.09959776617586613, 'Recall*@5': 0.1551182433962822, 'NDCG*@5': 0.10711335755884648, 'MRR*@5': 0.09139414571225643}
INFO    [02-25 13:40:58] train in BasicTrainer:
duration: 21.681772470474243s
INFO    [02-25 13:40:58] train in BasicTrainer:
epoch: 27
INFO    [02-25 13:41:17] _train_one_epoch in BasicTrainer:
loss = 3.8686780268696954
INFO    [02-25 13:41:20] validate in BasicTrainer:
{'Recall@10': 0.2194932433962822, 'NDCG@10': 0.1267382998764515, 'MRR@10': 0.09836337126791478, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10536246553063393, 'MRR@5': 0.08944918550550937, 'Recall*@10': 0.2194932433962822, 'NDCG*@10': 0.1267382998764515, 'MRR*@10': 0.09836337126791478, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10536246553063393, 'MRR*@5': 0.08944918550550937}
INFO    [02-25 13:41:20] train in BasicTrainer:
duration: 21.84548544883728s
INFO    [02-25 13:41:20] train in BasicTrainer:
epoch: 28
INFO    [02-25 13:41:40] _train_one_epoch in BasicTrainer:
loss = 3.8619274925489955
INFO    [02-25 13:41:42] log in loggers:
Update Best NDCG@10 Model at 28
INFO    [02-25 13:41:42] validate in BasicTrainer:
{'Recall@10': 0.2219932433962822, 'NDCG@10': 0.12774651885032653, 'MRR@10': 0.09895312272012234, 'Recall@5': 0.15543074339628218, 'NDCG@5': 0.10622230418026447, 'MRR@5': 0.09007080674171447, 'Recall*@10': 0.2219932433962822, 'NDCG*@10': 0.12774651885032653, 'MRR*@10': 0.09895312272012234, 'Recall*@5': 0.15543074339628218, 'NDCG*@5': 0.10622230418026447, 'MRR*@5': 0.09007080674171447}
INFO    [02-25 13:41:42] train in BasicTrainer:
duration: 22.16188645362854s
INFO    [02-25 13:41:42] train in BasicTrainer:
epoch: 29
INFO    [02-25 13:42:01] _train_one_epoch in BasicTrainer:
loss = 3.858228529796044
INFO    [02-25 13:42:03] log in loggers:
Update Best NDCG@10 Model at 29
INFO    [02-25 13:42:04] validate in BasicTrainer:
{'Recall@10': 0.22503378391265869, 'NDCG@10': 0.13114468708634378, 'MRR@10': 0.10262958690524102, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10834007300436496, 'MRR@5': 0.09334234401583671, 'Recall*@10': 0.22503378391265869, 'NDCG*@10': 0.13114468708634378, 'MRR*@10': 0.10262958690524102, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10834007300436496, 'MRR*@5': 0.09334234401583671}
INFO    [02-25 13:42:04] train in BasicTrainer:
duration: 21.123379230499268s
INFO    [02-25 13:42:04] train in BasicTrainer:
epoch: 30
INFO    [02-25 13:42:22] _train_one_epoch in BasicTrainer:
loss = 3.850222953750853
INFO    [02-25 13:42:25] validate in BasicTrainer:
{'Recall@10': 0.2151182433962822, 'NDCG@10': 0.1263642653822899, 'MRR@10': 0.09920901522040367, 'Recall@5': 0.1516807433962822, 'NDCG@5': 0.1059234604984522, 'MRR@5': 0.09081405021250248, 'Recall*@10': 0.2151182433962822, 'NDCG*@10': 0.1263642653822899, 'MRR*@10': 0.09920901522040367, 'Recall*@5': 0.1516807433962822, 'NDCG*@5': 0.1059234604984522, 'MRR*@5': 0.09081405021250248}
INFO    [02-25 13:42:25] train in BasicTrainer:
duration: 21.164085388183594s
INFO    [02-25 13:42:25] train in BasicTrainer:
epoch: 31
INFO    [02-25 13:42:43] _train_one_epoch in BasicTrainer:
loss = 3.8445321795794944
INFO    [02-25 13:42:46] validate in BasicTrainer:
{'Recall@10': 0.2138682433962822, 'NDCG@10': 0.12568141996860505, 'MRR@10': 0.098702891767025, 'Recall@5': 0.1523057433962822, 'NDCG@5': 0.10590963788330555, 'MRR@5': 0.0906230304017663, 'Recall*@10': 0.2138682433962822, 'NDCG*@10': 0.12568141996860505, 'MRR*@10': 0.098702891767025, 'Recall*@5': 0.1523057433962822, 'NDCG*@5': 0.10590963788330555, 'MRR*@5': 0.0906230304017663}
INFO    [02-25 13:42:46] train in BasicTrainer:
duration: 21.12587857246399s
INFO    [02-25 13:42:46] train in BasicTrainer:
epoch: 32
INFO    [02-25 13:43:04] _train_one_epoch in BasicTrainer:
loss = 3.84330886934417
INFO    [02-25 13:43:07] validate in BasicTrainer:
{'Recall@10': 0.2157432433962822, 'NDCG@10': 0.12568710163235663, 'MRR@10': 0.09819320511072874, 'Recall@5': 0.1526182433962822, 'NDCG@5': 0.10539263643324376, 'MRR@5': 0.08988541830331087, 'Recall*@10': 0.2157432433962822, 'NDCG*@10': 0.12568710163235663, 'MRR*@10': 0.09819320511072874, 'Recall*@5': 0.1526182433962822, 'NDCG*@5': 0.10539263643324376, 'MRR*@5': 0.08988541830331087}
INFO    [02-25 13:43:07] train in BasicTrainer:
duration: 21.215316772460938s
INFO    [02-25 13:43:07] train in BasicTrainer:
epoch: 33
INFO    [02-25 13:43:25] _train_one_epoch in BasicTrainer:
loss = 3.831271631015707
INFO    [02-25 13:43:28] validate in BasicTrainer:
{'Recall@10': 0.2198057433962822, 'NDCG@10': 0.1260656204074621, 'MRR@10': 0.09749700754880905, 'Recall@5': 0.1523902028799057, 'NDCG@5': 0.10440381802618504, 'MRR@5': 0.08863893650472164, 'Recall*@10': 0.2198057433962822, 'NDCG*@10': 0.1260656204074621, 'MRR*@10': 0.09749700754880905, 'Recall*@5': 0.1523902028799057, 'NDCG*@5': 0.10440381802618504, 'MRR*@5': 0.08863893650472164}
INFO    [02-25 13:43:28] train in BasicTrainer:
duration: 21.07026433944702s
INFO    [02-25 13:43:28] train in BasicTrainer:
epoch: 34
INFO    [02-25 13:43:47] _train_one_epoch in BasicTrainer:
loss = 3.835412378652659
INFO    [02-25 13:43:49] validate in BasicTrainer:
{'Recall@10': 0.21878378391265868, 'NDCG@10': 0.12744611844420434, 'MRR@10': 0.09952354677021504, 'Recall@5': 0.15497466221451758, 'NDCG@5': 0.1069349268823862, 'MRR@5': 0.09112711347639561, 'Recall*@10': 0.21878378391265868, 'NDCG*@10': 0.12744611844420434, 'MRR*@10': 0.09952354677021504, 'Recall*@5': 0.15497466221451758, 'NDCG*@5': 0.1069349268823862, 'MRR*@5': 0.09112711347639561}
INFO    [02-25 13:43:49] train in BasicTrainer:
duration: 21.29657793045044s
INFO    [02-25 13:43:49] train in BasicTrainer:
epoch: 35
INFO    [02-25 13:44:08] _train_one_epoch in BasicTrainer:
loss = 3.829642132043206
INFO    [02-25 13:44:10] validate in BasicTrainer:
{'Recall@10': 0.2223057433962822, 'NDCG@10': 0.1291091900318861, 'MRR@10': 0.10060105800628662, 'Recall@5': 0.1610557433962822, 'NDCG@5': 0.109515862762928, 'MRR@5': 0.09263429209589959, 'Recall*@10': 0.2223057433962822, 'NDCG*@10': 0.1291091900318861, 'MRR*@10': 0.10060105800628662, 'Recall*@5': 0.1610557433962822, 'NDCG*@5': 0.109515862762928, 'MRR*@5': 0.09263429209589959}
INFO    [02-25 13:44:10] train in BasicTrainer:
duration: 21.08231258392334s
INFO    [02-25 13:44:10] train in BasicTrainer:
epoch: 36
INFO    [02-25 13:44:29] _train_one_epoch in BasicTrainer:
loss = 3.824960941345053
INFO    [02-25 13:44:32] validate in BasicTrainer:
{'Recall@10': 0.2178462839126587, 'NDCG@10': 0.12430621467530728, 'MRR@10': 0.09563713870942593, 'Recall@5': 0.15418074339628218, 'NDCG@5': 0.10369926139712334, 'MRR@5': 0.08712500110268592, 'Recall*@10': 0.2178462839126587, 'NDCG*@10': 0.12430621467530728, 'MRR*@10': 0.09563713870942593, 'Recall*@5': 0.15418074339628218, 'NDCG*@5': 0.10369926139712334, 'MRR*@5': 0.08712500110268592}
INFO    [02-25 13:44:32] train in BasicTrainer:
duration: 21.11411738395691s
INFO    [02-25 13:44:32] train in BasicTrainer:
epoch: 37
INFO    [02-25 13:44:50] _train_one_epoch in BasicTrainer:
loss = 3.8236589634133904
INFO    [02-25 13:44:53] validate in BasicTrainer:
{'Recall@10': 0.2197212839126587, 'NDCG@10': 0.12746984854340554, 'MRR@10': 0.0993544601649046, 'Recall@5': 0.1535557433962822, 'NDCG@5': 0.10621140085160732, 'MRR@5': 0.09066610511392355, 'Recall*@10': 0.2197212839126587, 'NDCG*@10': 0.12746984854340554, 'MRR*@10': 0.0993544601649046, 'Recall*@5': 0.1535557433962822, 'NDCG*@5': 0.10621140085160732, 'MRR*@5': 0.09066610511392355}
INFO    [02-25 13:44:53] train in BasicTrainer:
duration: 21.077704668045044s
INFO    [02-25 13:44:53] train in BasicTrainer:
epoch: 38
INFO    [02-25 13:45:11] _train_one_epoch in BasicTrainer:
loss = 3.81728000128617
INFO    [02-25 13:45:14] validate in BasicTrainer:
{'Recall@10': 0.21918074339628218, 'NDCG@10': 0.1269983197003603, 'MRR@10': 0.0988302032649517, 'Recall@5': 0.1561402028799057, 'NDCG@5': 0.1067073954641819, 'MRR@5': 0.09051069930195808, 'Recall*@10': 0.21918074339628218, 'NDCG*@10': 0.1269983197003603, 'MRR*@10': 0.0988302032649517, 'Recall*@5': 0.1561402028799057, 'NDCG*@5': 0.1067073954641819, 'MRR*@5': 0.09051069930195808}
INFO    [02-25 13:45:14] train in BasicTrainer:
duration: 21.287208795547485s
INFO    [02-25 13:45:14] train in BasicTrainer:
epoch: 39
INFO    [02-25 13:45:33] _train_one_epoch in BasicTrainer:
loss = 3.8128387994412085
INFO    [02-25 13:45:35] validate in BasicTrainer:
{'Recall@10': 0.2169087839126587, 'NDCG@10': 0.1264586090296507, 'MRR@10': 0.09875716760754585, 'Recall@5': 0.1563682433962822, 'NDCG@5': 0.10710090361535549, 'MRR@5': 0.09090048104524612, 'Recall*@10': 0.2169087839126587, 'NDCG*@10': 0.1264586090296507, 'MRR*@10': 0.09875716760754585, 'Recall*@5': 0.1563682433962822, 'NDCG*@5': 0.10710090361535549, 'MRR*@5': 0.09090048104524612}
INFO    [02-25 13:45:35] train in BasicTrainer:
duration: 21.242944717407227s
INFO    [02-25 13:45:35] train in BasicTrainer:
epoch: 40
INFO    [02-25 13:45:54] _train_one_epoch in BasicTrainer:
loss = 3.806493300341801
INFO    [02-25 13:45:56] validate in BasicTrainer:
{'Recall@10': 0.2163682433962822, 'NDCG@10': 0.12608979627490044, 'MRR@10': 0.09853276304900646, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10599458888173104, 'MRR@5': 0.09031165637075901, 'Recall*@10': 0.2163682433962822, 'NDCG*@10': 0.12608979627490044, 'MRR*@10': 0.09853276304900646, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10599458888173104, 'MRR*@5': 0.09031165637075901}
INFO    [02-25 13:45:56] train in BasicTrainer:
duration: 21.271036624908447s
INFO    [02-25 13:45:56] train in BasicTrainer:
epoch: 41
INFO    [02-25 13:46:15] _train_one_epoch in BasicTrainer:
loss = 3.803789162825526
INFO    [02-25 13:46:18] validate in BasicTrainer:
{'Recall@10': 0.2144087839126587, 'NDCG@10': 0.1268991931527853, 'MRR@10': 0.10009363994002342, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.1073447198420763, 'MRR@5': 0.0920377267897129, 'Recall*@10': 0.2144087839126587, 'NDCG*@10': 0.1268991931527853, 'MRR*@10': 0.10009363994002342, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.1073447198420763, 'MRR*@5': 0.0920377267897129}
INFO    [02-25 13:46:18] train in BasicTrainer:
duration: 21.33625340461731s
INFO    [02-25 13:46:18] train in BasicTrainer:
epoch: 42
INFO    [02-25 13:46:37] _train_one_epoch in BasicTrainer:
loss = 3.8009546954056312
INFO    [02-25 13:46:39] validate in BasicTrainer:
{'Recall@10': 0.2141807433962822, 'NDCG@10': 0.12448690935969353, 'MRR@10': 0.09704398393630981, 'Recall@5': 0.1530152028799057, 'NDCG@5': 0.10470693923532963, 'MRR@5': 0.08887936569750308, 'Recall*@10': 0.2141807433962822, 'NDCG*@10': 0.12448690935969353, 'MRR*@10': 0.09704398393630981, 'Recall*@5': 0.1530152028799057, 'NDCG*@5': 0.10470693923532963, 'MRR*@5': 0.08887936569750308}
INFO    [02-25 13:46:39] train in BasicTrainer:
duration: 21.3899188041687s
INFO    [02-25 13:46:39] train in BasicTrainer:
epoch: 43
INFO    [02-25 13:46:58] _train_one_epoch in BasicTrainer:
loss = 3.800353081220025
INFO    [02-25 13:47:00] validate in BasicTrainer:
{'Recall@10': 0.2182432433962822, 'NDCG@10': 0.1258364114165306, 'MRR@10': 0.09752317443490029, 'Recall@5': 0.1555152028799057, 'NDCG@5': 0.10563884839415551, 'MRR@5': 0.0892378956824541, 'Recall*@10': 0.2182432433962822, 'NDCG*@10': 0.1258364114165306, 'MRR*@10': 0.09752317443490029, 'Recall*@5': 0.1555152028799057, 'NDCG*@5': 0.10563884839415551, 'MRR*@5': 0.0892378956824541}
INFO    [02-25 13:47:00] train in BasicTrainer:
duration: 21.196415901184082s
INFO    [02-25 13:47:00] train in BasicTrainer:
epoch: 44
INFO    [02-25 13:47:19] _train_one_epoch in BasicTrainer:
loss = 3.7986739371120137
INFO    [02-25 13:47:22] validate in BasicTrainer:
{'Recall@10': 0.2203462839126587, 'NDCG@10': 0.128747299015522, 'MRR@10': 0.10073151625692844, 'Recall@5': 0.1573902028799057, 'NDCG@5': 0.10846077755093575, 'MRR@5': 0.09239766456186771, 'Recall*@10': 0.2203462839126587, 'NDCG*@10': 0.128747299015522, 'MRR*@10': 0.10073151625692844, 'Recall*@5': 0.1573902028799057, 'NDCG*@5': 0.10846077755093575, 'MRR*@5': 0.09239766456186771}
INFO    [02-25 13:47:22] train in BasicTrainer:
duration: 21.11485767364502s
INFO    [02-25 13:47:22] train in BasicTrainer:
epoch: 45
INFO    [02-25 13:47:40] _train_one_epoch in BasicTrainer:
loss = 3.7920017931758565
INFO    [02-25 13:47:43] validate in BasicTrainer:
{'Recall@10': 0.2206587839126587, 'NDCG@10': 0.12926524601876735, 'MRR@10': 0.10130426317453384, 'Recall@5': 0.1604307433962822, 'NDCG@5': 0.10987403735518456, 'MRR@5': 0.09334712944924832, 'Recall*@10': 0.2206587839126587, 'NDCG*@10': 0.12926524601876735, 'MRR*@10': 0.10130426317453384, 'Recall*@5': 0.1604307433962822, 'NDCG*@5': 0.10987403735518456, 'MRR*@5': 0.09334712944924832}
INFO    [02-25 13:47:43] train in BasicTrainer:
duration: 21.377307415008545s
INFO    [02-25 13:47:43] train in BasicTrainer:
epoch: 46
INFO    [02-25 13:48:02] _train_one_epoch in BasicTrainer:
loss = 3.789602051046862
INFO    [02-25 13:48:04] validate in BasicTrainer:
{'Recall@10': 0.2185557433962822, 'NDCG@10': 0.12806155666708946, 'MRR@10': 0.10036733649671077, 'Recall@5': 0.1576182433962822, 'NDCG@5': 0.1086074960976839, 'MRR@5': 0.09248353205621243, 'Recall*@10': 0.2185557433962822, 'NDCG*@10': 0.12806155666708946, 'MRR*@10': 0.10036733649671077, 'Recall*@5': 0.1576182433962822, 'NDCG*@5': 0.1086074960976839, 'MRR*@5': 0.09248353205621243}
INFO    [02-25 13:48:04] train in BasicTrainer:
duration: 21.305962800979614s
INFO    [02-25 13:48:04] train in BasicTrainer:
epoch: 47
INFO    [02-25 13:48:23] _train_one_epoch in BasicTrainer:
loss = 3.7846775187737745
INFO    [02-25 13:48:25] validate in BasicTrainer:
{'Recall@10': 0.2151182433962822, 'NDCG@10': 0.12752960875630379, 'MRR@10': 0.10057568565011024, 'Recall@5': 0.1576182433962822, 'NDCG@5': 0.10881082475185394, 'MRR@5': 0.09277533948421478, 'Recall*@10': 0.2151182433962822, 'NDCG*@10': 0.12752960875630379, 'MRR*@10': 0.10057568565011024, 'Recall*@5': 0.1576182433962822, 'NDCG*@5': 0.10881082475185394, 'MRR*@5': 0.09277533948421478}
INFO    [02-25 13:48:25] train in BasicTrainer:
duration: 21.199882745742798s
INFO    [02-25 13:48:25] train in BasicTrainer:
epoch: 48
INFO    [02-25 13:48:44] _train_one_epoch in BasicTrainer:
loss = 3.7824272122876397
INFO    [02-25 13:48:47] validate in BasicTrainer:
{'Recall@10': 0.2210557433962822, 'NDCG@10': 0.12781003192067147, 'MRR@10': 0.09921738274395465, 'Recall@5': 0.1598057433962822, 'NDCG@5': 0.10816319994628429, 'MRR@5': 0.09119580671191216, 'Recall*@10': 0.2210557433962822, 'NDCG*@10': 0.12781003192067147, 'MRR*@10': 0.09921738274395465, 'Recall*@5': 0.1598057433962822, 'NDCG*@5': 0.10816319994628429, 'MRR*@5': 0.09119580671191216}
INFO    [02-25 13:48:47] train in BasicTrainer:
duration: 21.160822868347168s
INFO    [02-25 13:48:47] train in BasicTrainer:
epoch: 49
INFO    [02-25 13:49:05] _train_one_epoch in BasicTrainer:
loss = 3.7826418500363985
INFO    [02-25 13:49:08] validate in BasicTrainer:
{'Recall@10': 0.2216807433962822, 'NDCG@10': 0.13047828599810601, 'MRR@10': 0.10251748315989971, 'Recall@5': 0.15668074339628218, 'NDCG@5': 0.10939894773066045, 'MRR@5': 0.09378434851765632, 'Recall*@10': 0.2216807433962822, 'NDCG*@10': 0.13047828599810601, 'MRR*@10': 0.10251748315989971, 'Recall*@5': 0.15668074339628218, 'NDCG*@5': 0.10939894773066045, 'MRR*@5': 0.09378434851765632}
INFO    [02-25 13:49:08] train in BasicTrainer:
duration: 21.238444566726685s
INFO    [02-25 13:49:08] close_training in BasicTrainer:
finished training
DEBUG   [02-25 13:49:08] debug_summary in loss:
loss nan summary: nan 0 times, not nan 37700 times, ratio nan / (nan + not_nan) = 0.0
INFO    [02-25 13:49:08] run_routine in Routine:
Finished training, Start final validation
INFO    [02-25 13:49:08] final_validate in BasicTrainer:
validate model on val set!
INFO    [02-25 13:49:08] load_state_from_given_path in utils:
checkpoint epoch: 29
INFO    [02-25 13:49:08] load_state_from_given_path in utils:
Loading model's parameters
INFO    [02-25 13:49:11] validate in BasicTrainer:
{'Recall@10': 0.22503378391265869, 'NDCG@10': 0.13114468708634378, 'MRR@10': 0.10262958690524102, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10834007300436496, 'MRR@5': 0.09334234401583671, 'Recall*@10': 0.22503378391265869, 'NDCG*@10': 0.13114468708634378, 'MRR*@10': 0.10262958690524102, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10834007300436496, 'MRR*@5': 0.09334234401583671}
INFO    [02-25 13:49:11] run_routine in Routine:
Finished final validating. Result: {'Recall@10': 0.22503378391265869, 'NDCG@10': 0.13114468708634378, 'MRR@10': 0.10262958690524102, 'Recall@5': 0.1538682433962822, 'NDCG@5': 0.10834007300436496, 'MRR@5': 0.09334234401583671, 'Recall*@10': 0.22503378391265869, 'NDCG*@10': 0.13114468708634378, 'MRR*@10': 0.10262958690524102, 'Recall*@5': 0.1538682433962822, 'NDCG*@5': 0.10834007300436496, 'MRR*@5': 0.09334234401583671}
