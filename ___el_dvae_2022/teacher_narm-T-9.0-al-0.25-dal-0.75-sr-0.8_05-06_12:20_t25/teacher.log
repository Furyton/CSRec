INFO    [05-06 12:20:22] setup_train in utils:
{
    "experiment_dir": "___el_dvae_2022",
    "experiment_description": "teacher",
    "describe": "{config[model_code]}-T-{config[T]}-al-{config[alpha]}-dal-{config[dvae_alpha]}-sr-{config[sample_rate]}",
    "dataset_name": "electronics.csv",
    "sched": "dvae",
    "model_code": "narm",
    "mentor_code": "narm",
    "mentor2_code": "narm",
    "training_routine": "teacher",
    "softmaxed_mentor": false,
    "dvae_alpha": 0.75,
    "alpha": 0.25,
    "T": 9.0,
    "enable_auto_path_finder": true,
    "sample_seed": 2000,
    "sample_rate": 0.8,
    "mentor_describe": "{config[model_code]}-rate-{config[sample_rate]}-seed-{config[sample_seed]}",
    "num_epochs": 80,
    "mode": [
        "train",
        "test"
    ],
    "max_len": 10,
    "model_state_path": null,
    "test_state_path": null,
    "mentor_state_path": "___el_base_partial_2022",
    "mentor2_state_path": null,
    "rand_seed": 2022,
    "load_processed_dataset": true,
    "save_processed_dataset": false,
    "dataset_cache_filename": null,
    "do_remap": false,
    "weight_decay": 0,
    "decay_step": 15,
    "gamma": 0.99,
    "lr": 0.001,
    "min_length": 5,
    "min_item_inter": 5,
    "good_only": false,
    "use_rating": true,
    "test_negative_sampler_code": "random",
    "test_negative_sample_size": 0,
    "dataloader_type": "next",
    "train_batch_size": 4096,
    "val_batch_size": 4096,
    "test_batch_size": 4096,
    "prop_sliding_window": -1.0,
    "worker_number": 2,
    "metric_ks": [
        5,
        10
    ],
    "device": "cuda",
    "num_gpu": 1,
    "optimizer": "Adam",
    "best_metric": "NDCG@10",
    "show_process_bar": false,
    "enable_sample": false,
    "samples_ratio": 0.1,
    "config_file": "config2.electronics/narm/config_dvae.json",
    "task_id": 25,
    "split": "leave_one_out",
    "do_sampling": false,
    "path_for_sample": null,
    "train_negative_sampler_code": "random",
    "train_negative_sample_size": 100,
    "device_idx": "0",
    "momentum": null,
    "log_period_as_iter": 12800,
    "weight_list": [
        0.5,
        0.5
    ],
    "validation_rate": 0.2,
    "num_items": null,
    "start_index": 1,
    "kwargs": null
}
DEBUG   [05-06 12:20:22] __init__ in DVAEDistillSched:
DVAEDistillScheduler attribs: auxiliary tag=auxiliary_narm, teacher tag=teacher_narm, student tag=student_narm
INFO    [05-06 12:20:22] _load_full_dataset_from_path in utils:
loading cache from /data01/wushiguang-slurm/Codes/soft-rec/Data/Cache/electronics-5-5.pkl
INFO    [05-06 12:20:24] _check_dataset_cache in utils:
check if the cache is generated under this configuration
INFO    [05-06 12:20:24] _check_dataset_cache in utils:
correct.
INFO    [05-06 12:20:24] __init__ in NextItemDataloader:
there are 29351 items in this dataset, 102187 users, padding_first? False
DEBUG   [05-06 12:20:39] generate_model in utils:
model_code_list=['narm']
INFO    [05-06 12:20:39] load_model_config in utils:
loading model narm's config file at asset/config/model/narm.json
INFO    [05-06 12:20:39] load_model_config in utils:
{
    "embedding_size": 64,
    "hidden_size": 128,
    "n_layers": 1,
    "dropout_probs": [
        0.25,
        0.5
    ]
}
WARNING [05-06 12:20:48] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/auxiliary_narm_logs does not exist! Create one.
WARNING [05-06 12:20:48] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/auxiliary_narm_logs/tb_vis does not exist! Create one.
WARNING [05-06 12:20:48] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/auxiliary_narm_logs/checkpoint does not exist! Create one.
INFO    [05-06 12:20:49] load_state_from_given_path in utils:
checkpoint epoch: 78
INFO    [05-06 12:20:49] load_state_from_given_path in utils:
Loading model's parameters
INFO    [05-06 12:20:49] load_state_from_given_path in utils:
Loading optimizer's parameters
DEBUG   [05-06 12:20:49] _generate_auxliary_trainer in DVAEDistillSched:
auxiliary model: 
NARM(
  (item_embedding): Embedding(29352, 64, padding_idx=0)
  (emb_dropout): Dropout(p=0.25, inplace=False)
  (gru): GRU(64, 128, bias=False, batch_first=True)
  (a_1): Linear(in_features=128, out_features=128, bias=False)
  (a_2): Linear(in_features=128, out_features=128, bias=False)
  (v_t): Linear(in_features=128, out_features=1, bias=False)
  (ct_dropout): Dropout(p=0.5, inplace=False)
  (b): Linear(in_features=256, out_features=64, bias=False)
  (loss_fct): CrossEntropyLoss()
)
INFO    [05-06 12:20:49] assert_model_device in utils:
model auxiliary_narm has 7.63525390625 MB params.
INFO    [05-06 12:20:49] __init__ in BasicTrainer:
454656 iter per epoch
DEBUG   [05-06 12:20:49] generate_model in utils:
model_code_list=['prior']
INFO    [05-06 12:20:49] load_model_config in utils:
loading model prior's config file at asset/config/model/prior.json
INFO    [05-06 12:20:49] load_model_config in utils:
{
    "hidden_size": 64
}
DEBUG   [05-06 12:20:53] generate_model in utils:
model_code_list=['narm']
INFO    [05-06 12:20:53] load_model_config in utils:
loading model narm's config file at asset/config/model/narm.json
INFO    [05-06 12:20:53] load_model_config in utils:
{
    "embedding_size": 64,
    "hidden_size": 128,
    "n_layers": 1,
    "dropout_probs": [
        0.25,
        0.5
    ]
}
WARNING [05-06 12:20:58] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/teacher_narm_logs does not exist! Create one.
WARNING [05-06 12:20:58] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/teacher_narm_logs/tb_vis does not exist! Create one.
WARNING [05-06 12:20:58] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/teacher_narm_logs/checkpoint does not exist! Create one.
WARNING [05-06 12:20:58] get_path in utils:
Path is None
WARNING [05-06 12:20:58] load_state_from_given_path in utils:
Not given any path.
DEBUG   [05-06 12:20:58] _generate_teacher_trainer in DVAEDistillSched:
prior model: 
PriorModel(
  (observed_embedding): Embedding(29352, 64, padding_idx=0)
  (prior_item_embedding): Embedding(29352, 64, padding_idx=0)
)
DEBUG   [05-06 12:20:58] _generate_teacher_trainer in DVAEDistillSched:
teacher model: 
NARM(
  (item_embedding): Embedding(29352, 64, padding_idx=0)
  (emb_dropout): Dropout(p=0.25, inplace=False)
  (gru): GRU(64, 128, bias=False, batch_first=True)
  (a_1): Linear(in_features=128, out_features=128, bias=False)
  (a_2): Linear(in_features=128, out_features=128, bias=False)
  (v_t): Linear(in_features=128, out_features=1, bias=False)
  (ct_dropout): Dropout(p=0.5, inplace=False)
  (b): Linear(in_features=256, out_features=64, bias=False)
  (loss_fct): CrossEntropyLoss()
)
INFO    [05-06 12:20:58] assert_model_device in utils:
model teacher_narm has 7.63525390625 MB params.
INFO    [05-06 12:20:58] assert_model_device in utils:
model auxiliary_narm has 7.63525390625 MB params.
INFO    [05-06 12:20:58] assert_model_device in utils:
model prior has 14.33203125 MB params.
INFO    [05-06 12:20:58] __init__ in DVAETrainer:
454656 iter per epoch
DEBUG   [05-06 12:20:58] generate_model in utils:
model_code_list=['narm']
INFO    [05-06 12:20:58] load_model_config in utils:
loading model narm's config file at asset/config/model/narm.json
INFO    [05-06 12:20:58] load_model_config in utils:
{
    "embedding_size": 64,
    "hidden_size": 128,
    "n_layers": 1,
    "dropout_probs": [
        0.25,
        0.5
    ]
}
WARNING [05-06 12:21:03] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/student_narm_logs does not exist! Create one.
WARNING [05-06 12:21:03] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/student_narm_logs/tb_vis does not exist! Create one.
WARNING [05-06 12:21:03] get_exist_path in utils:
dir ___el_dvae_2022/teacher_narm-T-9.0-al-0.25-dal-0.75-sr-0.8_05-06_12:20_t25/student_narm_logs/checkpoint does not exist! Create one.
WARNING [05-06 12:21:03] get_path in utils:
Path is None
WARNING [05-06 12:21:03] load_state_from_given_path in utils:
Not given any path.
DEBUG   [05-06 12:21:03] _genearte_student_trainer in DVAEDistillSched:
student model: 
NARM(
  (item_embedding): Embedding(29352, 64, padding_idx=0)
  (emb_dropout): Dropout(p=0.25, inplace=False)
  (gru): GRU(64, 128, bias=False, batch_first=True)
  (a_1): Linear(in_features=128, out_features=128, bias=False)
  (a_2): Linear(in_features=128, out_features=128, bias=False)
  (v_t): Linear(in_features=128, out_features=1, bias=False)
  (ct_dropout): Dropout(p=0.5, inplace=False)
  (b): Linear(in_features=256, out_features=64, bias=False)
  (loss_fct): CrossEntropyLoss()
)
INFO    [05-06 12:21:03] assert_model_device in utils:
model student_narm has 7.63525390625 MB params.
INFO    [05-06 12:21:03] assert_model_device in utils:
model teacher_narm has 7.63525390625 MB params.
INFO    [05-06 12:21:03] __init__ in DistillTrainer:
454656 iter per epoch
INFO    [05-06 12:21:03] _set_current_routine in Routine:
first routine: teacher
INFO    [05-06 12:21:03] run_routine in Routine:
Start routine teacher
INFO    [05-06 12:21:03] run_routine in Routine:
Start training
INFO    [05-06 12:21:45] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [05-06 12:21:45] validate in BasicTrainer:
{'Recall@10': 0.000380859375, 'NDCG@10': 0.00016723612614441663, 'MRR@10': 0.00010360475571360439, 'Recall@5': 0.00021484375, 'NDCG@5': 0.00011410955397877842, 'MRR@5': 8.203125064028427e-05, 'Recall*@10': 0.00038453699904493987, 'NDCG*@10': 0.00016273027984425425, 'MRR*@10': 9.700098380562849e-05, 'Recall*@5': 0.00020425495691597461, 'NDCG*@5': 0.00010497452516574413, 'MRR*@5': 7.350673477048985e-05}
INFO    [05-06 12:21:45] train in BasicTrainer:
epoch: 0
DEBUG   [05-06 12:21:57] calculate_loss in loss:
KL_loss1: 
tensor(3.5700, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:21:57] calculate_loss in loss:
KL_loss2: 
tensor(2.8348, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:21:57] calculate_loss in loss:
expectation_loss: 
tensor(11.1756, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:21:57] calculate_loss in loss:
max in g softmax: 0.9999115467071533 argmax: 10161078
DEBUG   [05-06 12:21:57] calculate_loss in loss:
max in f softmax: 0.07735227793455124 argmax: 4681243
DEBUG   [05-06 12:21:57] calculate_loss in loss:
max in h softmax: 4.3373482185415924e-05 argmax: 111684379
DEBUG   [05-06 12:21:57] calculate_loss in loss:
max_in_col: tensor([[0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744],
        [0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744],
        [0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744],
        ...,
        [0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744],
        [0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744],
        [0.2064, 0.2037, 0.1733,  ..., 0.2178, 0.1890, 0.1744]],
       device='cuda:0', grad_fn=<SliceBackward0>)
DEBUG   [05-06 12:22:07] calculate_loss in loss:
KL_loss1: 
tensor(2.9060, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:22:07] calculate_loss in loss:
KL_loss2: 
tensor(2.5713, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:22:07] calculate_loss in loss:
expectation_loss: 
tensor(11.1606, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:22:07] calculate_loss in loss:
max in g softmax: 0.9999523162841797 argmax: 26039698
DEBUG   [05-06 12:22:07] calculate_loss in loss:
max in f softmax: 0.045912936329841614 argmax: 32671595
DEBUG   [05-06 12:22:07] calculate_loss in loss:
max in h softmax: 4.421036646817811e-05 argmax: 65728509
DEBUG   [05-06 12:22:07] calculate_loss in loss:
max_in_col: tensor([[0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744],
        [0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744],
        [0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744],
        ...,
        [0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744],
        [0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744],
        [0.2064, 0.2037, 0.1812,  ..., 0.2178, 0.1987, 0.1744]],
       device='cuda:0', grad_fn=<SliceBackward0>)
INFO    [05-06 12:22:10] _train_one_epoch in BasicTrainer:
loss = 24.624756632624447
INFO    [05-06 12:22:50] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [05-06 12:22:51] validate in BasicTrainer:
{'Recall@10': 0.0324398846924305, 'NDCG@10': 0.016805587597191335, 'MRR@10': 0.012074335217475892, 'Recall@5': 0.020362319052219392, 'NDCG@5': 0.01295871526002884, 'MRR@5': 0.010520416460931301, 'Recall*@10': 0.03567421570420265, 'NDCG*@10': 0.0188762129470706, 'MRR*@10': 0.013777273409068584, 'Recall*@5': 0.02298210680484772, 'NDCG*@5': 0.014825227186083794, 'MRR*@5': 0.012136077284812927}
INFO    [05-06 12:22:51] train in BasicTrainer:
duration: 65.33498764038086s
INFO    [05-06 12:22:51] train in BasicTrainer:
epoch: 1
DEBUG   [05-06 12:23:00] calculate_loss in loss:
KL_loss1: 
tensor(2.7681, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:23:00] calculate_loss in loss:
KL_loss2: 
tensor(2.4532, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:23:00] calculate_loss in loss:
expectation_loss: 
tensor(11.1543, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:23:00] calculate_loss in loss:
max in g softmax: 0.9997871518135071 argmax: 34898598
DEBUG   [05-06 12:23:00] calculate_loss in loss:
max in f softmax: 0.04023141413927078 argmax: 113015784
DEBUG   [05-06 12:23:00] calculate_loss in loss:
max in h softmax: 4.390537287690677e-05 argmax: 44449568
DEBUG   [05-06 12:23:00] calculate_loss in loss:
max_in_col: tensor([[0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055],
        [0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055],
        [0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055],
        ...,
        [0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055],
        [0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055],
        [0.2124, 0.2466, 0.1972,  ..., 0.2178, 0.2308, 0.2055]],
       device='cuda:0', grad_fn=<SliceBackward0>)
DEBUG   [05-06 12:23:10] calculate_loss in loss:
KL_loss1: 
tensor(2.7352, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:23:10] calculate_loss in loss:
KL_loss2: 
tensor(2.4654, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:23:10] calculate_loss in loss:
expectation_loss: 
tensor(11.1624, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:23:10] calculate_loss in loss:
max in g softmax: 0.9999984502792358 argmax: 39775116
DEBUG   [05-06 12:23:10] calculate_loss in loss:
max in f softmax: 0.7541384100914001 argmax: 22341002
DEBUG   [05-06 12:23:10] calculate_loss in loss:
max in h softmax: 4.364975029602647e-05 argmax: 116588640
DEBUG   [05-06 12:23:10] calculate_loss in loss:
max_in_col: tensor([[0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379],
        [0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379],
        [0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379],
        ...,
        [0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379],
        [0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379],
        [0.2374, 0.2943, 0.2291,  ..., 0.2397, 0.2643, 0.2379]],
       device='cuda:0', grad_fn=<SliceBackward0>)
INFO    [05-06 12:23:15] _train_one_epoch in BasicTrainer:
loss = 23.346233625669736
INFO    [05-06 12:23:58] log in loggers:
Update Best NDCG@10 Model at 1
INFO    [05-06 12:23:59] validate in BasicTrainer:
{'Recall@10': 0.03527405872941017, 'NDCG@10': 0.018292123563587667, 'MRR@10': 0.01313541978597641, 'Recall@5': 0.022418992891907692, 'NDCG@5': 0.01417849276214838, 'MRR@5': 0.011462769769132138, 'Recall*@10': 0.038754656985402106, 'NDCG*@10': 0.020335901901125907, 'MRR*@10': 0.01473859865218401, 'Recall*@5': 0.024812388867139816, 'NDCG*@5': 0.015873249098658563, 'MRR*@5': 0.01292346216738224}
INFO    [05-06 12:23:59] train in BasicTrainer:
duration: 68.05119180679321s
INFO    [05-06 12:23:59] train in BasicTrainer:
epoch: 2
DEBUG   [05-06 12:24:06] calculate_loss in loss:
KL_loss1: 
tensor(2.5865, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:24:06] calculate_loss in loss:
KL_loss2: 
tensor(2.4006, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:24:06] calculate_loss in loss:
expectation_loss: 
tensor(11.1789, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:24:06] calculate_loss in loss:
max in g softmax: 0.9998621940612793 argmax: 34155576
DEBUG   [05-06 12:24:06] calculate_loss in loss:
max in f softmax: 0.0645294338464737 argmax: 26554427
DEBUG   [05-06 12:24:06] calculate_loss in loss:
max in h softmax: 4.42469900008291e-05 argmax: 41978398
DEBUG   [05-06 12:24:06] calculate_loss in loss:
max_in_col: tensor([[0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868],
        [0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868],
        [0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868],
        ...,
        [0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868],
        [0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868],
        [0.2774, 0.3407, 0.2565,  ..., 0.2691, 0.3096, 0.2868]],
       device='cuda:0', grad_fn=<SliceBackward0>)
DEBUG   [05-06 12:24:16] calculate_loss in loss:
KL_loss1: 
tensor(2.3217, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:24:16] calculate_loss in loss:
KL_loss2: 
tensor(2.2315, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:24:16] calculate_loss in loss:
expectation_loss: 
tensor(11.2050, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:24:16] calculate_loss in loss:
max in g softmax: 0.9999370574951172 argmax: 51490633
DEBUG   [05-06 12:24:16] calculate_loss in loss:
max in f softmax: 0.26385822892189026 argmax: 75992321
DEBUG   [05-06 12:24:16] calculate_loss in loss:
max in h softmax: 4.509738937485963e-05 argmax: 65659631
DEBUG   [05-06 12:24:16] calculate_loss in loss:
max_in_col: tensor([[0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273],
        [0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273],
        [0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273],
        ...,
        [0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273],
        [0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273],
        [0.3470, 0.3954, 0.3023,  ..., 0.3090, 0.3584, 0.3273]],
       device='cuda:0', grad_fn=<SliceBackward0>)
INFO    [05-06 12:24:23] _train_one_epoch in BasicTrainer:
loss = 22.892650209031665
INFO    [05-06 12:25:04] log in loggers:
Update Best NDCG@10 Model at 2
INFO    [05-06 12:25:05] validate in BasicTrainer:
{'Recall@10': 0.03900720596313476, 'NDCG@10': 0.02100567616522312, 'MRR@10': 0.015522515028715133, 'Recall@5': 0.026082173585891724, 'NDCG@5': 0.016868550069630145, 'MRR@5': 0.013840125575661659, 'Recall*@10': 0.042631921619176866, 'NDCG*@10': 0.023009384348988533, 'MRR*@10': 0.017026596479117872, 'Recall*@5': 0.028684910833835602, 'NDCG*@5': 0.01853939823806286, 'MRR*@5': 0.015205482915043832}
INFO    [05-06 12:25:05] train in BasicTrainer:
duration: 65.83785605430603s
INFO    [05-06 12:25:05] train in BasicTrainer:
epoch: 3
DEBUG   [05-06 12:25:09] calculate_loss in loss:
KL_loss1: 
tensor(2.1923, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:25:09] calculate_loss in loss:
KL_loss2: 
tensor(2.1105, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:25:09] calculate_loss in loss:
expectation_loss: 
tensor(11.2367, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:25:09] calculate_loss in loss:
max in g softmax: 0.999983549118042 argmax: 68243688
DEBUG   [05-06 12:25:09] calculate_loss in loss:
max in f softmax: 0.19663968682289124 argmax: 50850211
DEBUG   [05-06 12:25:09] calculate_loss in loss:
max in h softmax: 4.59440634585917e-05 argmax: 92222286
DEBUG   [05-06 12:25:09] calculate_loss in loss:
max_in_col: tensor([[0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828],
        [0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828],
        [0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828],
        ...,
        [0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828],
        [0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828],
        [0.4352, 0.4729, 0.3476,  ..., 0.3826, 0.4199, 0.3828]],
       device='cuda:0', grad_fn=<SliceBackward0>)
DEBUG   [05-06 12:25:19] calculate_loss in loss:
KL_loss1: 
tensor(2.1900, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:25:19] calculate_loss in loss:
KL_loss2: 
tensor(2.1152, device='cuda:0', grad_fn=<DivBackward0>)
DEBUG   [05-06 12:25:19] calculate_loss in loss:
expectation_loss: 
tensor(11.2726, device='cuda:0', grad_fn=<AddBackward0>)
DEBUG   [05-06 12:25:19] calculate_loss in loss:
max in g softmax: 0.9991140961647034 argmax: 25117742
DEBUG   [05-06 12:25:19] calculate_loss in loss:
max in f softmax: 0.25115323066711426 argmax: 22591752
DEBUG   [05-06 12:25:19] calculate_loss in loss:
max in h softmax: 4.799230373464525e-05 argmax: 116319457
DEBUG   [05-06 12:25:19] calculate_loss in loss:
max_in_col: tensor([[0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379],
        [0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379],
        [0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379],
        ...,
        [0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379],
        [0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379],
        [0.5055, 0.5120, 0.4074,  ..., 0.4513, 0.5016, 0.4379]],
       device='cuda:0', grad_fn=<SliceBackward0>)
INFO    [05-06 12:25:29] _train_one_epoch in BasicTrainer:
loss = 22.58040914449606
INFO    [05-06 12:26:09] log in loggers:
Update Best NDCG@10 Model at 3
INFO    [05-06 12:26:10] validate in BasicTrainer:
{'Recall@10': 0.04186853408813476, 'NDCG@10': 0.022698194086551667, 'MRR@10': 0.016865870617330074, 'Recall@5': 0.027791157960891724, 'NDCG@5': 0.018166301660239696, 'MRR@5': 0.015007225535809994, 'Recall*@10': 0.04547157645225525, 'NDCG*@10': 0.024835292622447012, 'MRR*@10': 0.01854975201189518, 'Recall*@5': 0.030465832725167275, 'NDCG*@5': 0.019998376742005348, 'MRR*@5': 0.016562449000775813}
INFO    [05-06 12:26:10] train in BasicTrainer:
duration: 65.72399020195007s
INFO    [05-06 12:26:10] train in BasicTrainer:
epoch: 4
INFO    [05-06 12:26:35] _train_one_epoch in BasicTrainer:
loss = 22.425329363023913
INFO    [05-06 12:27:18] log in loggers:
Update Best NDCG@10 Model at 4
INFO    [05-06 12:27:18] validate in BasicTrainer:
{'Recall@10': 0.04526243954896927, 'NDCG@10': 0.024325003176927568, 'MRR@10': 0.01795871488749981, 'Recall@5': 0.0298011464625597, 'NDCG@5': 0.019353988692164422, 'MRR@5': 0.015923748649656774, 'Recall*@10': 0.04914746657013893, 'NDCG*@10': 0.026467130854725837, 'MRR*@10': 0.019568159207701684, 'Recall*@5': 0.032436644956469536, 'NDCG*@5': 0.021092128083109854, 'MRR*@5': 0.017366491667926313}
INFO    [05-06 12:27:18] train in BasicTrainer:
duration: 67.92283225059509s
INFO    [05-06 12:27:18] train in BasicTrainer:
epoch: 5
INFO    [05-06 12:27:42] _train_one_epoch in BasicTrainer:
loss = 22.193266344500017
INFO    [05-06 12:28:23] log in loggers:
Update Best NDCG@10 Model at 5
INFO    [05-06 12:28:24] validate in BasicTrainer:
{'Recall@10': 0.048289660066366195, 'NDCG@10': 0.02634790152311325, 'MRR@10': 0.019659171998500823, 'Recall@5': 0.03247186005115509, 'NDCG@5': 0.021247766837477686, 'MRR@5': 0.017562705427408218, 'Recall*@10': 0.05214946314692497, 'NDCG*@10': 0.028390213921666144, 'MRR*@10': 0.021142306327819823, 'Recall*@5': 0.035178003385663036, 'NDCG*@5': 0.022916413694620132, 'MRR*@5': 0.018891225457191466}
INFO    [05-06 12:28:24] train in BasicTrainer:
duration: 65.79566097259521s
INFO    [05-06 12:28:24] train in BasicTrainer:
epoch: 6
INFO    [05-06 12:28:49] _train_one_epoch in BasicTrainer:
loss = 22.06514087024036
INFO    [05-06 12:29:30] log in loggers:
Update Best NDCG@10 Model at 6
INFO    [05-06 12:29:31] validate in BasicTrainer:
{'Recall@10': 0.049585274159908294, 'NDCG@10': 0.027162512689828874, 'MRR@10': 0.02034777097404003, 'Recall@5': 0.0331403312087059, 'NDCG@5': 0.021880370303988456, 'MRR@5': 0.01818864483386278, 'Recall*@10': 0.053720197528600695, 'NDCG*@10': 0.029382774382829668, 'MRR*@10': 0.021983956396579744, 'Recall*@5': 0.035943496823310855, 'NDCG*@5': 0.02367284707725048, 'MRR*@5': 0.019649959579110147}
INFO    [05-06 12:29:31] train in BasicTrainer:
duration: 66.71404838562012s
INFO    [05-06 12:29:31] train in BasicTrainer:
epoch: 7
INFO    [05-06 12:29:55] _train_one_epoch in BasicTrainer:
loss = 22.009568738507795
INFO    [05-06 12:30:35] log in loggers:
Update Best NDCG@10 Model at 7
INFO    [05-06 12:30:36] validate in BasicTrainer:
{'Recall@10': 0.0497018027305603, 'NDCG@10': 0.027340218499302862, 'MRR@10': 0.020534120500087738, 'Recall@5': 0.03329711690545082, 'NDCG@5': 0.022048319205641747, 'MRR@5': 0.018357521593570708, 'Recall*@10': 0.053773621022701265, 'NDCG*@10': 0.029589762315154075, 'MRR*@10': 0.022225612103939058, 'Recall*@5': 0.0361202646791935, 'NDCG*@5': 0.02389713332056999, 'MRR*@5': 0.019885565266013146}
INFO    [05-06 12:30:36] train in BasicTrainer:
duration: 64.92337942123413s
INFO    [05-06 12:30:36] train in BasicTrainer:
epoch: 8
INFO    [05-06 12:31:00] _train_one_epoch in BasicTrainer:
loss = 21.97584923752793
INFO    [05-06 12:31:42] log in loggers:
Update Best NDCG@10 Model at 8
INFO    [05-06 12:31:43] validate in BasicTrainer:
{'Recall@10': 0.0509322714805603, 'NDCG@10': 0.027941518425941468, 'MRR@10': 0.020949309095740318, 'Recall@5': 0.03409188240766525, 'NDCG@5': 0.022521925941109657, 'MRR@5': 0.01872802197933197, 'Recall*@10': 0.05513671815395355, 'NDCG*@10': 0.030196671411395072, 'MRR*@10': 0.022611456587910653, 'Recall*@5': 0.03679915830492973, 'NDCG*@5': 0.024291951209306717, 'MRR*@5': 0.020189354196190834}
INFO    [05-06 12:31:43] train in BasicTrainer:
duration: 67.00717949867249s
INFO    [05-06 12:31:43] train in BasicTrainer:
epoch: 9
INFO    [05-06 12:32:07] _train_one_epoch in BasicTrainer:
loss = 21.94455389074377
INFO    [05-06 12:32:48] log in loggers:
Update Best NDCG@10 Model at 9
INFO    [05-06 12:32:49] validate in BasicTrainer:
{'Recall@10': 0.05155179128050804, 'NDCG@10': 0.028361500203609467, 'MRR@10': 0.021323801130056382, 'Recall@5': 0.03428773060441017, 'NDCG@5': 0.02282446213066578, 'MRR@5': 0.019065196216106414, 'Recall*@10': 0.055854942947626114, 'NDCG*@10': 0.0307509346306324, 'MRR*@10': 0.023134164810180664, 'Recall*@5': 0.03710307642817497, 'NDCG*@5': 0.024735014289617538, 'MRR*@5': 0.02067920871078968}
INFO    [05-06 12:32:49] train in BasicTrainer:
duration: 65.8521466255188s
INFO    [05-06 12:32:49] train in BasicTrainer:
epoch: 10
INFO    [05-06 12:33:13] _train_one_epoch in BasicTrainer:
loss = 21.912340026718002
INFO    [05-06 12:33:53] log in loggers:
Update Best NDCG@10 Model at 10
INFO    [05-06 12:33:54] validate in BasicTrainer:
{'Recall@10': 0.05199886724352837, 'NDCG@10': 0.028620344027876853, 'MRR@10': 0.021515241861343383, 'Recall@5': 0.03463768601417541, 'NDCG@5': 0.02302671916782856, 'MRR@5': 0.019218807741999626, 'Recall*@10': 0.056232654005289075, 'NDCG*@10': 0.031008081808686257, 'MRR*@10': 0.023343479335308073, 'Recall*@5': 0.03749660268425942, 'NDCG*@5': 0.024973725602030754, 'MRR*@5': 0.020867360085248948}
INFO    [05-06 12:33:54] train in BasicTrainer:
duration: 65.0768678188324s
INFO    [05-06 12:33:54] train in BasicTrainer:
epoch: 11
INFO    [05-06 12:34:18] _train_one_epoch in BasicTrainer:
loss = 21.873051136463612
INFO    [05-06 12:35:00] log in loggers:
Update Best NDCG@10 Model at 11
INFO    [05-06 12:35:00] validate in BasicTrainer:
{'Recall@10': 0.051918599605560306, 'NDCG@10': 0.028652152940630914, 'MRR@10': 0.021578943729400633, 'Recall@5': 0.035048377960920335, 'NDCG@5': 0.02323565073311329, 'MRR@5': 0.01936628095805645, 'Recall*@10': 0.05628811895847321, 'NDCG*@10': 0.03121463656425476, 'MRR*@10': 0.023589495718479157, 'Recall*@5': 0.03824229821562767, 'NDCG*@5': 0.02542219951748848, 'MRR*@5': 0.021224236711859704}
INFO    [05-06 12:35:00] train in BasicTrainer:
duration: 66.57792496681213s
INFO    [05-06 12:35:00] train in BasicTrainer:
epoch: 12
INFO    [05-06 12:35:24] _train_one_epoch in BasicTrainer:
loss = 21.825556849574184
INFO    [05-06 12:36:05] log in loggers:
Update Best NDCG@10 Model at 12
INFO    [05-06 12:36:05] validate in BasicTrainer:
{'Recall@10': 0.0526373827457428, 'NDCG@10': 0.02898990198969841, 'MRR@10': 0.021822490096092224, 'Recall@5': 0.03472718372941017, 'NDCG@5': 0.02323233537375927, 'MRR@5': 0.019466496333479882, 'Recall*@10': 0.05703857272863388, 'NDCG*@10': 0.03147678330540657, 'MRR*@10': 0.023730783089995384, 'Recall*@5': 0.03770024754106999, 'NDCG*@5': 0.0252595591545105, 'MRR*@5': 0.021186368614435194}
INFO    [05-06 12:36:05] train in BasicTrainer:
duration: 64.95523810386658s
INFO    [05-06 12:36:05] train in BasicTrainer:
epoch: 13
INFO    [05-06 12:36:30] _train_one_epoch in BasicTrainer:
loss = 21.776795378676407
INFO    [05-06 12:37:11] log in loggers:
Update Best NDCG@10 Model at 13
INFO    [05-06 12:37:12] validate in BasicTrainer:
{'Recall@10': 0.05273343190550804, 'NDCG@10': 0.029447634369134904, 'MRR@10': 0.02237177677452564, 'Recall@5': 0.035794851034879685, 'NDCG@5': 0.024006247445940973, 'MRR@5': 0.020147213265299797, 'Recall*@10': 0.05705084040760994, 'NDCG*@10': 0.03191749967634678, 'MRR*@10': 0.02428220234811306, 'Recall*@5': 0.03871529668569565, 'NDCG*@5': 0.02603026032447815, 'MRR*@5': 0.02187702864408493}
INFO    [05-06 12:37:12] train in BasicTrainer:
duration: 66.94119453430176s
INFO    [05-06 12:37:12] train in BasicTrainer:
epoch: 14
INFO    [05-06 12:37:36] _train_one_epoch in BasicTrainer:
loss = 21.731353295815957
INFO    [05-06 12:38:17] log in loggers:
Update Best NDCG@10 Model at 14
INFO    [05-06 12:38:18] validate in BasicTrainer:
{'Recall@10': 0.05344739392399788, 'NDCG@10': 0.0296281498670578, 'MRR@10': 0.02240593731403351, 'Recall@5': 0.03562829971313477, 'NDCG@5': 0.0239033742249012, 'MRR@5': 0.0200656758248806, 'Recall*@10': 0.05780150219798088, 'NDCG*@10': 0.03208332784473896, 'MRR*@10': 0.024286142215132714, 'Recall*@5': 0.038509996831417086, 'NDCG*@5': 0.025885829254984855, 'MRR*@5': 0.02175282970070839}
INFO    [05-06 12:38:18] train in BasicTrainer:
duration: 65.90872597694397s
INFO    [05-06 12:38:18] train in BasicTrainer:
epoch: 15
INFO    [05-06 12:38:42] _train_one_epoch in BasicTrainer:
loss = 21.689069009042
INFO    [05-06 12:39:22] log in loggers:
Update Best NDCG@10 Model at 15
INFO    [05-06 12:39:23] validate in BasicTrainer:
{'Recall@10': 0.054146110117435454, 'NDCG@10': 0.029885246977210046, 'MRR@10': 0.02253261744976044, 'Recall@5': 0.036068288534879686, 'NDCG@5': 0.024099603444337845, 'MRR@5': 0.02017946943640709, 'Recall*@10': 0.05840604677796364, 'NDCG*@10': 0.03232879772782326, 'MRR*@10': 0.024423369616270067, 'Recall*@5': 0.03908859811723232, 'NDCG*@5': 0.026147103682160378, 'MRR*@5': 0.02190960995852947}
INFO    [05-06 12:39:23] train in BasicTrainer:
duration: 65.02031421661377s
INFO    [05-06 12:39:23] train in BasicTrainer:
epoch: 16
INFO    [05-06 12:39:48] _train_one_epoch in BasicTrainer:
loss = 21.652869490889817
INFO    [05-06 12:40:29] log in loggers:
Update Best NDCG@10 Model at 16
INFO    [05-06 12:40:30] validate in BasicTrainer:
{'Recall@10': 0.05424430206418038, 'NDCG@10': 0.03021870717406273, 'MRR@10': 0.022917742133140562, 'Recall@5': 0.0365180429816246, 'NDCG@5': 0.024505773335695268, 'MRR@5': 0.020571008548140524, 'Recall*@10': 0.058660753220319745, 'NDCG*@10': 0.032769378274679184, 'MRR*@10': 0.024909324198961257, 'Recall*@5': 0.03935591787099838, 'NDCG*@5': 0.02655079334974289, 'MRR*@5': 0.022356716096401216}
INFO    [05-06 12:40:30] train in BasicTrainer:
duration: 66.57655096054077s
INFO    [05-06 12:40:30] train in BasicTrainer:
epoch: 17
INFO    [05-06 12:40:53] _train_one_epoch in BasicTrainer:
loss = 21.617234221449845
INFO    [05-06 12:41:34] validate in BasicTrainer:
{'Recall@10': 0.05429045185446739, 'NDCG@10': 0.030132654383778573, 'MRR@10': 0.022818100973963737, 'Recall@5': 0.03594347804784775, 'NDCG@5': 0.024237479940056803, 'MRR@5': 0.0204068373888731, 'Recall*@10': 0.058478075563907626, 'NDCG*@10': 0.032479602620005606, 'MRR*@10': 0.024606730714440347, 'Recall*@5': 0.03881770446896553, 'NDCG*@5': 0.026158667728304864, 'MRR*@5': 0.0220191241055727}
INFO    [05-06 12:41:34] train in BasicTrainer:
duration: 64.16940808296204s
INFO    [05-06 12:41:34] train in BasicTrainer:
epoch: 18
INFO    [05-06 12:41:58] _train_one_epoch in BasicTrainer:
loss = 21.586559570587433
INFO    [05-06 12:42:39] log in loggers:
Update Best NDCG@10 Model at 18
INFO    [05-06 12:42:40] validate in BasicTrainer:
{'Recall@10': 0.05435011699795723, 'NDCG@10': 0.030426624342799188, 'MRR@10': 0.023157544359564783, 'Recall@5': 0.03634333297610283, 'NDCG@5': 0.0246281448751688, 'MRR@5': 0.02077830284833908, 'Recall*@10': 0.058322929441928864, 'NDCG*@10': 0.03262305364012718, 'MRR*@10': 0.02481199085712433, 'Recall*@5': 0.03903197169303894, 'NDCG*@5': 0.026408616825938223, 'MRR*@5': 0.022260579839348794}
INFO    [05-06 12:42:40] train in BasicTrainer:
duration: 66.21231603622437s
INFO    [05-06 12:42:40] train in BasicTrainer:
epoch: 19
INFO    [05-06 12:43:04] _train_one_epoch in BasicTrainer:
loss = 21.555016440314215
INFO    [05-06 12:43:44] log in loggers:
Update Best NDCG@10 Model at 19
INFO    [05-06 12:43:45] validate in BasicTrainer:
{'Recall@10': 0.055462862551212314, 'NDCG@10': 0.030846881344914437, 'MRR@10': 0.0233813451975584, 'Recall@5': 0.0370610448718071, 'NDCG@5': 0.024943590611219407, 'MRR@5': 0.02097277596592903, 'Recall*@10': 0.05994617015123367, 'NDCG*@10': 0.03332704775035381, 'MRR*@10': 0.02525520361959934, 'Recall*@5': 0.04005805402994156, 'NDCG*@5': 0.026938551366329194, 'MRR*@5': 0.022643692195415496}
INFO    [05-06 12:43:45] train in BasicTrainer:
duration: 64.91223931312561s
INFO    [05-06 12:43:45] train in BasicTrainer:
epoch: 20
INFO    [05-06 12:44:09] _train_one_epoch in BasicTrainer:
loss = 21.523506765967017
INFO    [05-06 12:44:51] log in loggers:
Update Best NDCG@10 Model at 20
INFO    [05-06 12:44:52] validate in BasicTrainer:
{'Recall@10': 0.05537002742290497, 'NDCG@10': 0.031095266342163086, 'MRR@10': 0.023722719624638556, 'Recall@5': 0.037717484533786774, 'NDCG@5': 0.025432378202676773, 'MRR@5': 0.021412171497941015, 'Recall*@10': 0.05953886449337006, 'NDCG*@10': 0.03342181071639061, 'MRR*@10': 0.025491194128990174, 'Recall*@5': 0.040529692471027376, 'NDCG*@5': 0.02731891080737114, 'MRR*@5': 0.022998156547546385}
INFO    [05-06 12:44:52] train in BasicTrainer:
duration: 66.54132199287415s
INFO    [05-06 12:44:52] train in BasicTrainer:
epoch: 21
INFO    [05-06 12:45:15] _train_one_epoch in BasicTrainer:
loss = 21.499018316870337
INFO    [05-06 12:45:57] log in loggers:
Update Best NDCG@10 Model at 21
INFO    [05-06 12:45:57] validate in BasicTrainer:
{'Recall@10': 0.05644960314035416, 'NDCG@10': 0.031698472797870636, 'MRR@10': 0.024186821579933168, 'Recall@5': 0.03798276349902153, 'NDCG@5': 0.025772479325532914, 'MRR@5': 0.02176777273416519, 'Recall*@10': 0.060663744956254956, 'NDCG*@10': 0.03410609155893326, 'MRR*@10': 0.026045516952872275, 'Recall*@5': 0.04095542624592781, 'NDCG*@5': 0.027783904150128366, 'MRR*@5': 0.02346616618335247}
INFO    [05-06 12:45:57] train in BasicTrainer:
duration: 65.89260244369507s
INFO    [05-06 12:45:57] train in BasicTrainer:
epoch: 22
INFO    [05-06 12:46:21] _train_one_epoch in BasicTrainer:
loss = 21.47318260948937
INFO    [05-06 12:47:02] log in loggers:
Update Best NDCG@10 Model at 22
INFO    [05-06 12:47:03] validate in BasicTrainer:
{'Recall@10': 0.05659394472837448, 'NDCG@10': 0.03185105890035629, 'MRR@10': 0.02434742622077465, 'Recall@5': 0.03783199355006218, 'NDCG@5': 0.025813381895422937, 'MRR@5': 0.02187305487692356, 'Recall*@10': 0.060756475627422334, 'NDCG*@10': 0.03416428931057453, 'MRR*@10': 0.02609820730984211, 'Recall*@5': 0.040708143562078476, 'NDCG*@5': 0.027714951187372206, 'MRR*@5': 0.023456428572535513}
INFO    [05-06 12:47:03] train in BasicTrainer:
duration: 65.07986044883728s
INFO    [05-06 12:47:03] train in BasicTrainer:
epoch: 23
INFO    [05-06 12:47:27] _train_one_epoch in BasicTrainer:
loss = 21.454043500058287
INFO    [05-06 12:48:09] log in loggers:
Update Best NDCG@10 Model at 23
INFO    [05-06 12:48:09] validate in BasicTrainer:
{'Recall@10': 0.056763297617435454, 'NDCG@10': 0.03208466075360775, 'MRR@10': 0.024592623710632325, 'Recall@5': 0.0382986007630825, 'NDCG@5': 0.026147413775324823, 'MRR@5': 0.02216173991560936, 'Recall*@10': 0.060909679532051085, 'NDCG*@10': 0.03437028788030148, 'MRR*@10': 0.02631386712193489, 'Recall*@5': 0.04108125224709511, 'NDCG*@5': 0.027993625849485396, 'MRR*@5': 0.023702584356069565}
INFO    [05-06 12:48:09] train in BasicTrainer:
duration: 66.715176820755s
INFO    [05-06 12:48:09] train in BasicTrainer:
epoch: 24
INFO    [05-06 12:48:33] _train_one_epoch in BasicTrainer:
loss = 21.433918119550825
INFO    [05-06 12:49:14] log in loggers:
Update Best NDCG@10 Model at 24
INFO    [05-06 12:49:14] validate in BasicTrainer:
{'Recall@10': 0.05722549617290497, 'NDCG@10': 0.03229170843958855, 'MRR@10': 0.024739521890878677, 'Recall@5': 0.03820308730006218, 'NDCG@5': 0.026176372691988945, 'MRR@5': 0.02223631978034973, 'Recall*@10': 0.06147476390004158, 'NDCG*@10': 0.034724185764789584, 'MRR*@10': 0.026620527133345603, 'Recall*@5': 0.041165045350790026, 'NDCG*@5': 0.028193655908107757, 'MRR*@5': 0.023946538269519806}
INFO    [05-06 12:49:14] train in BasicTrainer:
duration: 65.04463934898376s
INFO    [05-06 12:49:14] train in BasicTrainer:
epoch: 25
INFO    [05-06 12:49:39] _train_one_epoch in BasicTrainer:
loss = 21.41663580542212
INFO    [05-06 12:50:21] log in loggers:
Update Best NDCG@10 Model at 25
INFO    [05-06 12:50:21] validate in BasicTrainer:
{'Recall@10': 0.05813905626535416, 'NDCG@10': 0.03294432982802391, 'MRR@10': 0.02530693918466568, 'Recall@5': 0.038899125158786775, 'NDCG@5': 0.0267615270614624, 'MRR@5': 0.022778181582689284, 'Recall*@10': 0.06220853999257088, 'NDCG*@10': 0.03531431205570698, 'MRR*@10': 0.027161566317081453, 'Recall*@5': 0.041843456029891965, 'NDCG*@5': 0.028773812800645827, 'MRR*@5': 0.02448875769972801}
INFO    [05-06 12:50:21] train in BasicTrainer:
duration: 66.96612787246704s
INFO    [05-06 12:50:21] train in BasicTrainer:
epoch: 26
INFO    [05-06 12:50:45] _train_one_epoch in BasicTrainer:
loss = 21.398234564978797
INFO    [05-06 12:51:26] log in loggers:
Update Best NDCG@10 Model at 26
INFO    [05-06 12:51:27] validate in BasicTrainer:
{'Recall@10': 0.05799257189035416, 'NDCG@10': 0.03302347056567669, 'MRR@10': 0.025443933680653574, 'Recall@5': 0.039214303493499754, 'NDCG@5': 0.0269927379488945, 'MRR@5': 0.02298004202544689, 'Recall*@10': 0.0622921733558178, 'NDCG*@10': 0.03547851882874966, 'MRR*@10': 0.027341718152165413, 'Recall*@5': 0.0421131819486618, 'NDCG*@5': 0.029002087339758873, 'MRR*@5': 0.0246982029825449}
INFO    [05-06 12:51:27] train in BasicTrainer:
duration: 65.78033471107483s
INFO    [05-06 12:51:27] train in BasicTrainer:
epoch: 27
INFO    [05-06 12:51:51] _train_one_epoch in BasicTrainer:
loss = 21.38591042939607
INFO    [05-06 12:52:32] log in loggers:
Update Best NDCG@10 Model at 27
INFO    [05-06 12:52:32] validate in BasicTrainer:
{'Recall@10': 0.05872058510780334, 'NDCG@10': 0.033499276265501976, 'MRR@10': 0.025849631056189537, 'Recall@5': 0.03978404715657234, 'NDCG@5': 0.027438104525208472, 'MRR@5': 0.02338466316461563, 'Recall*@10': 0.06265867933630943, 'NDCG*@10': 0.03573622569441795, 'MRR*@10': 0.02756855048239231, 'Recall*@5': 0.04254135072231293, 'NDCG*@5': 0.029295151233673097, 'MRR*@5': 0.02494791179895401}
INFO    [05-06 12:52:32] train in BasicTrainer:
duration: 65.46014499664307s
INFO    [05-06 12:52:32] train in BasicTrainer:
epoch: 28
INFO    [05-06 12:52:57] _train_one_epoch in BasicTrainer:
loss = 21.370546014459283
INFO    [05-06 12:53:38] log in loggers:
Update Best NDCG@10 Model at 28
INFO    [05-06 12:53:39] validate in BasicTrainer:
{'Recall@10': 0.05897568583488464, 'NDCG@10': 0.0337277914583683, 'MRR@10': 0.026059499457478524, 'Recall@5': 0.04009642392396927, 'NDCG@5': 0.02765156239271164, 'MRR@5': 0.02356876038014889, 'Recall*@10': 0.06316498890519143, 'NDCG*@10': 0.03610455244779587, 'MRR*@10': 0.027884170487523077, 'Recall*@5': 0.043038374930620196, 'NDCG*@5': 0.029624063968658448, 'MRR*@5': 0.0252261658012867}
INFO    [05-06 12:53:39] train in BasicTrainer:
duration: 66.18033576011658s
INFO    [05-06 12:53:39] train in BasicTrainer:
epoch: 29
INFO    [05-06 12:54:02] _train_one_epoch in BasicTrainer:
loss = 21.359638334394575
INFO    [05-06 12:54:43] log in loggers:
Update Best NDCG@10 Model at 29
INFO    [05-06 12:54:44] validate in BasicTrainer:
{'Recall@10': 0.059928308427333835, 'NDCG@10': 0.034282421320676805, 'MRR@10': 0.026488879695534706, 'Recall@5': 0.04100141286849976, 'NDCG@5': 0.02819220572710037, 'MRR@5': 0.02399309679865837, 'Recall*@10': 0.06412666246294975, 'NDCG*@10': 0.0365878739207983, 'MRR*@10': 0.028219768553972246, 'Recall*@5': 0.043963015526533124, 'NDCG*@5': 0.030105654448270798, 'MRR*@5': 0.02556676372885704}
INFO    [05-06 12:54:44] train in BasicTrainer:
duration: 65.15764093399048s
INFO    [05-06 12:54:44] train in BasicTrainer:
epoch: 30
INFO    [05-06 12:55:08] _train_one_epoch in BasicTrainer:
loss = 21.351533236804308
INFO    [05-06 12:55:49] log in loggers:
Update Best NDCG@10 Model at 30
INFO    [05-06 12:55:50] validate in BasicTrainer:
{'Recall@10': 0.05991252690553665, 'NDCG@10': 0.03441754348576069, 'MRR@10': 0.02667814463376999, 'Recall@5': 0.04085439294576645, 'NDCG@5': 0.028280088379979133, 'MRR@5': 0.024159879758954048, 'Recall*@10': 0.06385284796357155, 'NDCG*@10': 0.03665988408029079, 'MRR*@10': 0.02839817903935909, 'Recall*@5': 0.04365763783454895, 'NDCG*@5': 0.030149879306554793, 'MRR*@5': 0.025723268911242485}
INFO    [05-06 12:55:50] train in BasicTrainer:
duration: 66.33969283103943s
INFO    [05-06 12:55:50] train in BasicTrainer:
epoch: 31
INFO    [05-06 12:56:14] _train_one_epoch in BasicTrainer:
loss = 21.34268413578068
INFO    [05-06 12:56:54] log in loggers:
Update Best NDCG@10 Model at 31
INFO    [05-06 12:56:55] validate in BasicTrainer:
{'Recall@10': 0.060130707919597626, 'NDCG@10': 0.03453042022883892, 'MRR@10': 0.026760147884488106, 'Recall@5': 0.041077395230531694, 'NDCG@5': 0.02840201459825039, 'MRR@5': 0.02424980454146862, 'Recall*@10': 0.06442948520183563, 'NDCG*@10': 0.03689886823296547, 'MRR*@10': 0.028544676899909974, 'Recall*@5': 0.04388903841376304, 'NDCG*@5': 0.030292502865195275, 'MRR*@5': 0.025838744193315506}
INFO    [05-06 12:56:55] train in BasicTrainer:
duration: 64.63415908813477s
INFO    [05-06 12:56:55] train in BasicTrainer:
epoch: 32
INFO    [05-06 12:57:19] _train_one_epoch in BasicTrainer:
loss = 21.341518109983152
INFO    [05-06 12:58:02] log in loggers:
Update Best NDCG@10 Model at 32
INFO    [05-06 12:58:02] validate in BasicTrainer:
{'Recall@10': 0.060003095865249635, 'NDCG@10': 0.034870351180434224, 'MRR@10': 0.027226867154240608, 'Recall@5': 0.0417212675511837, 'NDCG@5': 0.028998218849301337, 'MRR@5': 0.02482656456530094, 'Recall*@10': 0.06411044865846634, 'NDCG*@10': 0.03712758496403694, 'MRR*@10': 0.028917871341109277, 'Recall*@5': 0.04471394628286362, 'NDCG*@5': 0.030899034664034843, 'MRR*@5': 0.02637277841567993}
INFO    [05-06 12:58:02] train in BasicTrainer:
duration: 67.57795095443726s
INFO    [05-06 12:58:02] train in BasicTrainer:
epoch: 33
INFO    [05-06 12:58:26] _train_one_epoch in BasicTrainer:
loss = 21.33996667947855
INFO    [05-06 12:59:07] log in loggers:
Update Best NDCG@10 Model at 33
INFO    [05-06 12:59:08] validate in BasicTrainer:
{'Recall@10': 0.0603867569565773, 'NDCG@10': 0.034954035580158235, 'MRR@10': 0.027214192673563956, 'Recall@5': 0.04173276349902153, 'NDCG@5': 0.028941276669502258, 'MRR@5': 0.024743938520550728, 'Recall*@10': 0.06434444129467011, 'NDCG*@10': 0.0372774201631546, 'MRR*@10': 0.02903677485883236, 'Recall*@5': 0.04475439444184303, 'NDCG*@5': 0.030967599228024483, 'MRR*@5': 0.02644694522023201}
INFO    [05-06 12:59:08] train in BasicTrainer:
duration: 65.70574712753296s
INFO    [05-06 12:59:08] train in BasicTrainer:
epoch: 34
INFO    [05-06 12:59:32] _train_one_epoch in BasicTrainer:
loss = 21.337330603384757
INFO    [05-06 13:00:12] log in loggers:
Update Best NDCG@10 Model at 34
INFO    [05-06 13:00:13] validate in BasicTrainer:
{'Recall@10': 0.06105403363704681, 'NDCG@10': 0.035362554788589476, 'MRR@10': 0.027557998672127725, 'Recall@5': 0.04198988378047943, 'NDCG@5': 0.029233742952346802, 'MRR@5': 0.025049739480018617, 'Recall*@10': 0.06534187704324722, 'NDCG*@10': 0.03774207532405853, 'MRR*@10': 0.02935964524745941, 'Recall*@5': 0.04480283945798874, 'NDCG*@5': 0.031134963259100912, 'MRR*@5': 0.026653074398636817}
INFO    [05-06 13:00:13] train in BasicTrainer:
duration: 65.1345112323761s
INFO    [05-06 13:00:13] train in BasicTrainer:
epoch: 35
INFO    [05-06 13:00:38] _train_one_epoch in BasicTrainer:
loss = 21.33693030073836
INFO    [05-06 13:01:19] log in loggers:
Update Best NDCG@10 Model at 35
INFO    [05-06 13:01:20] validate in BasicTrainer:
{'Recall@10': 0.06150485932826996, 'NDCG@10': 0.03560636803507805, 'MRR@10': 0.02773892156779766, 'Recall@5': 0.04236419171094894, 'NDCG@5': 0.02945941634476185, 'MRR@5': 0.025226944088935853, 'Recall*@10': 0.06570993334054948, 'NDCG*@10': 0.03796718746423721, 'MRR*@10': 0.029531852677464485, 'Recall*@5': 0.04550843238830567, 'NDCG*@5': 0.03147525429725647, 'MRR*@5': 0.026876360774040223}
INFO    [05-06 13:01:20] train in BasicTrainer:
duration: 66.35444903373718s
INFO    [05-06 13:01:20] train in BasicTrainer:
epoch: 36
INFO    [05-06 13:01:43] _train_one_epoch in BasicTrainer:
loss = 21.337588610949815
