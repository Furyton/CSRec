INFO    [02-27 18:43:18] setup_train in utils:
{
    "experiment_dir": "___lfms_ensemble_distill_partial_trained_2022",
    "experiment_description": "ed",
    "describe": "{config[model_code]}-en-{config[weight_list][0]}-T-{config[T]}-al-{config[alpha]}-sr-{config[sample_rate]}",
    "dataset_name": "lastfm_small.csv",
    "sched": "ensemble_distill",
    "model_code": "nextitnet",
    "mentor_code": "nextitnet",
    "mentor2_code": "nextitnet",
    "weight_list": [
        0.5,
        0.5
    ],
    "alpha": 0.5,
    "T": 3.0,
    "training_routine": "student",
    "softmaxed_mentor": true,
    "enable_auto_path_finder": true,
    "mentor_state_path": "___lfms_base_partial_2022",
    "mentor_seed1": 2000,
    "mentor_seed2": 2001,
    "mentor_describe": "{config[model_code]}-rate-{config[sample_rate]}-seed-{config[sample_seed]}",
    "sample_rate": 0.8,
    "num_epochs": 60,
    "mode": "train",
    "max_len": 20,
    "test_state_path": null,
    "model_state_path": null,
    "rand_seed": 2022,
    "load_processed_dataset": true,
    "save_processed_dataset": false,
    "dataset_cache_filename": null,
    "weight_decay": 0,
    "decay_step": 15,
    "gamma": 0.99,
    "lr": 0.001,
    "min_length": 5,
    "min_item_inter": 5,
    "good_only": false,
    "use_rating": true,
    "test_negative_sampler_code": "random",
    "test_negative_sample_size": 0,
    "dataloader_type": "next",
    "train_batch_size": 64,
    "val_batch_size": 64,
    "test_batch_size": 64,
    "prop_sliding_window": -1.0,
    "worker_number": 2,
    "metric_ks": [
        5,
        10
    ],
    "device": "cuda",
    "num_gpu": 1,
    "optimizer": "Adam",
    "best_metric": "NDCG@10",
    "show_process_bar": false,
    "enable_sample": false,
    "samples_ratio": 0.1,
    "config_file": "config2.lastfm_small/nextitnet/config_distill_ensemble_partial.json",
    "task_id": 17,
    "split": "leave_one_out",
    "do_remap": true,
    "do_sampling": false,
    "path_for_sample": null,
    "sample_seed": 0,
    "train_negative_sampler_code": "random",
    "train_negative_sample_size": 100,
    "device_idx": "0",
    "momentum": null,
    "log_period_as_iter": 12800,
    "dvae_alpha": 0.5,
    "validation_rate": 0.2,
    "num_items": null,
    "start_index": 1,
    "kwargs": null
}
INFO    [02-27 18:43:18] _load_full_dataset_from_path in utils:
loading cache from /data/wushiguang-slurm/code/gitee-repos/soft-rec/Data/Cache/lastfm_small-5-5.pkl
INFO    [02-27 18:43:18] _check_dataset_cache in utils:
check if the cache is generated under this configuration
INFO    [02-27 18:43:18] _check_dataset_cache in utils:
correct.
INFO    [02-27 18:43:18] __init__ in NextItemDataloader:
there are 3646 items in this dataset, 3173 users, padding_first? True
DEBUG   [02-27 18:43:21] generate_model in utils:
model_code_list=['nextitnet']
INFO    [02-27 18:43:21] load_model_config in utils:
loading model nextitnet's config file at asset/config/model/nextitnet.json
INFO    [02-27 18:43:21] load_model_config in utils:
{
    "embedding_size": 64,
    "kernel_size": 3,
    "block_num": 5,
    "dilations": [
        1
    ],
    "reg_weight": 5e-06,
    "loss_type": "CE"
}
WARNING [02-27 18:43:31] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher1_nextitnet_logs does not exist! Create one.
WARNING [02-27 18:43:31] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher1_nextitnet_logs/tb_vis does not exist! Create one.
WARNING [02-27 18:43:31] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher1_nextitnet_logs/checkpoint does not exist! Create one.
INFO    [02-27 18:43:31] load_state_from_given_path in utils:
checkpoint epoch: 35
INFO    [02-27 18:43:31] load_state_from_given_path in utils:
Loading model's parameters
INFO    [02-27 18:43:31] load_state_from_given_path in utils:
Loading optimizer's parameters
DEBUG   [02-27 18:43:31] _generate_teacher_trainer in EnsembleDistillSched:
teacher1_nextitnet: 
NextItNet(
  (item_embedding): Embedding(3647, 64, padding_idx=0)
  (residual_blocks): Sequential(
    (0): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (1): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (2): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (3): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (4): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
  )
  (final_layer): Linear(in_features=64, out_features=64, bias=True)
  (loss_fct): CrossEntropyLoss()
  (reg_loss): RegLoss()
)
INFO    [02-27 18:43:31] assert_model_device in utils:
model teacher1_nextitnet has 1.38232421875 MB params.
INFO    [02-27 18:43:31] __init__ in BasicTrainer:
48256 iter per epoch
DEBUG   [02-27 18:43:31] generate_model in utils:
model_code_list=['nextitnet']
INFO    [02-27 18:43:31] load_model_config in utils:
loading model nextitnet's config file at asset/config/model/nextitnet.json
INFO    [02-27 18:43:31] load_model_config in utils:
{
    "embedding_size": 64,
    "kernel_size": 3,
    "block_num": 5,
    "dilations": [
        1
    ],
    "reg_weight": 5e-06,
    "loss_type": "CE"
}
WARNING [02-27 18:43:32] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher2_nextitnet_logs does not exist! Create one.
WARNING [02-27 18:43:32] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher2_nextitnet_logs/tb_vis does not exist! Create one.
WARNING [02-27 18:43:32] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/teacher2_nextitnet_logs/checkpoint does not exist! Create one.
INFO    [02-27 18:43:32] load_state_from_given_path in utils:
checkpoint epoch: 21
INFO    [02-27 18:43:32] load_state_from_given_path in utils:
Loading model's parameters
INFO    [02-27 18:43:32] load_state_from_given_path in utils:
Loading optimizer's parameters
DEBUG   [02-27 18:43:32] _generate_teacher_trainer in EnsembleDistillSched:
teacher2_nextitnet: 
NextItNet(
  (item_embedding): Embedding(3647, 64, padding_idx=0)
  (residual_blocks): Sequential(
    (0): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (1): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (2): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (3): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (4): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
  )
  (final_layer): Linear(in_features=64, out_features=64, bias=True)
  (loss_fct): CrossEntropyLoss()
  (reg_loss): RegLoss()
)
INFO    [02-27 18:43:32] assert_model_device in utils:
model teacher2_nextitnet has 1.38232421875 MB params.
INFO    [02-27 18:43:32] __init__ in BasicTrainer:
48256 iter per epoch
DEBUG   [02-27 18:43:32] generate_model in utils:
model_code_list=['nextitnet']
INFO    [02-27 18:43:32] load_model_config in utils:
loading model nextitnet's config file at asset/config/model/nextitnet.json
INFO    [02-27 18:43:32] load_model_config in utils:
{
    "embedding_size": 64,
    "kernel_size": 3,
    "block_num": 5,
    "dilations": [
        1
    ],
    "reg_weight": 5e-06,
    "loss_type": "CE"
}
WARNING [02-27 18:43:33] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/student_nextitnet_logs does not exist! Create one.
WARNING [02-27 18:43:33] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/student_nextitnet_logs/tb_vis does not exist! Create one.
WARNING [02-27 18:43:33] get_exist_path in utils:
dir ___lfms_ensemble_distill_partial_trained_2022/ed_nextitnet-en-0.5-T-3.0-al-0.5-sr-0.8_02-27_18:43_t17/student_nextitnet_logs/checkpoint does not exist! Create one.
WARNING [02-27 18:43:33] get_path in utils:
Path is None
WARNING [02-27 18:43:33] load_state_from_given_path in utils:
Not given any path.
DEBUG   [02-27 18:43:33] _generate_student_trainer in EnsembleDistillSched:
student_nextitnet: 
NextItNet(
  (item_embedding): Embedding(3647, 64, padding_idx=0)
  (residual_blocks): Sequential(
    (0): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (1): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (2): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (3): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (4): ResidualBlock_b(
      (conv1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1))
      (ln1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      (conv2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))
      (ln2): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
  )
  (final_layer): Linear(in_features=64, out_features=64, bias=True)
  (loss_fct): CrossEntropyLoss()
  (reg_loss): RegLoss()
)
INFO    [02-27 18:43:33] assert_model_device in utils:
model student_nextitnet has 1.38232421875 MB params.
INFO    [02-27 18:43:33] assert_model_device in utils:
model mix_nextitnet_nextitnet has 0.0 MB params.
INFO    [02-27 18:43:33] assert_model_device in utils:
model mix_nextitnet_nextitnet has no param
INFO    [02-27 18:43:33] __init__ in DistillTrainer:
48256 iter per epoch
INFO    [02-27 18:43:33] _set_current_routine in Routine:
first routine: student
INFO    [02-27 18:43:33] run_routine in Routine:
Start routine student
INFO    [02-27 18:43:33] run_routine in Routine:
Start training
INFO    [02-27 18:43:33] train in DistillTrainer:
Test mentor model: mix_nextitnet_nextitnet
DEBUG   [02-27 18:43:35] forward in Ensembler:
raw predict
DEBUG   [02-27 18:43:35] forward in Ensembler:
[tensor([[8.1518e-07, 9.4239e-06, 1.7203e-07,  ..., 5.0294e-06, 2.7580e-06,
         1.2221e-05],
        [2.8907e-06, 8.2139e-04, 1.6359e-09,  ..., 2.3190e-05, 2.2660e-07,
         7.1865e-05],
        [5.5780e-06, 3.5061e-05, 2.3956e-07,  ..., 8.4142e-08, 5.2386e-05,
         1.2734e-04],
        ...,
        [1.8477e-06, 6.8706e-05, 5.3183e-07,  ..., 7.1969e-06, 1.8633e-08,
         1.9450e-07],
        [8.4716e-07, 1.8737e-04, 3.4653e-08,  ..., 1.3224e-05, 3.9700e-09,
         4.5672e-09],
        [3.6543e-07, 8.3184e-04, 1.3516e-08,  ..., 5.3860e-06, 1.9303e-07,
         1.7417e-06]], device='cuda:0'), tensor([[1.5799e-06, 1.0030e-05, 6.6941e-06,  ..., 4.9774e-06, 1.0676e-05,
         1.0070e-08],
        [1.7597e-06, 1.2005e-05, 8.7226e-05,  ..., 2.2366e-06, 1.4012e-06,
         1.2204e-06],
        [3.8422e-06, 7.1308e-05, 2.6633e-07,  ..., 6.3558e-04, 1.2959e-05,
         2.0279e-08],
        ...,
        [2.3814e-06, 9.1101e-06, 2.3031e-07,  ..., 3.8886e-05, 1.1949e-06,
         3.4248e-08],
        [8.8759e-06, 7.4626e-06, 1.8263e-06,  ..., 2.1354e-04, 1.9449e-05,
         9.1086e-08],
        [4.3725e-06, 6.0281e-06, 5.3190e-06,  ..., 1.9832e-04, 5.4118e-08,
         1.8421e-06]], device='cuda:0')]
DEBUG   [02-27 18:43:35] forward in Ensembler:
raw confidence
DEBUG   [02-27 18:43:35] forward in Ensembler:
[tensor([0.4837, 0.1611, 0.0387, 0.2129, 0.2954, 0.1797, 0.1423, 0.0822, 0.0971,
        0.1474, 0.1172, 0.0641, 0.1163, 0.1019, 0.2138, 0.3823, 0.0845, 0.0968,
        0.1172, 0.1587, 0.2047, 0.3765, 0.0371, 0.1008, 0.1807, 0.1675, 0.1142,
        0.0674, 0.0925, 0.0361, 0.0819, 0.1378, 0.0763, 0.0590, 0.3057, 0.4506,
        0.0604, 0.1612, 0.1350, 0.1180, 0.1041, 0.2031, 0.1372, 0.1479, 0.3938,
        0.0826, 0.0635, 0.0635, 0.4944, 0.3942, 0.0982, 0.0799, 0.2242, 0.2817,
        0.0711, 0.1207, 0.0300, 0.1358, 0.2756, 0.1997, 0.1352, 0.0727, 0.7790,
        0.1382], device='cuda:0'), tensor([0.0315, 0.0636, 0.0572, 0.0734, 0.0611, 0.0857, 0.1634, 0.0524, 0.0706,
        0.0209, 0.0172, 0.0228, 0.0704, 0.1160, 0.1347, 0.0867, 0.0686, 0.0870,
        0.0519, 0.0296, 0.0356, 0.0419, 0.0360, 0.0343, 0.0785, 0.0411, 0.0603,
        0.0261, 0.0620, 0.0246, 0.0549, 0.0265, 0.0608, 0.0429, 0.0288, 0.0397,
        0.0475, 0.0606, 0.0284, 0.0491, 0.0486, 0.1810, 0.0510, 0.0235, 0.0451,
        0.0245, 0.0259, 0.0402, 0.0558, 0.1022, 0.0427, 0.1468, 0.0338, 0.0244,
        0.0524, 0.0314, 0.0148, 0.0223, 0.0694, 0.1015, 0.0500, 0.0760, 0.0322,
        0.0864], device='cuda:0')]
DEBUG   [02-27 18:43:35] forward in Ensembler:
weighted predict
DEBUG   [02-27 18:43:35] forward in Ensembler:
[tensor([[4.0759e-07, 4.7119e-06, 8.6015e-08,  ..., 2.5147e-06, 1.3790e-06,
         6.1103e-06],
        [1.4453e-06, 4.1069e-04, 8.1794e-10,  ..., 1.1595e-05, 1.1330e-07,
         3.5933e-05],
        [2.7890e-06, 1.7531e-05, 1.1978e-07,  ..., 4.2071e-08, 2.6193e-05,
         6.3672e-05],
        ...,
        [9.2387e-07, 3.4353e-05, 2.6591e-07,  ..., 3.5984e-06, 9.3163e-09,
         9.7252e-08],
        [4.2358e-07, 9.3684e-05, 1.7327e-08,  ..., 6.6121e-06, 1.9850e-09,
         2.2836e-09],
        [1.8272e-07, 4.1592e-04, 6.7578e-09,  ..., 2.6930e-06, 9.6513e-08,
         8.7084e-07]], device='cuda:0'), tensor([[7.8995e-07, 5.0148e-06, 3.3470e-06,  ..., 2.4887e-06, 5.3381e-06,
         5.0350e-09],
        [8.7987e-07, 6.0023e-06, 4.3613e-05,  ..., 1.1183e-06, 7.0062e-07,
         6.1018e-07],
        [1.9211e-06, 3.5654e-05, 1.3316e-07,  ..., 3.1779e-04, 6.4797e-06,
         1.0140e-08],
        ...,
        [1.1907e-06, 4.5550e-06, 1.1516e-07,  ..., 1.9443e-05, 5.9743e-07,
         1.7124e-08],
        [4.4379e-06, 3.7313e-06, 9.1315e-07,  ..., 1.0677e-04, 9.7243e-06,
         4.5543e-08],
        [2.1862e-06, 3.0140e-06, 2.6595e-06,  ..., 9.9162e-05, 2.7059e-08,
         9.2105e-07]], device='cuda:0')]
DEBUG   [02-27 18:43:35] forward in Ensembler:
final predict
DEBUG   [02-27 18:43:35] forward in Ensembler:
tensor([[1.1975e-06, 9.7267e-06, 3.4331e-06,  ..., 5.0034e-06, 6.7172e-06,
         6.1153e-06],
        [2.3252e-06, 4.1670e-04, 4.3614e-05,  ..., 1.2714e-05, 8.1392e-07,
         3.6543e-05],
        [4.7101e-06, 5.3185e-05, 2.5294e-07,  ..., 3.1783e-04, 3.2673e-05,
         6.3683e-05],
        ...,
        [2.1146e-06, 3.8908e-05, 3.8107e-07,  ..., 2.3042e-05, 6.0675e-07,
         1.1438e-07],
        [4.8615e-06, 9.7416e-05, 9.3047e-07,  ..., 1.1338e-04, 9.7263e-06,
         4.7827e-08],
        [2.3689e-06, 4.1893e-04, 2.6663e-06,  ..., 1.0186e-04, 1.2357e-07,
         1.7919e-06]], device='cuda:0')
DEBUG   [02-27 18:43:35] forward in Ensembler:
final confidence
DEBUG   [02-27 18:43:35] forward in Ensembler:
tensor([0.2420, 0.0807, 0.0287, 0.1065, 0.1526, 0.1023, 0.0867, 0.0475, 0.0502,
        0.0739, 0.0603, 0.0322, 0.0585, 0.0629, 0.1075, 0.1941, 0.0425, 0.0499,
        0.0633, 0.0794, 0.1026, 0.1884, 0.0229, 0.0533, 0.0927, 0.0838, 0.0573,
        0.0357, 0.0462, 0.0206, 0.0410, 0.0689, 0.0467, 0.0425, 0.1575, 0.2253,
        0.0345, 0.0806, 0.0682, 0.0643, 0.0533, 0.1170, 0.0732, 0.0739, 0.1970,
        0.0414, 0.0323, 0.0335, 0.2600, 0.1980, 0.0491, 0.0734, 0.1122, 0.1417,
        0.0356, 0.0605, 0.0180, 0.0688, 0.1725, 0.1039, 0.0753, 0.0442, 0.3898,
        0.0713], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[1.4778e-07, 1.4939e-09, 3.6230e-08,  ..., 1.6172e-07, 7.4308e-06,
         6.8173e-09],
        [5.0898e-06, 4.1044e-04, 4.4324e-07,  ..., 2.1628e-05, 7.5382e-06,
         1.0442e-06],
        [5.6751e-07, 9.2552e-08, 1.1340e-07,  ..., 4.7936e-08, 2.3719e-07,
         1.3990e-08],
        ...,
        [1.3946e-06, 2.6608e-04, 4.8231e-09,  ..., 3.5222e-07, 2.6401e-05,
         2.2533e-08],
        [1.3093e-07, 3.8024e-07, 2.0236e-05,  ..., 1.6635e-06, 5.3106e-09,
         1.8238e-03],
        [5.3376e-07, 6.2034e-08, 1.0487e-08,  ..., 1.3126e-08, 2.7312e-06,
         9.1894e-09]], device='cuda:0'), tensor([[4.9247e-07, 1.8042e-07, 1.3046e-08,  ..., 1.9504e-05, 1.8120e-08,
         1.1662e-07],
        [1.0068e-05, 3.5093e-05, 8.9298e-05,  ..., 2.0664e-06, 1.8714e-05,
         6.2636e-05],
        [4.5117e-05, 6.9344e-05, 2.4079e-05,  ..., 3.1448e-06, 3.2941e-05,
         5.1599e-06],
        ...,
        [4.1333e-06, 3.1956e-04, 2.1437e-07,  ..., 4.1290e-05, 2.5080e-04,
         1.4546e-07],
        [1.2100e-05, 2.7585e-07, 7.5282e-05,  ..., 8.2552e-06, 2.0366e-05,
         1.7067e-04],
        [1.4219e-05, 1.6187e-04, 2.1047e-05,  ..., 1.1523e-03, 4.4503e-07,
         6.2313e-07]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([0.1101, 0.0578, 0.1454, 0.1171, 0.0723, 0.0535, 0.2605, 0.2092, 0.2669,
        0.1379, 0.1472, 0.2036, 0.0570, 0.1208, 0.0933, 0.0839, 0.1733, 0.3952,
        0.0522, 0.2277, 0.1678, 0.0987, 0.0906, 0.4465, 0.1661, 0.1576, 0.1440,
        0.0664, 0.1575, 0.1589, 0.0763, 0.1387, 0.1852, 0.0781, 0.1731, 0.1752,
        0.0961, 0.1236, 0.0832, 0.3597, 0.4303, 0.0491, 0.0622, 0.0562, 0.1734,
        0.0482, 0.1222, 0.6161, 0.2007, 0.0779, 0.0838, 0.2133, 0.1055, 0.1004,
        0.1331, 0.3148, 0.0901, 0.1352, 0.1106, 0.0773, 0.1206, 0.1597, 0.3546,
        0.1456], device='cuda:0'), tensor([0.2303, 0.0317, 0.0235, 0.0296, 0.0563, 0.0702, 0.0986, 0.0343, 0.0731,
        0.0362, 0.0405, 0.0291, 0.0643, 0.0642, 0.0827, 0.0479, 0.0745, 0.3089,
        0.0944, 0.0319, 0.1028, 0.0736, 0.0781, 0.0523, 0.0321, 0.0522, 0.1165,
        0.0449, 0.1542, 0.1438, 0.0203, 0.1079, 0.0677, 0.0379, 0.0478, 0.0329,
        0.0289, 0.1139, 0.0366, 0.0753, 0.0455, 0.0447, 0.3357, 0.0207, 0.1057,
        0.0276, 0.0434, 0.0461, 0.0520, 0.0534, 0.0277, 0.0474, 0.0462, 0.0187,
        0.0643, 0.0462, 0.0447, 0.0273, 0.0557, 0.1010, 0.0433, 0.0278, 0.0508,
        0.0304], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
weighted predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[7.3892e-08, 7.4696e-10, 1.8115e-08,  ..., 8.0858e-08, 3.7154e-06,
         3.4086e-09],
        [2.5449e-06, 2.0522e-04, 2.2162e-07,  ..., 1.0814e-05, 3.7691e-06,
         5.2211e-07],
        [2.8375e-07, 4.6276e-08, 5.6702e-08,  ..., 2.3968e-08, 1.1859e-07,
         6.9951e-09],
        ...,
        [6.9730e-07, 1.3304e-04, 2.4115e-09,  ..., 1.7611e-07, 1.3200e-05,
         1.1266e-08],
        [6.5464e-08, 1.9012e-07, 1.0118e-05,  ..., 8.3177e-07, 2.6553e-09,
         9.1188e-04],
        [2.6688e-07, 3.1017e-08, 5.2437e-09,  ..., 6.5630e-09, 1.3656e-06,
         4.5947e-09]], device='cuda:0'), tensor([[2.4624e-07, 9.0211e-08, 6.5228e-09,  ..., 9.7522e-06, 9.0600e-09,
         5.8308e-08],
        [5.0338e-06, 1.7546e-05, 4.4649e-05,  ..., 1.0332e-06, 9.3571e-06,
         3.1318e-05],
        [2.2558e-05, 3.4672e-05, 1.2040e-05,  ..., 1.5724e-06, 1.6470e-05,
         2.5800e-06],
        ...,
        [2.0666e-06, 1.5978e-04, 1.0719e-07,  ..., 2.0645e-05, 1.2540e-04,
         7.2729e-08],
        [6.0502e-06, 1.3793e-07, 3.7641e-05,  ..., 4.1276e-06, 1.0183e-05,
         8.5337e-05],
        [7.1093e-06, 8.0935e-05, 1.0523e-05,  ..., 5.7613e-04, 2.2252e-07,
         3.1156e-07]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
final predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([[3.2013e-07, 9.0958e-08, 2.4638e-08,  ..., 9.8330e-06, 3.7245e-06,
         6.1716e-08],
        [7.5786e-06, 2.2276e-04, 4.4870e-05,  ..., 1.1847e-05, 1.3126e-05,
         3.1840e-05],
        [2.2842e-05, 3.4718e-05, 1.2096e-05,  ..., 1.5963e-06, 1.6589e-05,
         2.5869e-06],
        ...,
        [2.7639e-06, 2.9282e-04, 1.0960e-07,  ..., 2.0821e-05, 1.3860e-04,
         8.3995e-08],
        [6.1157e-06, 3.2805e-07, 4.7759e-05,  ..., 4.9594e-06, 1.0186e-05,
         9.9721e-04],
        [7.3762e-06, 8.0966e-05, 1.0529e-05,  ..., 5.7614e-04, 1.5881e-06,
         3.1616e-07]], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
final confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([0.1185, 0.0290, 0.0727, 0.0711, 0.0372, 0.0351, 0.1310, 0.1218, 0.1334,
        0.0774, 0.0744, 0.1018, 0.0322, 0.0604, 0.0469, 0.0442, 0.1209, 0.3520,
        0.0472, 0.1139, 0.0852, 0.0505, 0.0457, 0.2250, 0.0832, 0.0789, 0.0720,
        0.0341, 0.0798, 0.0796, 0.0382, 0.0759, 0.0926, 0.0401, 0.0867, 0.0878,
        0.0510, 0.0618, 0.0417, 0.1798, 0.2156, 0.0250, 0.1679, 0.0281, 0.1396,
        0.0251, 0.0684, 0.3081, 0.1104, 0.0399, 0.0429, 0.1067, 0.0758, 0.0506,
        0.0666, 0.1575, 0.0454, 0.0788, 0.0553, 0.0512, 0.0621, 0.0828, 0.1773,
        0.0730], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[5.4704e-06, 3.7968e-04, 3.8926e-06,  ..., 1.8103e-05, 1.3314e-06,
         3.6142e-06],
        [1.2291e-06, 5.6065e-04, 1.0938e-06,  ..., 3.0404e-05, 1.6290e-07,
         2.0422e-07],
        [8.0775e-06, 5.9328e-05, 2.5270e-06,  ..., 5.3213e-05, 3.4518e-08,
         2.7802e-05],
        ...,
        [9.9064e-06, 6.2131e-05, 1.4977e-07,  ..., 3.1107e-06, 3.0156e-06,
         2.6125e-07],
        [4.0482e-06, 7.2523e-07, 1.7332e-09,  ..., 7.3645e-07, 6.9334e-09,
         2.5192e-10],
        [1.7936e-07, 8.6107e-04, 1.5638e-08,  ..., 1.2138e-06, 6.9468e-09,
         3.4880e-07]], device='cuda:0'), tensor([[1.4195e-05, 8.7291e-04, 1.3686e-05,  ..., 2.1132e-04, 9.1643e-06,
         2.5429e-06],
        [1.8313e-06, 3.1563e-04, 2.9643e-07,  ..., 5.9576e-06, 1.4261e-05,
         1.0500e-06],
        [6.9551e-06, 2.1408e-05, 2.9393e-05,  ..., 1.2440e-04, 4.4969e-04,
         1.8496e-06],
        ...,
        [1.8737e-05, 1.1004e-04, 2.7712e-06,  ..., 1.2749e-04, 3.2698e-05,
         2.2003e-06],
        [7.5488e-06, 4.0259e-04, 9.4489e-08,  ..., 1.3980e-03, 1.2316e-05,
         4.5991e-07],
        [2.6835e-06, 1.4416e-04, 2.0290e-05,  ..., 5.5916e-04, 6.3520e-07,
         2.8485e-07]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([0.0675, 0.1428, 0.0336, 0.1701, 0.1442, 0.2676, 0.1792, 0.1173, 0.0458,
        0.0421, 0.1930, 0.2808, 0.2960, 0.1157, 0.1957, 0.0496, 0.1894, 0.0614,
        0.0558, 0.2605, 0.0835, 0.0731, 0.2076, 0.1814, 0.0702, 0.1604, 0.0744,
        0.1806, 0.1961, 0.3129, 0.1702, 0.1030, 0.0825, 0.1287, 0.0976, 0.1238,
        0.0921, 0.1993, 0.2554, 0.0545, 0.2120, 0.0694, 0.0364, 0.1170, 0.3214,
        0.1008, 0.0382, 0.1860, 0.0833, 0.0715, 0.0716, 0.1482, 0.0721, 0.1753,
        0.0969, 0.0942, 0.1129, 0.2356, 0.0813, 0.0593, 0.1321, 0.0971, 0.0827,
        0.3144], device='cuda:0'), tensor([0.0188, 0.0574, 0.0187, 0.0343, 0.0228, 0.0728, 0.0367, 0.1018, 0.0542,
        0.0314, 0.0580, 0.0251, 0.2627, 0.1232, 0.0513, 0.0561, 0.0262, 0.0286,
        0.0352, 0.1189, 0.0390, 0.0495, 0.0414, 0.0492, 0.0702, 0.0475, 0.0274,
        0.1298, 0.0484, 0.1569, 0.2148, 0.0844, 0.0643, 0.0216, 0.0358, 0.1408,
        0.0362, 0.0496, 0.0436, 0.0314, 0.0807, 0.1090, 0.0488, 0.0531, 0.0631,
        0.0875, 0.0350, 0.0394, 0.0748, 0.0301, 0.1361, 0.0504, 0.0454, 0.0955,
        0.0341, 0.0636, 0.0640, 0.0373, 0.0480, 0.0302, 0.0516, 0.0225, 0.0429,
        0.0337], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
weighted predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[2.7352e-06, 1.8984e-04, 1.9463e-06,  ..., 9.0515e-06, 6.6568e-07,
         1.8071e-06],
        [6.1455e-07, 2.8033e-04, 5.4691e-07,  ..., 1.5202e-05, 8.1449e-08,
         1.0211e-07],
        [4.0388e-06, 2.9664e-05, 1.2635e-06,  ..., 2.6606e-05, 1.7259e-08,
         1.3901e-05],
        ...,
        [4.9532e-06, 3.1066e-05, 7.4886e-08,  ..., 1.5554e-06, 1.5078e-06,
         1.3062e-07],
        [2.0241e-06, 3.6261e-07, 8.6658e-10,  ..., 3.6823e-07, 3.4667e-09,
         1.2596e-10],
        [8.9678e-08, 4.3053e-04, 7.8189e-09,  ..., 6.0691e-07, 3.4734e-09,
         1.7440e-07]], device='cuda:0'), tensor([[7.0975e-06, 4.3645e-04, 6.8432e-06,  ..., 1.0566e-04, 4.5822e-06,
         1.2715e-06],
        [9.1565e-07, 1.5782e-04, 1.4821e-07,  ..., 2.9788e-06, 7.1303e-06,
         5.2502e-07],
        [3.4776e-06, 1.0704e-05, 1.4697e-05,  ..., 6.2199e-05, 2.2485e-04,
         9.2480e-07],
        ...,
        [9.3687e-06, 5.5021e-05, 1.3856e-06,  ..., 6.3744e-05, 1.6349e-05,
         1.1001e-06],
        [3.7744e-06, 2.0130e-04, 4.7244e-08,  ..., 6.9902e-04, 6.1580e-06,
         2.2996e-07],
        [1.3417e-06, 7.2081e-05, 1.0145e-05,  ..., 2.7958e-04, 3.1760e-07,
         1.4243e-07]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
final predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([[9.8327e-06, 6.2630e-04, 8.7895e-06,  ..., 1.1471e-04, 5.2479e-06,
         3.0786e-06],
        [1.5302e-06, 4.3814e-04, 6.9512e-07,  ..., 1.8181e-05, 7.2118e-06,
         6.2713e-07],
        [7.5163e-06, 4.0368e-05, 1.5960e-05,  ..., 8.8805e-05, 2.2486e-04,
         1.4826e-05],
        ...,
        [1.4322e-05, 8.6087e-05, 1.4605e-06,  ..., 6.5299e-05, 1.7857e-05,
         1.2308e-06],
        [5.7985e-06, 2.0166e-04, 4.8111e-08,  ..., 6.9939e-04, 6.1615e-06,
         2.3008e-07],
        [1.4314e-06, 5.0262e-04, 1.0153e-05,  ..., 2.8019e-04, 3.2107e-07,
         3.1683e-07]], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
final confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([0.0361, 0.0761, 0.0169, 0.0854, 0.0721, 0.1338, 0.0896, 0.0618, 0.0271,
        0.0222, 0.0965, 0.1408, 0.1486, 0.0635, 0.0979, 0.0281, 0.0947, 0.0308,
        0.0297, 0.1897, 0.0516, 0.0366, 0.1039, 0.0907, 0.0352, 0.0831, 0.0380,
        0.0903, 0.1098, 0.1566, 0.1076, 0.0515, 0.0413, 0.0646, 0.0500, 0.0705,
        0.0461, 0.1245, 0.1277, 0.0272, 0.1464, 0.0611, 0.0244, 0.0586, 0.1607,
        0.0530, 0.0191, 0.0931, 0.0508, 0.0358, 0.0685, 0.0908, 0.0376, 0.0896,
        0.0485, 0.0471, 0.0565, 0.1194, 0.0407, 0.0296, 0.0662, 0.0513, 0.0414,
        0.1572], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[1.4477e-07, 1.0236e-09, 3.9137e-06,  ..., 2.0111e-08, 1.1055e-07,
         1.8854e-05],
        [4.3145e-06, 3.7102e-09, 3.6681e-05,  ..., 1.6529e-04, 1.4566e-08,
         2.4279e-06],
        [8.0162e-07, 3.4932e-09, 1.2898e-06,  ..., 3.3994e-07, 4.0737e-06,
         9.4376e-06],
        ...,
        [1.6129e-06, 2.9104e-06, 4.7430e-06,  ..., 2.2228e-05, 4.7123e-05,
         5.7503e-07],
        [1.1749e-05, 2.0286e-05, 3.3071e-06,  ..., 5.9073e-06, 2.6016e-05,
         1.1780e-07],
        [5.1891e-07, 5.6642e-05, 4.0429e-07,  ..., 3.4565e-06, 6.7154e-07,
         5.0837e-07]], device='cuda:0'), tensor([[6.4291e-07, 1.4797e-09, 3.1278e-05,  ..., 2.4725e-06, 1.4616e-07,
         4.2446e-08],
        [6.7438e-06, 3.7372e-06, 1.1766e-06,  ..., 7.7104e-05, 2.3874e-05,
         3.8395e-06],
        [3.6267e-06, 1.2411e-08, 3.8544e-07,  ..., 6.0924e-06, 4.6741e-06,
         4.4468e-08],
        ...,
        [2.7413e-06, 1.8826e-05, 2.3398e-05,  ..., 1.7963e-05, 1.5026e-05,
         3.7690e-06],
        [1.3853e-05, 5.5881e-06, 2.1997e-04,  ..., 3.1507e-06, 1.4322e-05,
         6.7256e-05],
        [2.8581e-06, 2.2242e-06, 4.8000e-04,  ..., 1.6297e-06, 6.0610e-03,
         8.7600e-05]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([0.0885, 0.1149, 0.1108, 0.0678, 0.1438, 0.1434, 0.1980, 0.1228, 0.1403,
        0.0762, 0.0684, 0.1258, 0.1062, 0.1389, 0.6097, 0.1402, 0.0744, 0.0617,
        0.1779, 0.0773, 0.1485, 0.0510, 0.0980, 0.1432, 0.2147, 0.0891, 0.2114,
        0.1158, 0.0459, 0.3145, 0.3206, 0.1717, 0.0998, 0.2224, 0.0967, 0.1114,
        0.2792, 0.0814, 0.3026, 0.1509, 0.1340, 0.1698, 0.0800, 0.0590, 0.0406,
        0.2137, 0.2271, 0.3850, 0.0597, 0.0526, 0.1251, 0.0686, 0.0333, 0.1163,
        0.1412, 0.5209, 0.0455, 0.1011, 0.0779, 0.1224, 0.1172, 0.2359, 0.0804,
        0.1174], device='cuda:0'), tensor([0.3285, 0.1149, 0.0349, 0.0410, 0.0750, 0.0862, 0.0447, 0.0538, 0.0508,
        0.0878, 0.2934, 0.0350, 0.0585, 0.0858, 0.0655, 0.0344, 0.0445, 0.0278,
        0.0527, 0.0405, 0.0230, 0.0546, 0.0314, 0.0942, 0.0395, 0.0246, 0.0673,
        0.0293, 0.0301, 0.0683, 0.1002, 0.0816, 0.2000, 0.0573, 0.1140, 0.0495,
        0.1645, 0.0657, 0.0834, 0.0316, 0.0729, 0.0572, 0.0593, 0.0333, 0.0497,
        0.0697, 0.0562, 0.0828, 0.0178, 0.0637, 0.0424, 0.0506, 0.0421, 0.0712,
        0.1630, 0.0482, 0.0939, 0.0360, 0.0272, 0.0937, 0.1091, 0.1298, 0.0317,
        0.0740], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
weighted predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[7.2387e-08, 5.1179e-10, 1.9569e-06,  ..., 1.0056e-08, 5.5277e-08,
         9.4269e-06],
        [2.1573e-06, 1.8551e-09, 1.8341e-05,  ..., 8.2646e-05, 7.2831e-09,
         1.2140e-06],
        [4.0081e-07, 1.7466e-09, 6.4491e-07,  ..., 1.6997e-07, 2.0368e-06,
         4.7188e-06],
        ...,
        [8.0647e-07, 1.4552e-06, 2.3715e-06,  ..., 1.1114e-05, 2.3562e-05,
         2.8752e-07],
        [5.8744e-06, 1.0143e-05, 1.6536e-06,  ..., 2.9537e-06, 1.3008e-05,
         5.8901e-08],
        [2.5945e-07, 2.8321e-05, 2.0215e-07,  ..., 1.7283e-06, 3.3577e-07,
         2.5418e-07]], device='cuda:0'), tensor([[3.2146e-07, 7.3986e-10, 1.5639e-05,  ..., 1.2362e-06, 7.3082e-08,
         2.1223e-08],
        [3.3719e-06, 1.8686e-06, 5.8829e-07,  ..., 3.8552e-05, 1.1937e-05,
         1.9197e-06],
        [1.8134e-06, 6.2055e-09, 1.9272e-07,  ..., 3.0462e-06, 2.3371e-06,
         2.2234e-08],
        ...,
        [1.3707e-06, 9.4128e-06, 1.1699e-05,  ..., 8.9816e-06, 7.5130e-06,
         1.8845e-06],
        [6.9267e-06, 2.7940e-06, 1.0998e-04,  ..., 1.5753e-06, 7.1610e-06,
         3.3628e-05],
        [1.4291e-06, 1.1121e-06, 2.4000e-04,  ..., 8.1485e-07, 3.0305e-03,
         4.3800e-05]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
final predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([[3.9384e-07, 1.2516e-09, 1.7596e-05,  ..., 1.2463e-06, 1.2836e-07,
         9.4482e-06],
        [5.5292e-06, 1.8704e-06, 1.8929e-05,  ..., 1.2120e-04, 1.1944e-05,
         3.1337e-06],
        [2.2142e-06, 7.9521e-09, 8.3763e-07,  ..., 3.2162e-06, 4.3739e-06,
         4.7410e-06],
        ...,
        [2.1771e-06, 1.0868e-05, 1.4071e-05,  ..., 2.0095e-05, 3.1075e-05,
         2.1720e-06],
        [1.2801e-05, 1.2937e-05, 1.1164e-04,  ..., 4.5290e-06, 2.0169e-05,
         3.3687e-05],
        [1.6885e-06, 2.9433e-05, 2.4020e-04,  ..., 2.5431e-06, 3.0308e-03,
         4.4054e-05]], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
final confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([0.2085, 0.0575, 0.0554, 0.0358, 0.0726, 0.0724, 0.0991, 0.0623, 0.0702,
        0.0698, 0.1468, 0.0631, 0.0559, 0.0697, 0.3049, 0.0778, 0.0373, 0.0316,
        0.0896, 0.0397, 0.0793, 0.0273, 0.0536, 0.0716, 0.1074, 0.0568, 0.1057,
        0.0580, 0.0236, 0.1573, 0.1603, 0.0862, 0.1042, 0.1116, 0.0660, 0.0568,
        0.1402, 0.0407, 0.1527, 0.0765, 0.0671, 0.1135, 0.0420, 0.0388, 0.0271,
        0.1084, 0.1245, 0.2018, 0.0327, 0.0380, 0.0626, 0.0386, 0.0211, 0.0582,
        0.0817, 0.2605, 0.0668, 0.0654, 0.0426, 0.0625, 0.0588, 0.1182, 0.0453,
        0.0587], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[1.0051e-05, 3.0362e-08, 2.8407e-05,  ..., 8.4481e-07, 4.1235e-08,
         6.0123e-07],
        [1.0621e-05, 1.0976e-07, 6.6694e-06,  ..., 3.9797e-04, 3.5677e-06,
         1.3452e-04],
        [4.1932e-06, 9.5550e-08, 1.4287e-08,  ..., 3.5696e-07, 1.2550e-09,
         3.1712e-10],
        ...,
        [3.0141e-08, 4.2865e-11, 1.0815e-05,  ..., 4.7565e-09, 4.6117e-08,
         4.8189e-07],
        [3.8322e-07, 2.5720e-07, 4.3033e-04,  ..., 1.8304e-08, 4.6574e-08,
         1.8510e-07],
        [3.3161e-06, 1.6044e-05, 5.6279e-08,  ..., 3.7777e-06, 6.6574e-06,
         7.6013e-09]], device='cuda:0'), tensor([[2.5244e-05, 1.7508e-05, 7.4976e-05,  ..., 3.9704e-05, 6.4664e-05,
         2.3510e-05],
        [2.3933e-05, 3.3317e-04, 2.0430e-04,  ..., 2.5960e-05, 9.9009e-05,
         9.5581e-05],
        [2.1616e-05, 5.9076e-06, 1.6585e-06,  ..., 1.3501e-03, 5.6203e-04,
         3.5603e-07],
        ...,
        [1.5678e-06, 2.8272e-08, 1.5046e-04,  ..., 1.6103e-06, 3.8581e-05,
         7.6640e-04],
        [8.8165e-06, 4.1070e-06, 2.8400e-05,  ..., 7.6237e-06, 7.1522e-06,
         2.1542e-07],
        [6.2983e-06, 1.3561e-05, 3.9088e-06,  ..., 4.6452e-05, 1.5722e-05,
         1.1247e-05]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
raw confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([0.1499, 0.0566, 0.1040, 0.0940, 0.1133, 0.1803, 0.0748, 0.1075, 0.1095,
        0.3998, 0.0782, 0.1957, 0.3228, 0.1863, 0.1368, 0.2051, 0.0558, 0.1358,
        0.1433, 0.1183, 0.0903, 0.2695, 0.0500, 0.1162, 0.0899, 0.1321, 0.0770,
        0.1015, 0.2057, 0.2678, 0.1187, 0.2118, 0.1771, 0.3901, 0.1847, 0.3880,
        0.0665, 0.2914, 0.1392, 0.0985, 0.0659, 0.1380, 0.0534, 0.7934, 0.0542,
        0.3707, 0.0687, 0.5106, 0.1117, 0.0901, 0.1811, 0.0713, 0.0962, 0.2194,
        0.1132, 0.1285, 0.0676, 0.0616, 0.0900, 0.1539, 0.1727, 0.2613, 0.1637,
        0.1082], device='cuda:0'), tensor([0.0183, 0.0228, 0.0375, 0.0516, 0.0283, 0.0554, 0.0342, 0.0374, 0.0166,
        0.0465, 0.0425, 0.0727, 0.0399, 0.1895, 0.0755, 0.0829, 0.0261, 0.0344,
        0.0547, 0.0600, 0.0516, 0.0646, 0.0256, 0.0173, 0.0948, 0.0467, 0.0369,
        0.0342, 0.0542, 0.0533, 0.0411, 0.0474, 0.1377, 0.0624, 0.0950, 0.0472,
        0.0415, 0.0980, 0.0533, 0.0619, 0.0219, 0.1061, 0.0254, 0.0502, 0.0465,
        0.1124, 0.0538, 0.0437, 0.0215, 0.0406, 0.0277, 0.0471, 0.0566, 0.0335,
        0.0254, 0.0729, 0.0186, 0.0569, 0.0622, 0.0342, 0.0651, 0.0844, 0.0381,
        0.0239], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
weighted predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
[tensor([[5.0256e-06, 1.5181e-08, 1.4204e-05,  ..., 4.2241e-07, 2.0618e-08,
         3.0062e-07],
        [5.3104e-06, 5.4879e-08, 3.3347e-06,  ..., 1.9899e-04, 1.7839e-06,
         6.7260e-05],
        [2.0966e-06, 4.7775e-08, 7.1436e-09,  ..., 1.7848e-07, 6.2751e-10,
         1.5856e-10],
        ...,
        [1.5071e-08, 2.1433e-11, 5.4073e-06,  ..., 2.3783e-09, 2.3059e-08,
         2.4094e-07],
        [1.9161e-07, 1.2860e-07, 2.1516e-04,  ..., 9.1520e-09, 2.3287e-08,
         9.2551e-08],
        [1.6580e-06, 8.0222e-06, 2.8140e-08,  ..., 1.8889e-06, 3.3287e-06,
         3.8006e-09]], device='cuda:0'), tensor([[1.2622e-05, 8.7539e-06, 3.7488e-05,  ..., 1.9852e-05, 3.2332e-05,
         1.1755e-05],
        [1.1967e-05, 1.6658e-04, 1.0215e-04,  ..., 1.2980e-05, 4.9504e-05,
         4.7791e-05],
        [1.0808e-05, 2.9538e-06, 8.2924e-07,  ..., 6.7504e-04, 2.8101e-04,
         1.7802e-07],
        ...,
        [7.8388e-07, 1.4136e-08, 7.5229e-05,  ..., 8.0516e-07, 1.9291e-05,
         3.8320e-04],
        [4.4083e-06, 2.0535e-06, 1.4200e-05,  ..., 3.8119e-06, 3.5761e-06,
         1.0771e-07],
        [3.1492e-06, 6.7805e-06, 1.9544e-06,  ..., 2.3226e-05, 7.8609e-06,
         5.6234e-06]], device='cuda:0')]
DEBUG   [02-27 18:43:36] forward in Ensembler:
final predict
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([[1.7648e-05, 8.7691e-06, 5.1692e-05,  ..., 2.0275e-05, 3.2353e-05,
         1.2056e-05],
        [1.7277e-05, 1.6664e-04, 1.0549e-04,  ..., 2.1197e-04, 5.1288e-05,
         1.1505e-04],
        [1.2904e-05, 3.0016e-06, 8.3638e-07,  ..., 6.7522e-04, 2.8102e-04,
         1.7818e-07],
        ...,
        [7.9895e-07, 1.4157e-08, 8.0637e-05,  ..., 8.0754e-07, 1.9314e-05,
         3.8344e-04],
        [4.5999e-06, 2.1821e-06, 2.2936e-04,  ..., 3.8210e-06, 3.5994e-06,
         2.0026e-07],
        [4.8072e-06, 1.4803e-05, 1.9826e-06,  ..., 2.5115e-05, 1.1190e-05,
         5.6272e-06]], device='cuda:0')
DEBUG   [02-27 18:43:36] forward in Ensembler:
final confidence
DEBUG   [02-27 18:43:36] forward in Ensembler:
tensor([0.0750, 0.0284, 0.0560, 0.0470, 0.0567, 0.0906, 0.0414, 0.0543, 0.0565,
        0.2014, 0.0391, 0.0982, 0.1618, 0.0949, 0.0686, 0.1026, 0.0312, 0.0699,
        0.0717, 0.0592, 0.0452, 0.1439, 0.0250, 0.0590, 0.0553, 0.0662, 0.0392,
        0.0508, 0.1093, 0.1339, 0.0676, 0.1093, 0.0946, 0.1982, 0.0964, 0.1943,
        0.0333, 0.1506, 0.0700, 0.0493, 0.0379, 0.0701, 0.0267, 0.3971, 0.0272,
        0.1854, 0.0352, 0.2556, 0.0561, 0.0451, 0.0906, 0.0366, 0.0488, 0.1099,
        0.0573, 0.0643, 0.0338, 0.0496, 0.0451, 0.0911, 0.0984, 0.1309, 0.0893,
        0.0543], device='cuda:0')
INFO    [02-27 18:43:42] test_mentor in DistillTrainer:
{'Recall@10': 0.1655152028799057, 'NDCG@10': 0.12058982387185097, 'MRR@10': 0.10691774055361748, 'Recall@5': 0.1327027028799057, 'NDCG@5': 0.11006353586912156, 'MRR@5': 0.10262359276413918, 'Recall*@10': 0.1655152028799057, 'NDCG*@10': 0.12058982387185097, 'MRR*@10': 0.10691774055361748, 'Recall*@5': 0.1327027028799057, 'NDCG*@5': 0.11006353586912156, 'MRR*@5': 0.10262359276413918}
INFO    [02-27 18:43:42] train in DistillTrainer:
result:
{'Recall@10': 0.1655152028799057, 'NDCG@10': 0.12058982387185097, 'MRR@10': 0.10691774055361748, 'Recall@5': 0.1327027028799057, 'NDCG@5': 0.11006353586912156, 'MRR@5': 0.10262359276413918, 'Recall*@10': 0.1655152028799057, 'NDCG*@10': 0.12058982387185097, 'MRR*@10': 0.10691774055361748, 'Recall*@5': 0.1327027028799057, 'NDCG*@5': 0.11006353586912156, 'MRR*@5': 0.10262359276413918}
INFO    [02-27 18:43:48] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [02-27 18:43:48] validate in BasicTrainer:
{'Recall@10': 0.0030405405536293984, 'NDCG@10': 0.0014288997277617454, 'MRR@10': 0.0009498337795957923, 'Recall@5': 0.0011655405536293983, 'NDCG@5': 0.0008097931370139122, 'MRR@5': 0.0006869369465857745, 'Recall*@10': 0.0030405405536293984, 'NDCG*@10': 0.0014288997277617454, 'MRR*@10': 0.0009498337795957923, 'Recall*@5': 0.0011655405536293983, 'NDCG*@5': 0.0008097931370139122, 'MRR*@5': 0.0006869369465857745}
INFO    [02-27 18:43:48] train in BasicTrainer:
epoch: 0
DEBUG   [02-27 18:43:49] calculate_loss in loss:
soft_target max: 0.7007467746734619, argmax 46375
DEBUG   [02-27 18:43:49] calculate_loss in loss:
pred max in softmax: 0.0005522277788259089, argmax 231012
INFO    [02-27 18:45:22] _train_one_epoch in BasicTrainer:
loss = 5.896963586225434
INFO    [02-27 18:45:28] log in loggers:
Update Best NDCG@10 Model at 0
INFO    [02-27 18:45:28] validate in BasicTrainer:
{'Recall@10': 0.0608277028799057, 'NDCG@10': 0.03232059843838215, 'MRR@10': 0.02373028642265126, 'Recall@5': 0.039121621698141096, 'NDCG@5': 0.02539807366207242, 'MRR@5': 0.020930039626546205, 'Recall*@10': 0.0608277028799057, 'NDCG*@10': 0.03232059843838215, 'MRR*@10': 0.02373028642265126, 'Recall*@5': 0.039121621698141096, 'NDCG*@5': 0.02539807366207242, 'MRR*@5': 0.020930039626546205}
INFO    [02-27 18:45:28] train in BasicTrainer:
duration: 99.8227367401123s
INFO    [02-27 18:45:28] train in BasicTrainer:
epoch: 1
DEBUG   [02-27 18:45:59] calculate_loss in loss:
soft_target max: 0.7409987449645996, argmax 30123
DEBUG   [02-27 18:45:59] calculate_loss in loss:
pred max in softmax: 0.059936802834272385, argmax 126919
DEBUG   [02-27 18:45:59] calculate_loss in loss:
soft_target max: 0.7720800638198853, argmax 53628
DEBUG   [02-27 18:45:59] calculate_loss in loss:
pred max in softmax: 0.06744295358657837, argmax 6568
INFO    [02-27 18:47:02] _train_one_epoch in BasicTrainer:
loss = 5.3347688549709575
INFO    [02-27 18:47:08] log in loggers:
Update Best NDCG@10 Model at 1
INFO    [02-27 18:47:08] validate in BasicTrainer:
{'Recall@10': 0.09028716221451759, 'NDCG@10': 0.045956201292574404, 'MRR@10': 0.0326808709371835, 'Recall@5': 0.0509966216981411, 'NDCG@5': 0.0332694673165679, 'MRR@5': 0.02745608139783144, 'Recall*@10': 0.09028716221451759, 'NDCG*@10': 0.045956201292574404, 'MRR*@10': 0.0326808709371835, 'Recall*@5': 0.0509966216981411, 'NDCG*@5': 0.0332694673165679, 'MRR*@5': 0.02745608139783144}
INFO    [02-27 18:47:08] train in BasicTrainer:
duration: 99.70610475540161s
INFO    [02-27 18:47:08] train in BasicTrainer:
epoch: 2
DEBUG   [02-27 18:48:09] calculate_loss in loss:
soft_target max: 0.714007556438446, argmax 117805
DEBUG   [02-27 18:48:09] calculate_loss in loss:
pred max in softmax: 0.10798987001180649, argmax 160436
DEBUG   [02-27 18:48:09] calculate_loss in loss:
soft_target max: 0.760595440864563, argmax 74375
DEBUG   [02-27 18:48:09] calculate_loss in loss:
pred max in softmax: 0.07307431101799011, argmax 142765
INFO    [02-27 18:48:41] _train_one_epoch in BasicTrainer:
loss = 4.977827648269087
INFO    [02-27 18:48:47] log in loggers:
Update Best NDCG@10 Model at 2
INFO    [02-27 18:48:47] validate in BasicTrainer:
{'Recall@10': 0.1049746622145176, 'NDCG@10': 0.053759128777310254, 'MRR@10': 0.03850872112903744, 'Recall@5': 0.061621621698141095, 'NDCG@5': 0.0399224759824574, 'MRR@5': 0.032907939748838544, 'Recall*@10': 0.1049746622145176, 'NDCG*@10': 0.053759128777310254, 'MRR*@10': 0.03850872112903744, 'Recall*@5': 0.061621621698141095, 'NDCG*@5': 0.0399224759824574, 'MRR*@5': 0.032907939748838544}
INFO    [02-27 18:48:47] train in BasicTrainer:
duration: 99.69022631645203s
INFO    [02-27 18:48:47] train in BasicTrainer:
epoch: 3
DEBUG   [02-27 18:50:19] calculate_loss in loss:
soft_target max: 0.7569979429244995, argmax 175428
DEBUG   [02-27 18:50:19] calculate_loss in loss:
pred max in softmax: 0.13625799119472504, argmax 77974
DEBUG   [02-27 18:50:19] calculate_loss in loss:
soft_target max: 0.7621592283248901, argmax 196201
DEBUG   [02-27 18:50:19] calculate_loss in loss:
pred max in softmax: 0.17294199764728546, argmax 7129
INFO    [02-27 18:50:21] _train_one_epoch in BasicTrainer:
loss = 4.698918519032729
INFO    [02-27 18:50:27] log in loggers:
Update Best NDCG@10 Model at 3
INFO    [02-27 18:50:27] validate in BasicTrainer:
{'Recall@10': 0.1369932433962822, 'NDCG@10': 0.07173138048499822, 'MRR@10': 0.05197740755975246, 'Recall@5': 0.0877027028799057, 'NDCG@5': 0.055902408286929134, 'MRR@5': 0.04550971357151866, 'Recall*@10': 0.1369932433962822, 'NDCG*@10': 0.07173138048499822, 'MRR*@10': 0.05197740755975246, 'Recall*@5': 0.0877027028799057, 'NDCG*@5': 0.055902408286929134, 'MRR*@5': 0.04550971357151866}
INFO    [02-27 18:50:27] train in BasicTrainer:
duration: 99.56838083267212s
INFO    [02-27 18:50:27] train in BasicTrainer:
epoch: 4
INFO    [02-27 18:52:01] _train_one_epoch in BasicTrainer:
loss = 4.4472403330259045
INFO    [02-27 18:52:07] log in loggers:
Update Best NDCG@10 Model at 4
INFO    [02-27 18:52:07] validate in BasicTrainer:
{'Recall@10': 0.1430743244290352, 'NDCG@10': 0.07555869810283183, 'MRR@10': 0.05528993789106607, 'Recall@5': 0.0886402028799057, 'NDCG@5': 0.05818955445662141, 'MRR@5': 0.048260980867780745, 'Recall*@10': 0.1430743244290352, 'NDCG*@10': 0.07555869810283183, 'MRR*@10': 0.05528993789106607, 'Recall*@5': 0.0886402028799057, 'NDCG*@5': 0.05818955445662141, 'MRR*@5': 0.048260980867780745}
INFO    [02-27 18:52:07] train in BasicTrainer:
duration: 99.79094910621643s
INFO    [02-27 18:52:07] train in BasicTrainer:
epoch: 5
DEBUG   [02-27 18:52:36] calculate_loss in loss:
soft_target max: 0.672580361366272, argmax 117762
DEBUG   [02-27 18:52:36] calculate_loss in loss:
pred max in softmax: 0.17679840326309204, argmax 77457
DEBUG   [02-27 18:52:36] calculate_loss in loss:
soft_target max: 0.7560656070709229, argmax 118525
DEBUG   [02-27 18:52:36] calculate_loss in loss:
pred max in softmax: 0.1331346482038498, argmax 160129
INFO    [02-27 18:53:40] _train_one_epoch in BasicTrainer:
loss = 4.224815515687674
INFO    [02-27 18:53:46] log in loggers:
Update Best NDCG@10 Model at 5
INFO    [02-27 18:53:46] validate in BasicTrainer:
{'Recall@10': 0.1570523649454117, 'NDCG@10': 0.08554629042744637, 'MRR@10': 0.06389920003712177, 'Recall@5': 0.10378378391265869, 'NDCG@5': 0.06851901669055223, 'MRR@5': 0.056986206248402595, 'Recall*@10': 0.1570523649454117, 'NDCG*@10': 0.08554629042744637, 'MRR*@10': 0.06389920003712177, 'Recall*@5': 0.10378378391265869, 'NDCG*@5': 0.06851901669055223, 'MRR*@5': 0.056986206248402595}
INFO    [02-27 18:53:46] train in BasicTrainer:
duration: 99.5950984954834s
INFO    [02-27 18:53:46] train in BasicTrainer:
epoch: 6
DEBUG   [02-27 18:54:45] calculate_loss in loss:
soft_target max: 0.6736658811569214, argmax 159951
DEBUG   [02-27 18:54:45] calculate_loss in loss:
pred max in softmax: 0.13656936585903168, argmax 32588
DEBUG   [02-27 18:54:46] calculate_loss in loss:
soft_target max: 0.8182128667831421, argmax 136027
DEBUG   [02-27 18:54:46] calculate_loss in loss:
pred max in softmax: 0.21118545532226562, argmax 201072
INFO    [02-27 18:55:20] _train_one_epoch in BasicTrainer:
loss = 4.024949856715113
INFO    [02-27 18:55:26] log in loggers:
Update Best NDCG@10 Model at 6
INFO    [02-27 18:55:26] validate in BasicTrainer:
{'Recall@10': 0.1565118244290352, 'NDCG@10': 0.08884181231260299, 'MRR@10': 0.06823117852210998, 'Recall@5': 0.11074324339628219, 'NDCG@5': 0.07423799455165864, 'MRR@5': 0.062318132109940055, 'Recall*@10': 0.1565118244290352, 'NDCG*@10': 0.08884181231260299, 'MRR*@10': 0.06823117852210998, 'Recall*@5': 0.11074324339628219, 'NDCG*@5': 0.07423799455165864, 'MRR*@5': 0.062318132109940055}
INFO    [02-27 18:55:26] train in BasicTrainer:
duration: 99.51322627067566s
INFO    [02-27 18:55:26] train in BasicTrainer:
epoch: 7
DEBUG   [02-27 18:56:55] calculate_loss in loss:
soft_target max: 0.805997371673584, argmax 59998
DEBUG   [02-27 18:56:55] calculate_loss in loss:
pred max in softmax: 0.20972201228141785, argmax 169185
DEBUG   [02-27 18:56:55] calculate_loss in loss:
soft_target max: 0.7882822751998901, argmax 76598
DEBUG   [02-27 18:56:55] calculate_loss in loss:
pred max in softmax: 0.2754895091056824, argmax 117276
INFO    [02-27 18:56:59] _train_one_epoch in BasicTrainer:
loss = 3.833002416777674
INFO    [02-27 18:57:05] log in loggers:
Update Best NDCG@10 Model at 7
INFO    [02-27 18:57:05] validate in BasicTrainer:
{'Recall@10': 0.16267736494541168, 'NDCG@10': 0.09486231297254562, 'MRR@10': 0.0742230112105608, 'Recall@5': 0.1125337839126587, 'NDCG@5': 0.07868326634168625, 'MRR@5': 0.06756644308567047, 'Recall*@10': 0.16267736494541168, 'NDCG*@10': 0.09486231297254562, 'MRR*@10': 0.0742230112105608, 'Recall*@5': 0.1125337839126587, 'NDCG*@5': 0.07868326634168625, 'MRR*@5': 0.06756644308567047}
INFO    [02-27 18:57:05] train in BasicTrainer:
duration: 99.50332069396973s
INFO    [02-27 18:57:05] train in BasicTrainer:
epoch: 8
INFO    [02-27 18:58:39] _train_one_epoch in BasicTrainer:
loss = 3.65637533955612
INFO    [02-27 18:58:45] log in loggers:
Update Best NDCG@10 Model at 8
INFO    [02-27 18:58:45] validate in BasicTrainer:
{'Recall@10': 0.17048986494541168, 'NDCG@10': 0.09999969825148583, 'MRR@10': 0.07860758882015943, 'Recall@5': 0.1192652028799057, 'NDCG@5': 0.08358437113463879, 'MRR@5': 0.07192103117704392, 'Recall*@10': 0.17048986494541168, 'NDCG*@10': 0.09999969825148583, 'MRR*@10': 0.07860758882015943, 'Recall*@5': 0.1192652028799057, 'NDCG*@5': 0.08358437113463879, 'MRR*@5': 0.07192103117704392}
INFO    [02-27 18:58:45] train in BasicTrainer:
duration: 99.65997695922852s
INFO    [02-27 18:58:45] train in BasicTrainer:
epoch: 9
DEBUG   [02-27 18:59:12] calculate_loss in loss:
soft_target max: 0.6852319836616516, argmax 66981
DEBUG   [02-27 18:59:12] calculate_loss in loss:
pred max in softmax: 0.3059725761413574, argmax 22646
DEBUG   [02-27 18:59:12] calculate_loss in loss:
soft_target max: 0.7053300738334656, argmax 117396
DEBUG   [02-27 18:59:12] calculate_loss in loss:
pred max in softmax: 0.367106169462204, argmax 88826
INFO    [02-27 19:00:19] _train_one_epoch in BasicTrainer:
loss = 3.4865999398876566
INFO    [02-27 19:00:25] log in loggers:
Update Best NDCG@10 Model at 9
INFO    [02-27 19:00:25] validate in BasicTrainer:
{'Recall@10': 0.1733868244290352, 'NDCG@10': 0.10101943261921406, 'MRR@10': 0.07892294466495514, 'Recall@5': 0.1215962839126587, 'NDCG@5': 0.08441647410392761, 'MRR@5': 0.07215639263391495, 'Recall*@10': 0.1733868244290352, 'NDCG*@10': 0.10101943261921406, 'MRR*@10': 0.07892294466495514, 'Recall*@5': 0.1215962839126587, 'NDCG*@5': 0.08441647410392761, 'MRR*@5': 0.07215639263391495}
INFO    [02-27 19:00:25] train in BasicTrainer:
duration: 99.71855092048645s
INFO    [02-27 19:00:25] train in BasicTrainer:
epoch: 10
DEBUG   [02-27 19:01:22] calculate_loss in loss:
soft_target max: 0.7485210299491882, argmax 68273
DEBUG   [02-27 19:01:22] calculate_loss in loss:
pred max in softmax: 0.22711023688316345, argmax 74461
DEBUG   [02-27 19:01:22] calculate_loss in loss:
soft_target max: 0.7560031414031982, argmax 60003
DEBUG   [02-27 19:01:22] calculate_loss in loss:
pred max in softmax: 0.37601760029792786, argmax 169043
INFO    [02-27 19:01:58] _train_one_epoch in BasicTrainer:
loss = 3.3219760495092254
INFO    [02-27 19:02:04] log in loggers:
Update Best NDCG@10 Model at 10
INFO    [02-27 19:02:04] validate in BasicTrainer:
{'Recall@10': 0.17094594597816468, 'NDCG@10': 0.10327335238456727, 'MRR@10': 0.08264039885252714, 'Recall@5': 0.1217652028799057, 'NDCG@5': 0.08743171159178019, 'MRR@5': 0.07614062678068877, 'Recall*@10': 0.17094594597816468, 'NDCG*@10': 0.10327335238456727, 'MRR*@10': 0.08264039885252714, 'Recall*@5': 0.1217652028799057, 'NDCG*@5': 0.08743171159178019, 'MRR*@5': 0.07614062678068877}
INFO    [02-27 19:02:04] train in BasicTrainer:
duration: 99.46825456619263s
INFO    [02-27 19:02:04] train in BasicTrainer:
epoch: 11
DEBUG   [02-27 19:03:32] calculate_loss in loss:
soft_target max: 0.7650526762008667, argmax 47336
DEBUG   [02-27 19:03:32] calculate_loss in loss:
pred max in softmax: 0.31905707716941833, argmax 109294
DEBUG   [02-27 19:03:32] calculate_loss in loss:
soft_target max: 0.7360932230949402, argmax 32761
DEBUG   [02-27 19:03:32] calculate_loss in loss:
pred max in softmax: 0.6365729570388794, argmax 32761
INFO    [02-27 19:03:38] _train_one_epoch in BasicTrainer:
loss = 3.174361759218676
INFO    [02-27 19:03:44] log in loggers:
Update Best NDCG@10 Model at 11
INFO    [02-27 19:03:44] validate in BasicTrainer:
{'Recall@10': 0.18017736494541167, 'NDCG@10': 0.108964723944664, 'MRR@10': 0.08709698885679246, 'Recall@5': 0.1326182433962822, 'NDCG@5': 0.09368043467402458, 'MRR@5': 0.08084459640085698, 'Recall*@10': 0.18017736494541167, 'NDCG*@10': 0.108964723944664, 'MRR*@10': 0.08709698885679246, 'Recall*@5': 0.1326182433962822, 'NDCG*@5': 0.09368043467402458, 'MRR*@5': 0.08084459640085698}
INFO    [02-27 19:03:44] train in BasicTrainer:
duration: 99.45106053352356s
INFO    [02-27 19:03:44] train in BasicTrainer:
epoch: 12
INFO    [02-27 19:05:17] _train_one_epoch in BasicTrainer:
loss = 3.0365753259203476
INFO    [02-27 19:05:23] log in loggers:
Update Best NDCG@10 Model at 12
INFO    [02-27 19:05:23] validate in BasicTrainer:
{'Recall@10': 0.1754307433962822, 'NDCG@10': 0.11262438386678696, 'MRR@10': 0.09326313607394696, 'Recall@5': 0.1341807433962822, 'NDCG@5': 0.099259894490242, 'MRR@5': 0.08773325003683567, 'Recall*@10': 0.1754307433962822, 'NDCG*@10': 0.11262438386678696, 'MRR*@10': 0.09326313607394696, 'Recall*@5': 0.1341807433962822, 'NDCG*@5': 0.099259894490242, 'MRR*@5': 0.08773325003683567}
INFO    [02-27 19:05:23] train in BasicTrainer:
duration: 99.68890023231506s
INFO    [02-27 19:05:23] train in BasicTrainer:
epoch: 13
DEBUG   [02-27 19:05:48] calculate_loss in loss:
soft_target max: 0.725828230381012, argmax 191521
DEBUG   [02-27 19:05:48] calculate_loss in loss:
pred max in softmax: 0.6276279091835022, argmax 97517
DEBUG   [02-27 19:05:48] calculate_loss in loss:
soft_target max: 0.7159067988395691, argmax 180454
DEBUG   [02-27 19:05:48] calculate_loss in loss:
pred max in softmax: 0.8028329014778137, argmax 224864
INFO    [02-27 19:06:57] _train_one_epoch in BasicTrainer:
loss = 2.910384694208201
INFO    [02-27 19:07:03] log in loggers:
Update Best NDCG@10 Model at 13
INFO    [02-27 19:07:03] validate in BasicTrainer:
{'Recall@10': 0.1817398649454117, 'NDCG@10': 0.11615467868745327, 'MRR@10': 0.09595933377742767, 'Recall@5': 0.13980574339628218, 'NDCG@5': 0.1025966315716505, 'MRR@5': 0.0903685250878334, 'Recall*@10': 0.1817398649454117, 'NDCG*@10': 0.11615467868745327, 'MRR*@10': 0.09595933377742767, 'Recall*@5': 0.13980574339628218, 'NDCG*@5': 0.1025966315716505, 'MRR*@5': 0.0903685250878334}
INFO    [02-27 19:07:03] train in BasicTrainer:
duration: 99.67621850967407s
INFO    [02-27 19:07:03] train in BasicTrainer:
epoch: 14
DEBUG   [02-27 19:07:58] calculate_loss in loss:
soft_target max: 0.7495809197425842, argmax 44034
DEBUG   [02-27 19:07:58] calculate_loss in loss:
pred max in softmax: 0.7259951829910278, argmax 30110
DEBUG   [02-27 19:07:58] calculate_loss in loss:
soft_target max: 0.7291364669799805, argmax 92060
DEBUG   [02-27 19:07:58] calculate_loss in loss:
pred max in softmax: 0.9079862236976624, argmax 208526
INFO    [02-27 19:08:37] _train_one_epoch in BasicTrainer:
loss = 2.793854472807927
INFO    [02-27 19:08:43] log in loggers:
Update Best NDCG@10 Model at 14
INFO    [02-27 19:08:43] validate in BasicTrainer:
{'Recall@10': 0.1846114867925644, 'NDCG@10': 0.11803698718547821, 'MRR@10': 0.09784095346927643, 'Recall@5': 0.1331587839126587, 'NDCG@5': 0.10146487690508366, 'MRR@5': 0.09103702269494533, 'Recall*@10': 0.1846114867925644, 'NDCG*@10': 0.11803698718547821, 'MRR*@10': 0.09784095346927643, 'Recall*@5': 0.1331587839126587, 'NDCG*@5': 0.10146487690508366, 'MRR*@5': 0.09103702269494533}
INFO    [02-27 19:08:43] train in BasicTrainer:
duration: 99.71978545188904s
INFO    [02-27 19:08:43] train in BasicTrainer:
epoch: 15
DEBUG   [02-27 19:10:08] calculate_loss in loss:
soft_target max: 0.7560655474662781, argmax 140407
DEBUG   [02-27 19:10:08] calculate_loss in loss:
pred max in softmax: 0.9166336059570312, argmax 131014
DEBUG   [02-27 19:10:08] calculate_loss in loss:
soft_target max: 0.6979873180389404, argmax 166103
DEBUG   [02-27 19:10:08] calculate_loss in loss:
pred max in softmax: 0.7796265482902527, argmax 135947
INFO    [02-27 19:10:16] _train_one_epoch in BasicTrainer:
loss = 2.682686028176973
INFO    [02-27 19:10:22] log in loggers:
Update Best NDCG@10 Model at 15
INFO    [02-27 19:10:22] validate in BasicTrainer:
{'Recall@10': 0.1806587839126587, 'NDCG@10': 0.11923417508602142, 'MRR@10': 0.100513004809618, 'Recall@5': 0.1354307433962822, 'NDCG@5': 0.10464090645313263, 'MRR@5': 0.09450577355921269, 'Recall*@10': 0.1806587839126587, 'NDCG*@10': 0.11923417508602142, 'MRR*@10': 0.100513004809618, 'Recall*@5': 0.1354307433962822, 'NDCG*@5': 0.10464090645313263, 'MRR*@5': 0.09450577355921269}
INFO    [02-27 19:10:22] train in BasicTrainer:
duration: 99.51534342765808s
INFO    [02-27 19:10:22] train in BasicTrainer:
epoch: 16
INFO    [02-27 19:11:56] _train_one_epoch in BasicTrainer:
loss = 2.586939689809511
INFO    [02-27 19:12:02] log in loggers:
Update Best NDCG@10 Model at 16
INFO    [02-27 19:12:02] validate in BasicTrainer:
{'Recall@10': 0.1865118244290352, 'NDCG@10': 0.12628221422433852, 'MRR@10': 0.10775718025863171, 'Recall@5': 0.1465962839126587, 'NDCG@5': 0.11341970071196555, 'MRR@5': 0.10247832372784614, 'Recall*@10': 0.1865118244290352, 'NDCG*@10': 0.12628221422433852, 'MRR*@10': 0.10775718025863171, 'Recall*@5': 0.1465962839126587, 'NDCG*@5': 0.11341970071196555, 'MRR*@5': 0.10247832372784614}
INFO    [02-27 19:12:02] train in BasicTrainer:
duration: 99.78911399841309s
INFO    [02-27 19:12:02] train in BasicTrainer:
epoch: 17
DEBUG   [02-27 19:12:25] calculate_loss in loss:
soft_target max: 0.7070711851119995, argmax 233017
DEBUG   [02-27 19:12:25] calculate_loss in loss:
pred max in softmax: 0.9353178143501282, argmax 78527
DEBUG   [02-27 19:12:25] calculate_loss in loss:
soft_target max: 0.723099410533905, argmax 68811
DEBUG   [02-27 19:12:25] calculate_loss in loss:
pred max in softmax: 0.7801480889320374, argmax 171292
INFO    [02-27 19:13:36] _train_one_epoch in BasicTrainer:
loss = 2.5019401082625756
INFO    [02-27 19:13:42] validate in BasicTrainer:
{'Recall@10': 0.1831587839126587, 'NDCG@10': 0.12332966655492783, 'MRR@10': 0.10503706485033035, 'Recall@5': 0.1423902028799057, 'NDCG@5': 0.11016624446958304, 'MRR@5': 0.09961303561925888, 'Recall*@10': 0.1831587839126587, 'NDCG*@10': 0.12332966655492783, 'MRR*@10': 0.10503706485033035, 'Recall*@5': 0.1423902028799057, 'NDCG*@5': 0.11016624446958304, 'MRR*@5': 0.09961303561925888}
INFO    [02-27 19:13:42] train in BasicTrainer:
duration: 99.7568211555481s
INFO    [02-27 19:13:42] train in BasicTrainer:
epoch: 18
DEBUG   [02-27 19:14:35] calculate_loss in loss:
soft_target max: 0.7559823393821716, argmax 40413
DEBUG   [02-27 19:14:35] calculate_loss in loss:
pred max in softmax: 0.634441077709198, argmax 192113
DEBUG   [02-27 19:14:35] calculate_loss in loss:
soft_target max: 0.7020687460899353, argmax 80057
DEBUG   [02-27 19:14:35] calculate_loss in loss:
pred max in softmax: 0.9160726070404053, argmax 224742
INFO    [02-27 19:15:15] _train_one_epoch in BasicTrainer:
loss = 2.4220345053495715
INFO    [02-27 19:15:21] log in loggers:
Update Best NDCG@10 Model at 18
INFO    [02-27 19:15:22] validate in BasicTrainer:
{'Recall@10': 0.18807432442903518, 'NDCG@10': 0.12720437042415142, 'MRR@10': 0.10863891758024692, 'Recall@5': 0.1442652028799057, 'NDCG@5': 0.11306330993771553, 'MRR@5': 0.1028132051229477, 'Recall*@10': 0.18807432442903518, 'NDCG*@10': 0.12720437042415142, 'MRR*@10': 0.10863891758024692, 'Recall*@5': 0.1442652028799057, 'NDCG*@5': 0.11306330993771553, 'MRR*@5': 0.1028132051229477}
INFO    [02-27 19:15:22] train in BasicTrainer:
duration: 99.7429039478302s
INFO    [02-27 19:15:22] train in BasicTrainer:
epoch: 19
DEBUG   [02-27 19:16:45] calculate_loss in loss:
soft_target max: 0.7720997929573059, argmax 11040
DEBUG   [02-27 19:16:45] calculate_loss in loss:
pred max in softmax: 0.8801625370979309, argmax 11040
DEBUG   [02-27 19:16:45] calculate_loss in loss:
soft_target max: 0.7777032256126404, argmax 87814
DEBUG   [02-27 19:16:45] calculate_loss in loss:
pred max in softmax: 0.8618996143341064, argmax 167051
INFO    [02-27 19:16:55] _train_one_epoch in BasicTrainer:
loss = 2.3532871683017014
INFO    [02-27 19:17:01] validate in BasicTrainer:
{'Recall@10': 0.18472128391265868, 'NDCG@10': 0.12605441510677337, 'MRR@10': 0.10814280159771443, 'Recall@5': 0.1441807433962822, 'NDCG@5': 0.11298000015318393, 'MRR@5': 0.1027646403759718, 'Recall*@10': 0.18472128391265868, 'NDCG*@10': 0.12605441510677337, 'MRR*@10': 0.10814280159771443, 'Recall*@5': 0.1441807433962822, 'NDCG*@5': 0.11298000015318393, 'MRR*@5': 0.1027646403759718}
INFO    [02-27 19:17:01] train in BasicTrainer:
duration: 99.44188737869263s
INFO    [02-27 19:17:01] train in BasicTrainer:
epoch: 20
INFO    [02-27 19:18:35] _train_one_epoch in BasicTrainer:
loss = 2.2868239191862254
INFO    [02-27 19:18:41] log in loggers:
Update Best NDCG@10 Model at 20
INFO    [02-27 19:18:41] validate in BasicTrainer:
{'Recall@10': 0.18892736494541168, 'NDCG@10': 0.12873393625020982, 'MRR@10': 0.11021081186830997, 'Recall@5': 0.1490962839126587, 'NDCG@5': 0.1158159253001213, 'MRR@5': 0.1048541685193777, 'Recall*@10': 0.18892736494541168, 'NDCG*@10': 0.12873393625020982, 'MRR*@10': 0.11021081186830997, 'Recall*@5': 0.1490962839126587, 'NDCG*@5': 0.1158159253001213, 'MRR*@5': 0.1048541685193777}
INFO    [02-27 19:18:41] train in BasicTrainer:
duration: 99.9227864742279s
INFO    [02-27 19:18:41] train in BasicTrainer:
epoch: 21
DEBUG   [02-27 19:19:02] calculate_loss in loss:
soft_target max: 0.7625399827957153, argmax 71784
DEBUG   [02-27 19:19:02] calculate_loss in loss:
pred max in softmax: 0.8861353993415833, argmax 220397
DEBUG   [02-27 19:19:02] calculate_loss in loss:
soft_target max: 0.7449015378952026, argmax 187306
DEBUG   [02-27 19:19:02] calculate_loss in loss:
pred max in softmax: 0.799489438533783, argmax 60188
INFO    [02-27 19:20:14] _train_one_epoch in BasicTrainer:
loss = 2.2254560555007794
INFO    [02-27 19:20:20] log in loggers:
Update Best NDCG@10 Model at 21
INFO    [02-27 19:20:21] validate in BasicTrainer:
{'Recall@10': 0.1827027028799057, 'NDCG@10': 0.12999018132686616, 'MRR@10': 0.11371393077075481, 'Recall@5': 0.1498902028799057, 'NDCG@5': 0.11934954077005386, 'MRR@5': 0.10930743373930454, 'Recall*@10': 0.1827027028799057, 'NDCG*@10': 0.12999018132686616, 'MRR*@10': 0.11371393077075481, 'Recall*@5': 0.1498902028799057, 'NDCG*@5': 0.11934954077005386, 'MRR*@5': 0.10930743373930454}
INFO    [02-27 19:20:21] train in BasicTrainer:
duration: 99.63613533973694s
INFO    [02-27 19:20:21] train in BasicTrainer:
epoch: 22
DEBUG   [02-27 19:21:12] calculate_loss in loss:
soft_target max: 0.7180298566818237, argmax 159849
DEBUG   [02-27 19:21:12] calculate_loss in loss:
pred max in softmax: 0.9081940650939941, argmax 114952
DEBUG   [02-27 19:21:12] calculate_loss in loss:
soft_target max: 0.7293285727500916, argmax 114258
DEBUG   [02-27 19:21:12] calculate_loss in loss:
pred max in softmax: 0.6884064674377441, argmax 95248
INFO    [02-27 19:21:54] _train_one_epoch in BasicTrainer:
loss = 2.175957669471872
INFO    [02-27 19:22:00] validate in BasicTrainer:
{'Recall@10': 0.1819087839126587, 'NDCG@10': 0.12904736332595348, 'MRR@10': 0.11290276169776917, 'Recall@5': 0.1414527028799057, 'NDCG@5': 0.11594141483306884, 'MRR@5': 0.10747987106442451, 'Recall*@10': 0.1819087839126587, 'NDCG*@10': 0.12904736332595348, 'MRR*@10': 0.11290276169776917, 'Recall*@5': 0.1414527028799057, 'NDCG*@5': 0.11594141483306884, 'MRR*@5': 0.10747987106442451}
INFO    [02-27 19:22:00] train in BasicTrainer:
duration: 99.33618378639221s
INFO    [02-27 19:22:00] train in BasicTrainer:
epoch: 23
DEBUG   [02-27 19:23:21] calculate_loss in loss:
soft_target max: 0.7550638914108276, argmax 171674
DEBUG   [02-27 19:23:21] calculate_loss in loss:
pred max in softmax: 0.8568001389503479, argmax 171674
DEBUG   [02-27 19:23:21] calculate_loss in loss:
soft_target max: 0.6623855829238892, argmax 211682
DEBUG   [02-27 19:23:21] calculate_loss in loss:
pred max in softmax: 0.8357594013214111, argmax 39549
INFO    [02-27 19:23:33] _train_one_epoch in BasicTrainer:
loss = 2.126768491628632
INFO    [02-27 19:23:39] validate in BasicTrainer:
{'Recall@10': 0.17815878391265869, 'NDCG@10': 0.1284835234284401, 'MRR@10': 0.11322646886110306, 'Recall@5': 0.1438682433962822, 'NDCG@5': 0.11746713772416115, 'MRR@5': 0.10872283257544041, 'Recall*@10': 0.17815878391265869, 'NDCG*@10': 0.1284835234284401, 'MRR*@10': 0.11322646886110306, 'Recall*@5': 0.1438682433962822, 'NDCG*@5': 0.11746713772416115, 'MRR*@5': 0.10872283257544041}
INFO    [02-27 19:23:39] train in BasicTrainer:
duration: 99.28680276870728s
INFO    [02-27 19:23:39] train in BasicTrainer:
epoch: 24
INFO    [02-27 19:25:13] _train_one_epoch in BasicTrainer:
loss = 2.0813491020341766
INFO    [02-27 19:25:19] log in loggers:
Update Best NDCG@10 Model at 24
INFO    [02-27 19:25:19] validate in BasicTrainer:
{'Recall@10': 0.1890962839126587, 'NDCG@10': 0.1340834929049015, 'MRR@10': 0.1172805069386959, 'Recall@5': 0.1510557433962822, 'NDCG@5': 0.12197368904948235, 'MRR@5': 0.11239597588777542, 'Recall*@10': 0.1890962839126587, 'NDCG*@10': 0.1340834929049015, 'MRR*@10': 0.1172805069386959, 'Recall*@5': 0.1510557433962822, 'NDCG*@5': 0.12197368904948235, 'MRR*@5': 0.11239597588777542}
INFO    [02-27 19:25:19] train in BasicTrainer:
duration: 99.61327934265137s
INFO    [02-27 19:25:19] train in BasicTrainer:
epoch: 25
DEBUG   [02-27 19:25:38] calculate_loss in loss:
soft_target max: 0.7911275625228882, argmax 4888
DEBUG   [02-27 19:25:38] calculate_loss in loss:
pred max in softmax: 0.7679011821746826, argmax 178998
DEBUG   [02-27 19:25:38] calculate_loss in loss:
soft_target max: 0.7239475846290588, argmax 91950
DEBUG   [02-27 19:25:38] calculate_loss in loss:
pred max in softmax: 0.9506300687789917, argmax 183635
INFO    [02-27 19:26:52] _train_one_epoch in BasicTrainer:
loss = 2.038596012548047
INFO    [02-27 19:26:58] validate in BasicTrainer:
{'Recall@10': 0.1821368244290352, 'NDCG@10': 0.13303532794117928, 'MRR@10': 0.11803542703390121, 'Recall@5': 0.14597128391265868, 'NDCG@5': 0.12136271819472313, 'MRR@5': 0.11323310896754264, 'Recall*@10': 0.1821368244290352, 'NDCG*@10': 0.13303532794117928, 'MRR*@10': 0.11803542703390121, 'Recall*@5': 0.14597128391265868, 'NDCG*@5': 0.12136271819472313, 'MRR*@5': 0.11323310896754264}
INFO    [02-27 19:26:58] train in BasicTrainer:
duration: 99.58542394638062s
INFO    [02-27 19:26:58] train in BasicTrainer:
epoch: 26
DEBUG   [02-27 19:27:48] calculate_loss in loss:
soft_target max: 0.772486686706543, argmax 77068
DEBUG   [02-27 19:27:48] calculate_loss in loss:
pred max in softmax: 0.8263244032859802, argmax 30402
INFO    [02-27 19:28:31] _train_one_epoch in BasicTrainer:
loss = 2.000777582907234
INFO    [02-27 19:28:37] log in loggers:
Update Best NDCG@10 Model at 26
INFO    [02-27 19:28:38] validate in BasicTrainer:
{'Recall@10': 0.1876182433962822, 'NDCG@10': 0.1365345171838999, 'MRR@10': 0.1208774946630001, 'Recall@5': 0.1507432433962822, 'NDCG@5': 0.1245833245664835, 'MRR@5': 0.11593032322824001, 'Recall*@10': 0.1876182433962822, 'NDCG*@10': 0.1365345171838999, 'MRR*@10': 0.1208774946630001, 'Recall*@5': 0.1507432433962822, 'NDCG*@5': 0.1245833245664835, 'MRR*@5': 0.11593032322824001}
INFO    [02-27 19:28:38] train in BasicTrainer:
duration: 99.16458010673523s
INFO    [02-27 19:28:38] train in BasicTrainer:
epoch: 27
INFO    [02-27 19:30:10] _train_one_epoch in BasicTrainer:
loss = 1.9669473512735545
INFO    [02-27 19:30:16] log in loggers:
Update Best NDCG@10 Model at 27
INFO    [02-27 19:30:16] validate in BasicTrainer:
{'Recall@10': 0.1861993244290352, 'NDCG@10': 0.1379971332848072, 'MRR@10': 0.12313905380666255, 'Recall@5': 0.1548057433962822, 'NDCG@5': 0.1278168198466301, 'MRR@5': 0.11891990609467029, 'Recall*@10': 0.1861993244290352, 'NDCG*@10': 0.1379971332848072, 'MRR*@10': 0.12313905380666255, 'Recall*@5': 0.1548057433962822, 'NDCG*@5': 0.1278168198466301, 'MRR*@5': 0.11891990609467029}
INFO    [02-27 19:30:16] train in BasicTrainer:
duration: 98.90278029441833s
INFO    [02-27 19:30:16] train in BasicTrainer:
epoch: 28
INFO    [02-27 19:31:49] _train_one_epoch in BasicTrainer:
loss = 1.9299733090147733
INFO    [02-27 19:31:55] validate in BasicTrainer:
{'Recall@10': 0.1844932433962822, 'NDCG@10': 0.132942021638155, 'MRR@10': 0.11732733204960823, 'Recall@5': 0.1429307433962822, 'NDCG@5': 0.1195439812541008, 'MRR@5': 0.11182249516248703, 'Recall*@10': 0.1844932433962822, 'NDCG*@10': 0.132942021638155, 'MRR*@10': 0.11732733204960823, 'Recall*@5': 0.1429307433962822, 'NDCG*@5': 0.1195439812541008, 'MRR*@5': 0.11182249516248703}
INFO    [02-27 19:31:55] train in BasicTrainer:
duration: 98.71061587333679s
INFO    [02-27 19:31:55] train in BasicTrainer:
epoch: 29
INFO    [02-27 19:33:28] _train_one_epoch in BasicTrainer:
loss = 1.900912068566846
INFO    [02-27 19:33:34] validate in BasicTrainer:
{'Recall@10': 0.1848057433962822, 'NDCG@10': 0.13381922647356986, 'MRR@10': 0.11807442478835582, 'Recall@5': 0.1529307433962822, 'NDCG@5': 0.1235833340883255, 'MRR@5': 0.11389287836849689, 'Recall*@10': 0.1848057433962822, 'NDCG*@10': 0.13381922647356986, 'MRR*@10': 0.11807442478835582, 'Recall*@5': 0.1529307433962822, 'NDCG*@5': 0.1235833340883255, 'MRR*@5': 0.11389287836849689}
INFO    [02-27 19:33:34] train in BasicTrainer:
duration: 98.83462047576904s
INFO    [02-27 19:33:34] train in BasicTrainer:
epoch: 30
INFO    [02-27 19:35:07] _train_one_epoch in BasicTrainer:
loss = 1.868992330541029
INFO    [02-27 19:35:13] validate in BasicTrainer:
{'Recall@10': 0.18668074339628218, 'NDCG@10': 0.13624516680836676, 'MRR@10': 0.12091984048485756, 'Recall@5': 0.14886824339628218, 'NDCG@5': 0.12425983101129531, 'MRR@5': 0.11611416161060334, 'Recall*@10': 0.18668074339628218, 'NDCG*@10': 0.13624516680836676, 'MRR*@10': 0.12091984048485756, 'Recall*@5': 0.14886824339628218, 'NDCG*@5': 0.12425983101129531, 'MRR*@5': 0.11611416161060334}
INFO    [02-27 19:35:13] train in BasicTrainer:
duration: 99.09889030456543s
INFO    [02-27 19:35:13] train in BasicTrainer:
epoch: 31
INFO    [02-27 19:36:47] _train_one_epoch in BasicTrainer:
loss = 1.8385502496828134
INFO    [02-27 19:36:53] validate in BasicTrainer:
{'Recall@10': 0.1806587839126587, 'NDCG@10': 0.13550979331135748, 'MRR@10': 0.12161246538162232, 'Recall@5': 0.1504307433962822, 'NDCG@5': 0.12574776589870454, 'MRR@5': 0.11759276658296586, 'Recall*@10': 0.1806587839126587, 'NDCG*@10': 0.13550979331135748, 'MRR*@10': 0.12161246538162232, 'Recall*@5': 0.1504307433962822, 'NDCG*@5': 0.12574776589870454, 'MRR*@5': 0.11759276658296586}
INFO    [02-27 19:36:53] train in BasicTrainer:
duration: 99.59816932678223s
INFO    [02-27 19:36:53] train in BasicTrainer:
epoch: 32
INFO    [02-27 19:38:26] _train_one_epoch in BasicTrainer:
loss = 1.814886933138263
INFO    [02-27 19:38:32] validate in BasicTrainer:
{'Recall@10': 0.1848057433962822, 'NDCG@10': 0.13560732707381248, 'MRR@10': 0.12042592421174049, 'Recall@5': 0.1523057433962822, 'NDCG@5': 0.12510346479713916, 'MRR@5': 0.11609755143523216, 'Recall*@10': 0.1848057433962822, 'NDCG*@10': 0.13560732707381248, 'MRR*@10': 0.12042592421174049, 'Recall*@5': 0.1523057433962822, 'NDCG*@5': 0.12510346479713916, 'MRR*@5': 0.11609755143523216}
INFO    [02-27 19:38:32] train in BasicTrainer:
duration: 99.60344099998474s
INFO    [02-27 19:38:32] train in BasicTrainer:
epoch: 33
INFO    [02-27 19:40:05] _train_one_epoch in BasicTrainer:
loss = 1.7921938676416715
INFO    [02-27 19:40:11] validate in BasicTrainer:
{'Recall@10': 0.1838682433962822, 'NDCG@10': 0.13645890414714812, 'MRR@10': 0.12188518270850182, 'Recall@5': 0.1532432433962822, 'NDCG@5': 0.1265707378089428, 'MRR@5': 0.11781573832035065, 'Recall*@10': 0.1838682433962822, 'NDCG*@10': 0.13645890414714812, 'MRR*@10': 0.12188518270850182, 'Recall*@5': 0.1532432433962822, 'NDCG*@5': 0.1265707378089428, 'MRR*@5': 0.11781573832035065}
INFO    [02-27 19:40:11] train in BasicTrainer:
duration: 99.005934715271s
INFO    [02-27 19:40:11] train in BasicTrainer:
epoch: 34
INFO    [02-27 19:41:45] _train_one_epoch in BasicTrainer:
loss = 1.7690421670121919
INFO    [02-27 19:41:51] validate in BasicTrainer:
{'Recall@10': 0.1835557433962822, 'NDCG@10': 0.13718989953398705, 'MRR@10': 0.12299442753195762, 'Recall@5': 0.1510557433962822, 'NDCG@5': 0.12670232474803925, 'MRR@5': 0.11868130758404732, 'Recall*@10': 0.1835557433962822, 'NDCG*@10': 0.13718989953398705, 'MRR*@10': 0.12299442753195762, 'Recall*@5': 0.1510557433962822, 'NDCG*@5': 0.12670232474803925, 'MRR*@5': 0.11868130758404732}
INFO    [02-27 19:41:51] train in BasicTrainer:
duration: 99.60557198524475s
INFO    [02-27 19:41:51] train in BasicTrainer:
epoch: 35
INFO    [02-27 19:43:24] _train_one_epoch in BasicTrainer:
loss = 1.7465667096942425
INFO    [02-27 19:43:30] validate in BasicTrainer:
{'Recall@10': 0.1779307433962822, 'NDCG@10': 0.13472286239266396, 'MRR@10': 0.12143217518925667, 'Recall@5': 0.1494932433962822, 'NDCG@5': 0.12545524448156356, 'MRR@5': 0.11756672374904156, 'Recall*@10': 0.1779307433962822, 'NDCG*@10': 0.13472286239266396, 'MRR*@10': 0.12143217518925667, 'Recall*@5': 0.1494932433962822, 'NDCG*@5': 0.12545524448156356, 'MRR*@5': 0.11756672374904156}
INFO    [02-27 19:43:30] train in BasicTrainer:
duration: 99.42031979560852s
INFO    [02-27 19:43:30] train in BasicTrainer:
epoch: 36
INFO    [02-27 19:45:04] _train_one_epoch in BasicTrainer:
loss = 1.7272503078774368
INFO    [02-27 19:45:10] validate in BasicTrainer:
{'Recall@10': 0.18557432442903518, 'NDCG@10': 0.13692260518670082, 'MRR@10': 0.12213941588997841, 'Recall@5': 0.1504307433962822, 'NDCG@5': 0.1256659761816263, 'MRR@5': 0.11755630686879158, 'Recall*@10': 0.18557432442903518, 'NDCG*@10': 0.13692260518670082, 'MRR*@10': 0.12213941588997841, 'Recall*@5': 0.1504307433962822, 'NDCG*@5': 0.1256659761816263, 'MRR*@5': 0.11755630686879158}
INFO    [02-27 19:45:10] train in BasicTrainer:
duration: 99.52598071098328s
INFO    [02-27 19:45:10] train in BasicTrainer:
epoch: 37
INFO    [02-27 19:46:43] _train_one_epoch in BasicTrainer:
loss = 1.7106800441400443
INFO    [02-27 19:46:50] validate in BasicTrainer:
{'Recall@10': 0.1794932433962822, 'NDCG@10': 0.13482165157794954, 'MRR@10': 0.12112798258662223, 'Recall@5': 0.1491807433962822, 'NDCG@5': 0.12510149054229258, 'MRR@5': 0.11716568119823932, 'Recall*@10': 0.1794932433962822, 'NDCG*@10': 0.13482165157794954, 'MRR*@10': 0.12112798258662223, 'Recall*@5': 0.1491807433962822, 'NDCG*@5': 0.12510149054229258, 'MRR*@5': 0.11716568119823932}
INFO    [02-27 19:46:50] train in BasicTrainer:
duration: 99.6322329044342s
INFO    [02-27 19:46:50] train in BasicTrainer:
epoch: 38
INFO    [02-27 19:48:23] _train_one_epoch in BasicTrainer:
loss = 1.692787871752873
INFO    [02-27 19:48:29] validate in BasicTrainer:
{'Recall@10': 0.1832432433962822, 'NDCG@10': 0.1364903250336647, 'MRR@10': 0.12207937113940716, 'Recall@5': 0.1510557433962822, 'NDCG@5': 0.12607217997312545, 'MRR@5': 0.11777505643665791, 'Recall*@10': 0.1832432433962822, 'NDCG*@10': 0.1364903250336647, 'MRR*@10': 0.12207937113940716, 'Recall*@5': 0.1510557433962822, 'NDCG*@5': 0.12607217997312545, 'MRR*@5': 0.11777505643665791}
INFO    [02-27 19:48:29] train in BasicTrainer:
duration: 99.59836483001709s
INFO    [02-27 19:48:29] train in BasicTrainer:
epoch: 39
INFO    [02-27 19:50:03] _train_one_epoch in BasicTrainer:
loss = 1.674480505109782
INFO    [02-27 19:50:09] validate in BasicTrainer:
{'Recall@10': 0.1829307433962822, 'NDCG@10': 0.13663381293416024, 'MRR@10': 0.1226011411100626, 'Recall@5': 0.1473057433962822, 'NDCG@5': 0.12524726375937462, 'MRR@5': 0.11797874502837657, 'Recall*@10': 0.1829307433962822, 'NDCG*@10': 0.13663381293416024, 'MRR*@10': 0.1226011411100626, 'Recall*@5': 0.1473057433962822, 'NDCG*@5': 0.12524726375937462, 'MRR*@5': 0.11797874502837657}
INFO    [02-27 19:50:09] train in BasicTrainer:
duration: 99.4915292263031s
INFO    [02-27 19:50:09] train in BasicTrainer:
epoch: 40
INFO    [02-27 19:51:42] _train_one_epoch in BasicTrainer:
loss = 1.6563107828246504
INFO    [02-27 19:51:48] validate in BasicTrainer:
{'Recall@10': 0.1757432433962822, 'NDCG@10': 0.13196221277117728, 'MRR@10': 0.11850832536816597, 'Recall@5': 0.1460557433962822, 'NDCG@5': 0.1222595091164112, 'MRR@5': 0.11444284997880459, 'Recall*@10': 0.1757432433962822, 'NDCG*@10': 0.13196221277117728, 'MRR*@10': 0.11850832536816597, 'Recall*@5': 0.1460557433962822, 'NDCG*@5': 0.1222595091164112, 'MRR*@5': 0.11444284997880459}
INFO    [02-27 19:51:48] train in BasicTrainer:
duration: 99.27529716491699s
INFO    [02-27 19:51:48] train in BasicTrainer:
epoch: 41
INFO    [02-27 19:53:21] _train_one_epoch in BasicTrainer:
loss = 1.6437918558044837
INFO    [02-27 19:53:27] validate in BasicTrainer:
{'Recall@10': 0.17761824339628218, 'NDCG@10': 0.13424751326441764, 'MRR@10': 0.12099468246102334, 'Recall@5': 0.1485557433962822, 'NDCG@5': 0.12506671965122224, 'MRR@5': 0.117331363260746, 'Recall*@10': 0.17761824339628218, 'NDCG*@10': 0.13424751326441764, 'MRR*@10': 0.12099468246102334, 'Recall*@5': 0.1485557433962822, 'NDCG*@5': 0.12506671965122224, 'MRR*@5': 0.117331363260746}
INFO    [02-27 19:53:27] train in BasicTrainer:
duration: 99.5125937461853s
INFO    [02-27 19:53:27] train in BasicTrainer:
epoch: 42
INFO    [02-27 19:55:01] _train_one_epoch in BasicTrainer:
loss = 1.6293963701402476
INFO    [02-27 19:55:07] validate in BasicTrainer:
{'Recall@10': 0.1804307433962822, 'NDCG@10': 0.13610814332962037, 'MRR@10': 0.1225864815711975, 'Recall@5': 0.15011824339628219, 'NDCG@5': 0.12641931913793086, 'MRR@5': 0.11865456216037273, 'Recall*@10': 0.1804307433962822, 'NDCG*@10': 0.13610814332962037, 'MRR*@10': 0.1225864815711975, 'Recall*@5': 0.15011824339628219, 'NDCG*@5': 0.12641931913793086, 'MRR*@5': 0.11865456216037273}
INFO    [02-27 19:55:07] train in BasicTrainer:
duration: 99.49739193916321s
INFO    [02-27 19:55:07] train in BasicTrainer:
epoch: 43
INFO    [02-27 19:56:40] _train_one_epoch in BasicTrainer:
loss = 1.6135731004277338
INFO    [02-27 19:56:46] validate in BasicTrainer:
{'Recall@10': 0.1785557433962822, 'NDCG@10': 0.1359770592302084, 'MRR@10': 0.12301557466387748, 'Recall@5': 0.1479307433962822, 'NDCG@5': 0.12625217355787755, 'MRR@5': 0.11910374537110328, 'Recall*@10': 0.1785557433962822, 'NDCG*@10': 0.1359770592302084, 'MRR*@10': 0.12301557466387748, 'Recall*@5': 0.1479307433962822, 'NDCG*@5': 0.12625217355787755, 'MRR*@5': 0.11910374537110328}
INFO    [02-27 19:56:46] train in BasicTrainer:
duration: 99.57112169265747s
INFO    [02-27 19:56:46] train in BasicTrainer:
epoch: 44
INFO    [02-27 19:58:20] _train_one_epoch in BasicTrainer:
loss = 1.6017593559599048
INFO    [02-27 19:58:26] validate in BasicTrainer:
{'Recall@10': 0.1763682433962822, 'NDCG@10': 0.13424021914601325, 'MRR@10': 0.12114541098475456, 'Recall@5': 0.15011824339628219, 'NDCG@5': 0.12588081300258636, 'MRR@5': 0.1177704119682312, 'Recall*@10': 0.1763682433962822, 'NDCG*@10': 0.13424021914601325, 'MRR*@10': 0.12114541098475456, 'Recall*@5': 0.15011824339628219, 'NDCG*@5': 0.12588081300258636, 'MRR*@5': 0.1177704119682312}
INFO    [02-27 19:58:26] train in BasicTrainer:
duration: 99.63738107681274s
INFO    [02-27 19:58:26] train in BasicTrainer:
epoch: 45
INFO    [02-27 20:00:00] _train_one_epoch in BasicTrainer:
loss = 1.5823369590610028
INFO    [02-27 20:00:06] validate in BasicTrainer:
{'Recall@10': 0.1775337839126587, 'NDCG@10': 0.1378017270565033, 'MRR@10': 0.12564024306833743, 'Recall@5': 0.1491807433962822, 'NDCG@5': 0.12865078449249268, 'MRR@5': 0.12187401629984379, 'Recall*@10': 0.1775337839126587, 'NDCG*@10': 0.1378017270565033, 'MRR*@10': 0.12564024306833743, 'Recall*@5': 0.1491807433962822, 'NDCG*@5': 0.12865078449249268, 'MRR*@5': 0.12187401629984379}
INFO    [02-27 20:00:06] train in BasicTrainer:
duration: 99.4663302898407s
INFO    [02-27 20:00:06] train in BasicTrainer:
epoch: 46
INFO    [02-27 20:01:39] _train_one_epoch in BasicTrainer:
loss = 1.569856514665113
INFO    [02-27 20:01:45] validate in BasicTrainer:
{'Recall@10': 0.17682432442903517, 'NDCG@10': 0.1327159248292446, 'MRR@10': 0.11907111793756485, 'Recall@5': 0.1482432433962822, 'NDCG@5': 0.12352163419127464, 'MRR@5': 0.11530532225966454, 'Recall*@10': 0.17682432442903517, 'NDCG*@10': 0.1327159248292446, 'MRR*@10': 0.11907111793756485, 'Recall*@5': 0.1482432433962822, 'NDCG*@5': 0.12352163419127464, 'MRR*@5': 0.11530532225966454}
INFO    [02-27 20:01:45] train in BasicTrainer:
duration: 99.42880344390869s
INFO    [02-27 20:01:45] train in BasicTrainer:
epoch: 47
INFO    [02-27 20:03:18] _train_one_epoch in BasicTrainer:
loss = 1.5571968017901918
INFO    [02-27 20:03:24] validate in BasicTrainer:
{'Recall@10': 0.1741807433962822, 'NDCG@10': 0.13516452200710774, 'MRR@10': 0.1229874886572361, 'Recall@5': 0.1513682433962822, 'NDCG@5': 0.12777333192527293, 'MRR@5': 0.11993032194674015, 'Recall*@10': 0.1741807433962822, 'NDCG*@10': 0.13516452200710774, 'MRR*@10': 0.1229874886572361, 'Recall*@5': 0.1513682433962822, 'NDCG*@5': 0.12777333192527293, 'MRR*@5': 0.11993032194674015}
INFO    [02-27 20:03:24] train in BasicTrainer:
duration: 99.33889150619507s
INFO    [02-27 20:03:24] train in BasicTrainer:
epoch: 48
INFO    [02-27 20:04:58] _train_one_epoch in BasicTrainer:
loss = 1.5508664674088557
INFO    [02-27 20:05:04] validate in BasicTrainer:
{'Recall@10': 0.1760557433962822, 'NDCG@10': 0.13503507524728775, 'MRR@10': 0.12245388314127922, 'Recall@5': 0.14761824339628218, 'NDCG@5': 0.1259329476952553, 'MRR@5': 0.1187532390654087, 'Recall*@10': 0.1760557433962822, 'NDCG*@10': 0.13503507524728775, 'MRR*@10': 0.12245388314127922, 'Recall*@5': 0.14761824339628218, 'NDCG*@5': 0.1259329476952553, 'MRR*@5': 0.1187532390654087}
INFO    [02-27 20:05:04] train in BasicTrainer:
duration: 99.48796057701111s
INFO    [02-27 20:05:04] train in BasicTrainer:
epoch: 49
INFO    [02-27 20:06:37] _train_one_epoch in BasicTrainer:
loss = 1.5376965979049946
INFO    [02-27 20:06:43] validate in BasicTrainer:
{'Recall@10': 0.1751182433962822, 'NDCG@10': 0.13349544040858746, 'MRR@10': 0.12069371446967125, 'Recall@5': 0.1485557433962822, 'NDCG@5': 0.12489621080458164, 'MRR@5': 0.11713865518569946, 'Recall*@10': 0.1751182433962822, 'NDCG*@10': 0.13349544040858746, 'MRR*@10': 0.12069371446967125, 'Recall*@5': 0.1485557433962822, 'NDCG*@5': 0.12489621080458164, 'MRR*@5': 0.11713865518569946}
INFO    [02-27 20:06:43] train in BasicTrainer:
duration: 99.60825634002686s
INFO    [02-27 20:06:43] train in BasicTrainer:
epoch: 50
INFO    [02-27 20:08:17] _train_one_epoch in BasicTrainer:
loss = 1.5265010037219808
INFO    [02-27 20:08:23] validate in BasicTrainer:
{'Recall@10': 0.1738682433962822, 'NDCG@10': 0.13208030194044112, 'MRR@10': 0.11925742313265801, 'Recall@5': 0.1419932433962822, 'NDCG@5': 0.12176119454205037, 'MRR@5': 0.11499465145170688, 'Recall*@10': 0.1738682433962822, 'NDCG*@10': 0.13208030194044112, 'MRR*@10': 0.11925742313265801, 'Recall*@5': 0.1419932433962822, 'NDCG*@5': 0.12176119454205037, 'MRR*@5': 0.11499465145170688}
INFO    [02-27 20:08:23] train in BasicTrainer:
duration: 99.35516571998596s
INFO    [02-27 20:08:23] train in BasicTrainer:
epoch: 51
INFO    [02-27 20:09:56] _train_one_epoch in BasicTrainer:
loss = 1.5152166915825254
INFO    [02-27 20:10:02] validate in BasicTrainer:
{'Recall@10': 0.1782432433962822, 'NDCG@10': 0.13471460118889808, 'MRR@10': 0.12118280291557312, 'Recall@5': 0.1526182433962822, 'NDCG@5': 0.1264422746747732, 'MRR@5': 0.11777407258749008, 'Recall*@10': 0.1782432433962822, 'NDCG*@10': 0.13471460118889808, 'MRR*@10': 0.12118280291557312, 'Recall*@5': 0.1526182433962822, 'NDCG*@5': 0.1264422746747732, 'MRR*@5': 0.11777407258749008}
INFO    [02-27 20:10:02] train in BasicTrainer:
duration: 99.50586271286011s
INFO    [02-27 20:10:02] train in BasicTrainer:
epoch: 52
INFO    [02-27 20:11:35] _train_one_epoch in BasicTrainer:
loss = 1.5064355836939116
INFO    [02-27 20:11:41] validate in BasicTrainer:
{'Recall@10': 0.1744932433962822, 'NDCG@10': 0.13194884851574898, 'MRR@10': 0.11884295381605625, 'Recall@5': 0.1460557433962822, 'NDCG@5': 0.12279343768954278, 'MRR@5': 0.1150912168622017, 'Recall*@10': 0.1744932433962822, 'NDCG*@10': 0.13194884851574898, 'MRR*@10': 0.11884295381605625, 'Recall*@5': 0.1460557433962822, 'NDCG*@5': 0.12279343768954278, 'MRR*@5': 0.1150912168622017}
INFO    [02-27 20:11:41] train in BasicTrainer:
duration: 99.11496806144714s
INFO    [02-27 20:11:41] train in BasicTrainer:
epoch: 53
INFO    [02-27 20:13:15] _train_one_epoch in BasicTrainer:
loss = 1.4971538263543531
INFO    [02-27 20:13:21] validate in BasicTrainer:
{'Recall@10': 0.1729307433962822, 'NDCG@10': 0.13218949615955353, 'MRR@10': 0.1196557604521513, 'Recall@5': 0.1448057433962822, 'NDCG@5': 0.12311822175979614, 'MRR@5': 0.11592609845101834, 'Recall*@10': 0.1729307433962822, 'NDCG*@10': 0.13218949615955353, 'MRR*@10': 0.1196557604521513, 'Recall*@5': 0.1448057433962822, 'NDCG*@5': 0.12311822175979614, 'MRR*@5': 0.11592609845101834}
INFO    [02-27 20:13:21] train in BasicTrainer:
duration: 99.6055018901825s
INFO    [02-27 20:13:21] train in BasicTrainer:
epoch: 54
INFO    [02-27 20:14:55] _train_one_epoch in BasicTrainer:
loss = 1.4899844297995934
INFO    [02-27 20:15:01] validate in BasicTrainer:
{'Recall@10': 0.1740962839126587, 'NDCG@10': 0.13468186661601067, 'MRR@10': 0.12261985287070275, 'Recall@5': 0.14565878391265868, 'NDCG@5': 0.12547628939151764, 'MRR@5': 0.11881404981017113, 'Recall*@10': 0.1740962839126587, 'NDCG*@10': 0.13468186661601067, 'MRR*@10': 0.12261985287070275, 'Recall*@5': 0.14565878391265868, 'NDCG*@5': 0.12547628939151764, 'MRR*@5': 0.11881404981017113}
INFO    [02-27 20:15:01] train in BasicTrainer:
duration: 99.55039405822754s
INFO    [02-27 20:15:01] train in BasicTrainer:
epoch: 55
INFO    [02-27 20:16:34] _train_one_epoch in BasicTrainer:
loss = 1.4803115663857296
INFO    [02-27 20:16:40] validate in BasicTrainer:
{'Recall@10': 0.17065878391265868, 'NDCG@10': 0.12989206865429878, 'MRR@10': 0.11736017346382141, 'Recall@5': 0.1432432433962822, 'NDCG@5': 0.12109772227704525, 'MRR@5': 0.11377407342195511, 'Recall*@10': 0.17065878391265868, 'NDCG*@10': 0.12989206865429878, 'MRR*@10': 0.11736017346382141, 'Recall*@5': 0.1432432433962822, 'NDCG*@5': 0.12109772227704525, 'MRR*@5': 0.11377407342195511}
INFO    [02-27 20:16:40] train in BasicTrainer:
duration: 99.40872240066528s
INFO    [02-27 20:16:40] train in BasicTrainer:
epoch: 56
INFO    [02-27 20:18:13] _train_one_epoch in BasicTrainer:
loss = 1.4727689631737828
INFO    [02-27 20:18:19] validate in BasicTrainer:
{'Recall@10': 0.17494932442903519, 'NDCG@10': 0.13287273727357388, 'MRR@10': 0.12000050954520702, 'Recall@5': 0.1434712839126587, 'NDCG@5': 0.12268248245120049, 'MRR@5': 0.11578519195318222, 'Recall*@10': 0.17494932442903519, 'NDCG*@10': 0.13287273727357388, 'MRR*@10': 0.12000050954520702, 'Recall*@5': 0.1434712839126587, 'NDCG*@5': 0.12268248245120049, 'MRR*@5': 0.11578519195318222}
INFO    [02-27 20:18:19] train in BasicTrainer:
duration: 99.39857578277588s
INFO    [02-27 20:18:19] train in BasicTrainer:
epoch: 57
INFO    [02-27 20:19:53] _train_one_epoch in BasicTrainer:
loss = 1.4640237004434398
INFO    [02-27 20:19:59] validate in BasicTrainer:
{'Recall@10': 0.1806587839126587, 'NDCG@10': 0.1361842380464077, 'MRR@10': 0.12266464576125145, 'Recall@5': 0.1466807433962822, 'NDCG@5': 0.12521155744791032, 'MRR@5': 0.11814414471387863, 'Recall*@10': 0.1806587839126587, 'NDCG*@10': 0.1361842380464077, 'MRR*@10': 0.12266464576125145, 'Recall*@5': 0.1466807433962822, 'NDCG*@5': 0.12521155744791032, 'MRR*@5': 0.11814414471387863}
INFO    [02-27 20:19:59] train in BasicTrainer:
duration: 99.73101449012756s
INFO    [02-27 20:19:59] train in BasicTrainer:
epoch: 58
INFO    [02-27 20:21:33] _train_one_epoch in BasicTrainer:
loss = 1.4569423627157743
INFO    [02-27 20:21:39] validate in BasicTrainer:
{'Recall@10': 0.1688682433962822, 'NDCG@10': 0.13126385673880578, 'MRR@10': 0.1197055558860302, 'Recall@5': 0.1438682433962822, 'NDCG@5': 0.1232580491155386, 'MRR@5': 0.1164474955946207, 'Recall*@10': 0.1688682433962822, 'NDCG*@10': 0.13126385673880578, 'MRR*@10': 0.1197055558860302, 'Recall*@5': 0.1438682433962822, 'NDCG*@5': 0.1232580491155386, 'MRR*@5': 0.1164474955946207}
INFO    [02-27 20:21:39] train in BasicTrainer:
duration: 99.79493522644043s
INFO    [02-27 20:21:39] train in BasicTrainer:
epoch: 59
INFO    [02-27 20:23:12] _train_one_epoch in BasicTrainer:
loss = 1.4455892348795418
INFO    [02-27 20:23:18] validate in BasicTrainer:
{'Recall@10': 0.1750337839126587, 'NDCG@10': 0.13495874144136905, 'MRR@10': 0.12273196607828141, 'Recall@5': 0.1453462839126587, 'NDCG@5': 0.12532502122223377, 'MRR@5': 0.11873705133795738, 'Recall*@10': 0.1750337839126587, 'NDCG*@10': 0.13495874144136905, 'MRR*@10': 0.12273196607828141, 'Recall*@5': 0.1453462839126587, 'NDCG*@5': 0.12532502122223377, 'MRR*@5': 0.11873705133795738}
INFO    [02-27 20:23:18] train in BasicTrainer:
duration: 99.47146773338318s
INFO    [02-27 20:23:18] close_training in BasicTrainer:
finished training
DEBUG   [02-27 20:23:18] debug_summary in loss:
loss nan summary: nan 0 times, not nan 45240 times, ratio nan / (nan + not_nan) = 0.0
INFO    [02-27 20:23:18] run_routine in Routine:
Finished training, Start final validation
INFO    [02-27 20:23:18] final_validate in BasicTrainer:
validate model on val set!
INFO    [02-27 20:23:19] load_state_from_given_path in utils:
checkpoint epoch: 27
INFO    [02-27 20:23:19] load_state_from_given_path in utils:
Loading model's parameters
INFO    [02-27 20:23:24] validate in BasicTrainer:
{'Recall@10': 0.1861993244290352, 'NDCG@10': 0.1379971332848072, 'MRR@10': 0.12313905380666255, 'Recall@5': 0.1548057433962822, 'NDCG@5': 0.1278168198466301, 'MRR@5': 0.11891990609467029, 'Recall*@10': 0.1861993244290352, 'NDCG*@10': 0.1379971332848072, 'MRR*@10': 0.12313905380666255, 'Recall*@5': 0.1548057433962822, 'NDCG*@5': 0.1278168198466301, 'MRR*@5': 0.11891990609467029}
INFO    [02-27 20:23:24] run_routine in Routine:
Finished final validating. Result: {'Recall@10': 0.1861993244290352, 'NDCG@10': 0.1379971332848072, 'MRR@10': 0.12313905380666255, 'Recall@5': 0.1548057433962822, 'NDCG@5': 0.1278168198466301, 'MRR@5': 0.11891990609467029, 'Recall*@10': 0.1861993244290352, 'NDCG*@10': 0.1379971332848072, 'MRR*@10': 0.12313905380666255, 'Recall*@5': 0.1548057433962822, 'NDCG*@5': 0.1278168198466301, 'MRR*@5': 0.11891990609467029}
